{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Start the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "# !pip3 install git+https://github.com/slremy/netsapi --user --upgrade\n",
    "from netsapi.challenge import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ChallengeSeqDecEnvironment(experimentCount=1050000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_agents=1\n",
    "states = env.state\n",
    "states = np.array([states]).reshape(1, 1)\n",
    "state_size = states.shape[1]\n",
    "action_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of each action: 2\n",
      "There are 1 agents. Each observes a state with length: 1\n",
      "The state for the first agent looks like: [[1]]\n"
     ]
    }
   ],
   "source": [
    "print('Size of each action:', action_size)\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.46154226]]\n",
      "1050000  Evaluations Remaining\n",
      "reward= 24.778090451075105\n",
      "[[0.24169257 0.        ]]\n",
      "1049999  Evaluations Remaining\n",
      "reward= 0.9650818731952384\n",
      "[[0. 1.]]\n",
      "1049998  Evaluations Remaining\n",
      "reward= 108.08112018943143\n",
      "[[0.         0.73162052]]\n",
      "1049997  Evaluations Remaining\n",
      "reward= -0.2270319713438118\n",
      "[[0.28312755 0.01642971]]\n",
      "1049996  Evaluations Remaining\n",
      "reward= 0.4495587132962693\n",
      "True\n",
      "Total score (averaged over agents) this episode: 134.0468192556542\n"
     ]
    }
   ],
   "source": [
    "env.reset()     # reset the environment    \n",
    "states = np.array([env.state]).reshape(1, 1) # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, 0, 1)                  # all actions between -1 and 1\n",
    "    print(actions)\n",
    " \n",
    "    next_states, reward, done, _ = env.evaluateAction(actions[0])           # send all actions to tne environment\n",
    "    scores += reward                        # update the score (for each agent)\n",
    "    print(\"reward=\",reward)\n",
    "    states = next_states                              # roll over states to next time step\n",
    "    if np.any(done): \n",
    "        print(done)\n",
    "        # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049995  Evaluations Remaining\n",
      "1049994  Evaluations Remaining\n",
      "1049993  Evaluations Remaining\n",
      "1049992  Evaluations Remaining\n",
      "1049991  Evaluations Remaining\n",
      "[{'1': [0.0, 0.4402395388825513], '2': [0.21141550547941215, 0.0], '3': [1.0, 0.0], '4': [0.0, 0.10152020954400577], '5': [0.0, 1.0]}, {'1': [0.0, 0.4402395388825513], '2': [0.21141550547941215, 0.0], '3': [1.0, 0.0], '4': [0.0, 0.10152020954400577], '5': [0.0, 1.0]}, {'1': [0.0, 0.4402395388825513], '2': [0.21141550547941215, 0.0], '3': [1.0, 0.0], '4': [0.0, 0.10152020954400577], '5': [0.0, 1.0]}, {'1': [0.0, 0.4402395388825513], '2': [0.21141550547941215, 0.0], '3': [1.0, 0.0], '4': [0.0, 0.10152020954400577], '5': [0.0, 1.0]}, {'1': [0.0, 0.4402395388825513], '2': [0.21141550547941215, 0.0], '3': [1.0, 0.0], '4': [0.0, 0.10152020954400577], '5': [0.0, 1.0]}]\n",
      "1049990  Evaluations Remaining\n",
      "results= [196.4702989972896, 188.40411200703286, 191.16737059899918, 194.47313287043667, 194.70705258166333]\n",
      "sum(results)= 965.2219670554216\n"
     ]
    }
   ],
   "source": [
    "env.reset()     # reset the environment    \n",
    "i = 0\n",
    "policies = []\n",
    "policy = {}\n",
    "while True:\n",
    "    \n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, 0, 1)                  # all actions between -1 and 1\n",
    "    i +=1\n",
    "    next_states, reward, done, _ = env.evaluateAction(actions[0])           # send all actions to tne environment\n",
    "    policy[str(i)]=list(actions[0])\n",
    "    policies.append(policy)\n",
    "    if done: \n",
    "        break\n",
    "    \n",
    "print(policies)\n",
    "reward = env.evaluatePolicy(policies)            \n",
    "print('results=',reward)\n",
    "print('sum(results)=',sum(reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.random.randn(1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Take Actions with DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.1663044 , -1.49098913])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randn(num_agents, action_size) \n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.1663044 , -1.49098913,  4.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(a[0],[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import deque\n",
    "from ddpg_agent import Agent\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising ReplayBuffer\n",
      "\n",
      " actions= [[0. 0.]]\n",
      "1049965  Evaluations Remaining\n",
      "rewards= 2.60878478422339\n",
      "\n",
      " actions= [[0. 0.]]\n",
      "1049964  Evaluations Remaining\n",
      "rewards= 0.1321420012646235\n",
      "Timestep 1\tScore: 2.74\tmin: 2.74\tmax: 2.74\n",
      " actions= [[1. 0.]]\n",
      "1049963  Evaluations Remaining\n",
      "rewards= 86.98250898996157\n",
      "Timestep 2\tScore: 89.72\tmin: 89.72\tmax: 89.72\n",
      " actions= [[0.4385173  0.40092149]]\n",
      "1049962  Evaluations Remaining\n",
      "rewards= 14.217400251450165\n",
      "Timestep 3\tScore: 103.94\tmin: 103.94\tmax: 103.94\n",
      " actions= [[0.43824422 0.5172857 ]]\n",
      "1049961  Evaluations Remaining\n",
      "rewards= -5.352043727134145\n",
      "Episode 1\tScore: 98.59\tAverage Score: 98.5959\n",
      "\n",
      " actions= [[0.09617476 0.21222468]]\n",
      "1049960  Evaluations Remaining\n",
      "rewards= 16.459587701767866\n",
      "\n",
      " actions= [[0. 0.]]\n",
      "1049959  Evaluations Remaining\n",
      "rewards= 0.023316145599379556\n",
      "Timestep 1\tScore: 16.48\tmin: 16.48\tmax: 16.48\n",
      " actions= [[0.36597833 0.49485904]]\n",
      "1049958  Evaluations Remaining\n",
      "rewards= 28.39431974751288\n",
      "Timestep 2\tScore: 44.88\tmin: 44.88\tmax: 44.88\n",
      " actions= [[0.        0.6380072]]\n",
      "1049957  Evaluations Remaining\n",
      "rewards= 9.681462551229377\n",
      "Timestep 3\tScore: 54.56\tmin: 54.56\tmax: 54.56\n",
      " actions= [[0.48174465 0.56295061]]\n",
      "1049956  Evaluations Remaining\n",
      "rewards= 6.133472578361596\n",
      "Episode 2\tScore: 60.69\tAverage Score: 79.6469\n",
      "\n",
      " actions= [[0.7592058 0.       ]]\n",
      "1049955  Evaluations Remaining\n",
      "rewards= 61.44648635671511\n",
      "\n",
      " actions= [[0.77456179 0.        ]]\n",
      "1049954  Evaluations Remaining\n",
      "rewards= -0.06708934167945735\n",
      "Timestep 1\tScore: 61.38\tmin: 61.38\tmax: 61.38\n",
      " actions= [[0.39546242 0.32869077]]\n",
      "1049953  Evaluations Remaining\n",
      "rewards= 4.784158566919677\n",
      "Timestep 2\tScore: 66.16\tmin: 66.16\tmax: 66.16\n",
      " actions= [[0.47743627 0.28242853]]\n",
      "1049952  Evaluations Remaining\n",
      "rewards= -92.68688670694523\n",
      "Timestep 3\tScore: -26.52\tmin: -26.52\tmax: -26.52\n",
      " actions= [[0.41381249 0.        ]]\n",
      "1049951  Evaluations Remaining\n",
      "rewards= 0.5673239962237524\n",
      "Episode 3\tScore: -25.96\tAverage Score: 44.445.96\n",
      "\n",
      " actions= [[0.22016774 0.06848884]]\n",
      "1049950  Evaluations Remaining\n",
      "rewards= -14.557030344753084\n",
      "\n",
      " actions= [[0.24014448 0.25651991]]\n",
      "1049949  Evaluations Remaining\n",
      "rewards= -11.28376551272097\n",
      "Timestep 1\tScore: -25.84\tmin: -25.84\tmax: -25.84\n",
      " actions= [[0.69343728 0.        ]]\n",
      "1049948  Evaluations Remaining\n",
      "rewards= 26.2585281596735\n",
      "Timestep 2\tScore: 0.42\tmin: 0.42\tmax: 0.42\n",
      " actions= [[1. 0.]]\n",
      "1049947  Evaluations Remaining\n",
      "rewards= 4.25508393240948\n",
      "Timestep 3\tScore: 4.67\tmin: 4.67\tmax: 4.67\n",
      " actions= [[0.42788732 0.47931635]]\n",
      "1049946  Evaluations Remaining\n",
      "rewards= 20.63900522427904\n",
      "Episode 4\tScore: 25.31\tAverage Score: 39.6631\n",
      "\n",
      " actions= [[0.20896687 0.13833214]]\n",
      "1049945  Evaluations Remaining\n",
      "rewards= -30.824951280425953\n",
      "\n",
      " actions= [[0.19081532 0.        ]]\n",
      "1049944  Evaluations Remaining\n",
      "rewards= -0.2679786235196011\n",
      "Timestep 1\tScore: -31.09\tmin: -31.09\tmax: -31.09\n",
      " actions= [[0.38547009 0.28543901]]\n",
      "1049943  Evaluations Remaining\n",
      "rewards= -22.512769816871195\n",
      "Timestep 2\tScore: -53.61\tmin: -53.61\tmax: -53.61\n",
      " actions= [[1. 1.]]\n",
      "1049942  Evaluations Remaining\n",
      "rewards= 18.027175253726114\n",
      "Timestep 3\tScore: -35.58\tmin: -35.58\tmax: -35.58\n",
      " actions= [[0.46736735 0.37272021]]\n",
      "1049941  Evaluations Remaining\n",
      "rewards= 0.12777422613339473\n",
      "Episode 5\tScore: -35.45\tAverage Score: 24.645.45\n",
      "\n",
      " actions= [[0.06403837 0.18179621]]\n",
      "1049940  Evaluations Remaining\n",
      "rewards= 35.93134067240821\n",
      "\n",
      " actions= [[0.25011677 0.31491277]]\n",
      "1049939  Evaluations Remaining\n",
      "rewards= -21.208026192431348\n",
      "Timestep 1\tScore: 14.72\tmin: 14.72\tmax: 14.72\n",
      " actions= [[0.         0.96095692]]\n",
      "1049938  Evaluations Remaining\n",
      "rewards= 44.48912860715996\n",
      "Timestep 2\tScore: 59.21\tmin: 59.21\tmax: 59.21\n",
      " actions= [[0.49184567 0.3764559 ]]\n",
      "1049937  Evaluations Remaining\n",
      "rewards= 21.970063232255313\n",
      "Timestep 3\tScore: 81.18\tmin: 81.18\tmax: 81.18\n",
      " actions= [[0.59663165 0.50926286]]\n",
      "1049936  Evaluations Remaining\n",
      "rewards= -3.448309947359385\n",
      "Episode 6\tScore: 77.73\tAverage Score: 33.4973\n",
      "\n",
      " actions= [[0.23602647 0.14621443]]\n",
      "1049935  Evaluations Remaining\n",
      "rewards= -53.79986944319419\n",
      "\n",
      " actions= [[0.33911532 0.32773963]]\n",
      "1049934  Evaluations Remaining\n",
      "rewards= -18.129202858279594\n",
      "Timestep 1\tScore: -71.93\tmin: -71.93\tmax: -71.93\n",
      " actions= [[0.45238644 0.30011588]]\n",
      "1049933  Evaluations Remaining\n",
      "rewards= -90.57830730511985\n",
      "Timestep 2\tScore: -162.51\tmin: -162.51\tmax: -162.51\n",
      " actions= [[0.49204075 0.38479587]]\n",
      "1049932  Evaluations Remaining\n",
      "rewards= -26.619032637103103\n",
      "Timestep 3\tScore: -189.13\tmin: -189.13\tmax: -189.13\n",
      " actions= [[0.10451504 0.        ]]\n",
      "1049931  Evaluations Remaining\n",
      "rewards= -0.022244372109421207\n",
      "Episode 7\tScore: -189.15\tAverage Score: 1.68-189.15\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049930  Evaluations Remaining\n",
      "rewards= 15.250636126410084\n",
      "\n",
      " actions= [[0.         0.74279889]]\n",
      "1049929  Evaluations Remaining\n",
      "rewards= -0.16603773476987582\n",
      "Timestep 1\tScore: 15.08\tmin: 15.08\tmax: 15.08\n",
      " actions= [[0.35609823 0.17160322]]\n",
      "1049928  Evaluations Remaining\n",
      "rewards= -15.998559202579775\n",
      "Timestep 2\tScore: -0.91\tmin: -0.91\tmax: -0.91\n",
      " actions= [[0.48995286 0.25724342]]\n",
      "1049927  Evaluations Remaining\n",
      "rewards= -83.85188431526542\n",
      "Timestep 3\tScore: -84.77\tmin: -84.77\tmax: -84.77\n",
      " actions= [[0.43145043 0.34936586]]\n",
      "1049926  Evaluations Remaining\n",
      "rewards= -14.830555784140962\n",
      "Episode 8\tScore: -99.60\tAverage Score: -10.98.60\n",
      "\n",
      " actions= [[1.         0.51867787]]\n",
      "1049925  Evaluations Remaining\n",
      "rewards= 49.028919025227445\n",
      "\n",
      " actions= [[0.56567481 1.        ]]\n",
      "1049924  Evaluations Remaining\n",
      "rewards= 20.914543887207284\n",
      "Timestep 1\tScore: 69.94\tmin: 69.94\tmax: 69.94\n",
      " actions= [[0.19104886 0.15941722]]\n",
      "1049923  Evaluations Remaining\n",
      "rewards= -0.22124234594044\n",
      "Timestep 2\tScore: 69.72\tmin: 69.72\tmax: 69.72\n",
      " actions= [[0.46389401 0.27544427]]\n",
      "1049922  Evaluations Remaining\n",
      "rewards= -40.36595496703481\n",
      "Timestep 3\tScore: 29.36\tmin: 29.36\tmax: 29.36\n",
      " actions= [[0. 0.]]\n",
      "1049921  Evaluations Remaining\n",
      "rewards= 0.04943743910246878\n",
      "Episode 9\tScore: 29.41\tAverage Score: -6.4941\n",
      "\n",
      " actions= [[0.09805747 0.07444128]]\n",
      "1049920  Evaluations Remaining\n",
      "rewards= 9.199121114692074\n",
      "\n",
      " actions= [[0.16232385 0.10117805]]\n",
      "1049919  Evaluations Remaining\n",
      "rewards= -1.3529689010322703\n",
      "Timestep 1\tScore: 7.85\tmin: 7.85\tmax: 7.85\n",
      " actions= [[0.15093873 0.11389184]]\n",
      "1049918  Evaluations Remaining\n",
      "rewards= 5.619813610234624\n",
      "Timestep 2\tScore: 13.47\tmin: 13.47\tmax: 13.47\n",
      " actions= [[0.17587923 0.17054366]]\n",
      "1049917  Evaluations Remaining\n",
      "rewards= -1.0001016305114978\n",
      "Timestep 3\tScore: 12.47\tmin: 12.47\tmax: 12.47\n",
      " actions= [[0.28556173 0.        ]]\n",
      "1049916  Evaluations Remaining\n",
      "rewards= 1.1152756705260982\n",
      "Episode 10\tScore: 13.58\tAverage Score: -4.488\n",
      "\n",
      " actions= [[0.45668453 0.        ]]\n",
      "1049915  Evaluations Remaining\n",
      "rewards= 19.98256013240884\n",
      "\n",
      " actions= [[0. 0.]]\n",
      "1049914  Evaluations Remaining\n",
      "rewards= 0.2197188814722586\n",
      "Timestep 1\tScore: 20.20\tmin: 20.20\tmax: 20.20\n",
      " actions= [[0.30838603 0.4329235 ]]\n",
      "1049913  Evaluations Remaining\n",
      "rewards= 48.151267827099524\n",
      "Timestep 2\tScore: 68.35\tmin: 68.35\tmax: 68.35\n",
      " actions= [[0.30723169 0.45023498]]\n",
      "1049912  Evaluations Remaining\n",
      "rewards= -14.11526924294749\n",
      "Timestep 3\tScore: 54.24\tmin: 54.24\tmax: 54.24\n",
      " actions= [[0.94842884 0.41133384]]\n",
      "1049911  Evaluations Remaining\n",
      "rewards= 36.676626020543615\n",
      "Episode 11\tScore: 90.91\tAverage Score: -5.251\n",
      "\n",
      " actions= [[0.07780237 0.        ]]\n",
      "1049910  Evaluations Remaining\n",
      "rewards= 2.7634071571116334\n",
      "\n",
      " actions= [[0.21930952 0.17418543]]\n",
      "1049909  Evaluations Remaining\n",
      "rewards= -32.238087325194826\n",
      "Timestep 1\tScore: -29.47\tmin: -29.47\tmax: -29.47\n",
      " actions= [[0.09613978 0.07819483]]\n",
      "1049908  Evaluations Remaining\n",
      "rewards= 5.986945287000793\n",
      "Timestep 2\tScore: -23.49\tmin: -23.49\tmax: -23.49\n",
      " actions= [[0.29264265 1.        ]]\n",
      "1049907  Evaluations Remaining\n",
      "rewards= 29.024477824666874\n",
      "Timestep 3\tScore: 5.54\tmin: 5.54\tmax: 5.54\n",
      " actions= [[0.30347514 0.34953067]]\n",
      "1049906  Evaluations Remaining\n",
      "rewards= 0.32873989351059896\n",
      "Episode 12\tScore: 5.87\tAverage Score: -10.73\n",
      "\n",
      " actions= [[0.17282307 0.1544908 ]]\n",
      "1049905  Evaluations Remaining\n",
      "rewards= -13.251864666770778\n",
      "\n",
      " actions= [[0.22975676 0.21908443]]\n",
      "1049904  Evaluations Remaining\n",
      "rewards= -21.653836346987486\n",
      "Timestep 1\tScore: -34.91\tmin: -34.91\tmax: -34.91\n",
      " actions= [[1.         0.10189588]]\n",
      "1049903  Evaluations Remaining\n",
      "rewards= 43.711127236675765\n",
      "Timestep 2\tScore: 8.81\tmin: 8.81\tmax: 8.81\n",
      " actions= [[0.95636834 0.        ]]\n",
      "1049902  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 0.22931963374970232\n",
      "Timestep 3\tScore: 9.03\tmin: 9.03\tmax: 9.03\n",
      " actions= [[0.37548211 0.39606211]]\n",
      "1049901  Evaluations Remaining\n",
      "rewards= 12.86434915198748\n",
      "Episode 13\tScore: 21.90\tAverage Score: -5.950\n",
      "\n",
      " actions= [[0.12652691 0.17064135]]\n",
      "1049900  Evaluations Remaining\n",
      "rewards= 13.213112469262143\n",
      "\n",
      " actions= [[0.25020206 0.15487337]]\n",
      "1049899  Evaluations Remaining\n",
      "rewards= -38.48699720810298\n",
      "Timestep 1\tScore: -25.27\tmin: -25.27\tmax: -25.27\n",
      " actions= [[0.2669062  0.17072126]]\n",
      "1049898  Evaluations Remaining\n",
      "rewards= -34.20647860256117\n",
      "Timestep 2\tScore: -59.48\tmin: -59.48\tmax: -59.48\n",
      " actions= [[0.33076802 0.26172411]]\n",
      "1049897  Evaluations Remaining\n",
      "rewards= -42.8052122951351\n",
      "Timestep 3\tScore: -102.29\tmin: -102.29\tmax: -102.29\n",
      " actions= [[0.36759443 0.        ]]\n",
      "1049896  Evaluations Remaining\n",
      "rewards= 1.2300204945854052\n",
      "Episode 14\tScore: -101.06\tAverage Score: -18.591.06\n",
      "\n",
      " actions= [[0.13945195 0.1920846 ]]\n",
      "1049895  Evaluations Remaining\n",
      "rewards= 5.715151979316203\n",
      "\n",
      " actions= [[0.28860977 0.20365757]]\n",
      "1049894  Evaluations Remaining\n",
      "rewards= -65.2570976885826\n",
      "Timestep 1\tScore: -59.54\tmin: -59.54\tmax: -59.54\n",
      " actions= [[0.37841034 0.1954778 ]]\n",
      "1049893  Evaluations Remaining\n",
      "rewards= -82.30897271356051\n",
      "Timestep 2\tScore: -141.85\tmin: -141.85\tmax: -141.85\n",
      " actions= [[0.527004   0.25078601]]\n",
      "1049892  Evaluations Remaining\n",
      "rewards= -84.56081652131442\n",
      "Timestep 3\tScore: -226.41\tmin: -226.41\tmax: -226.41\n",
      " actions= [[0.51841784 0.26033244]]\n",
      "1049891  Evaluations Remaining\n",
      "rewards= -60.19366595629718\n",
      "Episode 15\tScore: -286.61\tAverage Score: -43.706.61\n",
      "\n",
      " actions= [[0.04654501 0.19482172]]\n",
      "1049890  Evaluations Remaining\n",
      "rewards= 35.37822284733834\n",
      "\n",
      " actions= [[0.07016436 0.1814452 ]]\n",
      "1049889  Evaluations Remaining\n",
      "rewards= 38.61100680311857\n",
      "Timestep 1\tScore: 73.99\tmin: 73.99\tmax: 73.99\n",
      " actions= [[0.24166654 0.21183713]]\n",
      "1049888  Evaluations Remaining\n",
      "rewards= -50.01528859037017\n",
      "Timestep 2\tScore: 23.97\tmin: 23.97\tmax: 23.97\n",
      " actions= [[0.22823039 0.36653787]]\n",
      "1049887  Evaluations Remaining\n",
      "rewards= -3.0676167672659433\n",
      "Timestep 3\tScore: 20.91\tmin: 20.91\tmax: 20.91\n",
      " actions= [[0.21758229 0.37279058]]\n",
      "1049886  Evaluations Remaining\n",
      "rewards= -6.684046952171399\n",
      "Episode 16\tScore: 14.22\tAverage Score: -50.05\n",
      "\n",
      " actions= [[0. 0.]]\n",
      "1049885  Evaluations Remaining\n",
      "rewards= 2.7811733508481615\n",
      "\n",
      " actions= [[0. 0.]]\n",
      "1049884  Evaluations Remaining\n",
      "rewards= -0.22046998758032244\n",
      "Timestep 1\tScore: 2.56\tmin: 2.56\tmax: 2.56\n",
      " actions= [[0.         0.67978509]]\n",
      "1049883  Evaluations Remaining\n",
      "rewards= 48.90967298314917\n",
      "Timestep 2\tScore: 51.47\tmin: 51.47\tmax: 51.47\n",
      " actions= [[0.37818694 0.39649096]]\n",
      "1049882  Evaluations Remaining\n",
      "rewards= -56.855470930754365\n",
      "Timestep 3\tScore: -5.39\tmin: -5.39\tmax: -5.39\n",
      " actions= [[0.51461881 0.5435136 ]]\n",
      "1049881  Evaluations Remaining\n",
      "rewards= 3.0069459773048455\n",
      "Episode 17\tScore: -2.38\tAverage Score: -31.37\n",
      "\n",
      " actions= [[0.0544744  0.18010239]]\n",
      "1049880  Evaluations Remaining\n",
      "rewards= 40.29112966483198\n",
      "\n",
      " actions= [[0.18807866 0.28597057]]\n",
      "1049879  Evaluations Remaining\n",
      "rewards= -8.773197853471588\n",
      "Timestep 1\tScore: 31.52\tmin: 31.52\tmax: 31.52\n",
      " actions= [[0.29027876 0.33534044]]\n",
      "1049878  Evaluations Remaining\n",
      "rewards= -27.03659762117935\n",
      "Timestep 2\tScore: 4.48\tmin: 4.48\tmax: 4.48\n",
      " actions= [[0.         0.94425289]]\n",
      "1049877  Evaluations Remaining\n",
      "rewards= 35.889157018803104\n",
      "Timestep 3\tScore: 40.37\tmin: 40.37\tmax: 40.37\n",
      " actions= [[0.29286098 0.40361699]]\n",
      "1049876  Evaluations Remaining\n",
      "rewards= -11.006111137267604\n",
      "Episode 18\tScore: 29.36\tAverage Score: -18.48\n",
      "\n",
      " actions= [[0.18977338 0.09792662]]\n",
      "1049875  Evaluations Remaining\n",
      "rewards= -13.86782056130726\n",
      "\n",
      " actions= [[0.17481674 0.12083727]]\n",
      "1049874  Evaluations Remaining\n",
      "rewards= 0.9803564907707139\n",
      "Timestep 1\tScore: -12.89\tmin: -12.89\tmax: -12.89\n",
      " actions= [[0.21481776 0.18567321]]\n",
      "1049873  Evaluations Remaining\n",
      "rewards= -18.673508928759926\n",
      "Timestep 2\tScore: -31.56\tmin: -31.56\tmax: -31.56\n",
      " actions= [[0. 0.]]\n",
      "1049872  Evaluations Remaining\n",
      "rewards= -0.13423699555706037\n",
      "Timestep 3\tScore: -31.70\tmin: -31.70\tmax: -31.70\n",
      " actions= [[0.22749916 0.26001763]]\n",
      "1049871  Evaluations Remaining\n",
      "rewards= -16.098756774592967\n",
      "Episode 19\tScore: -47.79\tAverage Score: -26.2079\n",
      "\n",
      " actions= [[0. 0.]]\n",
      "1049870  Evaluations Remaining\n",
      "rewards= 2.486054057971634\n",
      "\n",
      " actions= [[0.14141242 0.11776091]]\n",
      "1049869  Evaluations Remaining\n",
      "rewards= 1.8672945890895059\n",
      "Timestep 1\tScore: 4.35\tmin: 4.35\tmax: 4.35\n",
      " actions= [[0.22173887 0.27295777]]\n",
      "1049868  Evaluations Remaining\n",
      "rewards= -12.391999288509139\n",
      "Timestep 2\tScore: -8.04\tmin: -8.04\tmax: -8.04\n",
      " actions= [[0.2623744  0.33337227]]\n",
      "1049867  Evaluations Remaining\n",
      "rewards= -14.290710481545814\n",
      "Timestep 3\tScore: -22.33\tmin: -22.33\tmax: -22.33\n",
      " actions= [[0.31499881 0.34816819]]\n",
      "1049866  Evaluations Remaining\n",
      "rewards= -29.372702400434385\n",
      "Episode 20\tScore: -51.70\tAverage Score: -32.7370\n",
      "\n",
      " actions= [[0.22495346 0.21421319]]\n",
      "1049865  Evaluations Remaining\n",
      "rewards= -32.16338769785389\n",
      "\n",
      " actions= [[0.27122664 0.38097259]]\n",
      "1049864  Evaluations Remaining\n",
      "rewards= -5.292378034453057\n",
      "Timestep 1\tScore: -37.46\tmin: -37.46\tmax: -37.46\n",
      " actions= [[0.25155038 0.34757659]]\n",
      "1049863  Evaluations Remaining\n",
      "rewards= -13.3718080668785\n",
      "Timestep 2\tScore: -50.83\tmin: -50.83\tmax: -50.83\n",
      " actions= [[0.23196781 0.30038995]]\n",
      "1049862  Evaluations Remaining\n",
      "rewards= -13.674350475226435\n",
      "Timestep 3\tScore: -64.50\tmin: -64.50\tmax: -64.50\n",
      " actions= [[0.30764443 0.34959793]]\n",
      "1049861  Evaluations Remaining\n",
      "rewards= -25.583091815289755\n",
      "Episode 21\tScore: -90.09\tAverage Score: -50.8309\n",
      "\n",
      " actions= [[0.16305123 0.16613594]]\n",
      "1049860  Evaluations Remaining\n",
      "rewards= -5.64471875217307\n",
      "\n",
      " actions= [[0.         0.26072904]]\n",
      "1049859  Evaluations Remaining\n",
      "rewards= 32.03768399548898\n",
      "Timestep 1\tScore: 26.39\tmin: 26.39\tmax: 26.39\n",
      " actions= [[0.35293975 0.37130314]]\n",
      "1049858  Evaluations Remaining\n",
      "rewards= -22.26555249577148\n",
      "Timestep 2\tScore: 4.13\tmin: 4.13\tmax: 4.13\n",
      " actions= [[0.31410956 0.5023613 ]]\n",
      "1049857  Evaluations Remaining\n",
      "rewards= -2.5084095996576834\n",
      "Timestep 3\tScore: 1.62\tmin: 1.62\tmax: 1.62\n",
      " actions= [[0.45584825 0.52343559]]\n",
      "1049856  Evaluations Remaining\n",
      "rewards= -36.77134232981484\n",
      "Episode 22\tScore: -35.15\tAverage Score: -54.9315\n",
      "\n",
      " actions= [[0. 0.]]\n",
      "1049855  Evaluations Remaining\n",
      "rewards= 2.637780699204822\n",
      "\n",
      " actions= [[0. 0.]]\n",
      "1049854  Evaluations Remaining\n",
      "rewards= -0.24455150627924782\n",
      "Timestep 1\tScore: 2.39\tmin: 2.39\tmax: 2.39\n",
      " actions= [[0.09966351 0.28865373]]\n",
      "1049853  Evaluations Remaining\n",
      "rewards= 3.3689247643349485\n",
      "Timestep 2\tScore: 5.76\tmin: 5.76\tmax: 5.76\n",
      " actions= [[0.20137382 0.27901164]]\n",
      "1049852  Evaluations Remaining\n",
      "rewards= -17.464661051069708\n",
      "Timestep 3\tScore: -11.70\tmin: -11.70\tmax: -11.70\n",
      " actions= [[0.37255785 0.27252209]]\n",
      "1049851  Evaluations Remaining\n",
      "rewards= -96.21350011987111\n",
      "Episode 23\tScore: -107.92\tAverage Score: -67.917.92\n",
      "\n",
      " actions= [[0.18205939 0.20580675]]\n",
      "1049850  Evaluations Remaining\n",
      "rewards= -12.14393437069226\n",
      "\n",
      " actions= [[0.34345695 0.24443966]]\n",
      "1049849  Evaluations Remaining\n",
      "rewards= -86.8365532892458\n",
      "Timestep 1\tScore: -98.98\tmin: -98.98\tmax: -98.98\n",
      " actions= [[1. 0.]]\n",
      "1049848  Evaluations Remaining\n",
      "rewards= 46.43709931172718\n",
      "Timestep 2\tScore: -52.54\tmin: -52.54\tmax: -52.54\n",
      " actions= [[0.47226354 0.32658291]]\n",
      "1049847  Evaluations Remaining\n",
      "rewards= 10.173687422153503\n",
      "Timestep 3\tScore: -42.37\tmin: -42.37\tmax: -42.37\n",
      " actions= [[0.60014766 0.47240958]]\n",
      "1049846  Evaluations Remaining\n",
      "rewards= -3.092332503668057\n",
      "Episode 24\tScore: -45.46\tAverage Score: -62.3546\n",
      "\n",
      " actions= [[1.         0.33862487]]\n",
      "1049845  Evaluations Remaining\n",
      "rewards= 52.22420088939706\n",
      "\n",
      " actions= [[0.21193941 0.20621358]]\n",
      "1049844  Evaluations Remaining\n",
      "rewards= 48.625268514631756\n",
      "Timestep 1\tScore: 100.85\tmin: 100.85\tmax: 100.85\n",
      " actions= [[0. 0.]]\n",
      "1049843  Evaluations Remaining\n",
      "rewards= -0.07946469683693103\n",
      "Timestep 2\tScore: 100.77\tmin: 100.77\tmax: 100.77\n",
      " actions= [[0.51748845 0.        ]]\n",
      "1049842  Evaluations Remaining\n",
      "rewards= 27.91788629583174\n",
      "Timestep 3\tScore: 128.69\tmin: 128.69\tmax: 128.69\n",
      " actions= [[0.78636625 0.        ]]\n",
      "1049841  Evaluations Remaining\n",
      "rewards= 9.289084761198707\n",
      "Episode 25\tScore: 137.98\tAverage Score: -19.8998\n",
      "\n",
      " actions= [[1. 0.]]\n",
      "1049840  Evaluations Remaining\n",
      "rewards= 95.78975043190019\n",
      "\n",
      " actions= [[0.22039139 0.18512137]]\n",
      "1049839  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 51.18739523012359\n",
      "Timestep 1\tScore: 146.98\tmin: 146.98\tmax: 146.98\n",
      " actions= [[0.29745486 0.35201165]]\n",
      "1049838  Evaluations Remaining\n",
      "rewards= -10.177779905654726\n",
      "Timestep 2\tScore: 136.80\tmin: 136.80\tmax: 136.80\n",
      " actions= [[0.37040117 0.45549741]]\n",
      "1049837  Evaluations Remaining\n",
      "rewards= -11.256100070820507\n",
      "Timestep 3\tScore: 125.54\tmin: 125.54\tmax: 125.54\n",
      " actions= [[0.47303054 0.58977425]]\n",
      "1049836  Evaluations Remaining\n",
      "rewards= -1.3870852948604009\n",
      "Episode 26\tScore: 124.16\tAverage Score: -8.90.16\n",
      "\n",
      " actions= [[0.22722964 0.0714964 ]]\n",
      "1049835  Evaluations Remaining\n",
      "rewards= -19.03560158374707\n",
      "\n",
      " actions= [[0.35167247 0.1857055 ]]\n",
      "1049834  Evaluations Remaining\n",
      "rewards= -89.02865331622569\n",
      "Timestep 1\tScore: -108.06\tmin: -108.06\tmax: -108.06\n",
      " actions= [[0.61902672 0.16349812]]\n",
      "1049833  Evaluations Remaining\n",
      "rewards= -44.738124988602905\n",
      "Timestep 2\tScore: -152.80\tmin: -152.80\tmax: -152.80\n",
      " actions= [[0.64861608 0.24548735]]\n",
      "1049832  Evaluations Remaining\n",
      "rewards= -54.74845130968245\n",
      "Timestep 3\tScore: -207.55\tmin: -207.55\tmax: -207.55\n",
      " actions= [[1.         0.64948765]]\n",
      "1049831  Evaluations Remaining\n",
      "rewards= 35.47301921634968\n",
      "Episode 27\tScore: -172.08\tAverage Score: -25.872.08\n",
      "\n",
      " actions= [[0.14204846 0.21005583]]\n",
      "1049830  Evaluations Remaining\n",
      "rewards= 3.436435349890991\n",
      "\n",
      " actions= [[0.26179591 0.37322301]]\n",
      "1049829  Evaluations Remaining\n",
      "rewards= -7.27777724375431\n",
      "Timestep 1\tScore: -3.84\tmin: -3.84\tmax: -3.84\n",
      " actions= [[0.         0.80942413]]\n",
      "1049828  Evaluations Remaining\n",
      "rewards= 27.2905157547571\n",
      "Timestep 2\tScore: 23.45\tmin: 23.45\tmax: 23.45\n",
      " actions= [[0.44980124 0.54594773]]\n",
      "1049827  Evaluations Remaining\n",
      "rewards= -1.23711681935517\n",
      "Timestep 3\tScore: 22.21\tmin: 22.21\tmax: 22.21\n",
      " actions= [[0.47404563 0.46699619]]\n",
      "1049826  Evaluations Remaining\n",
      "rewards= -53.87113206988358\n",
      "Episode 28\tScore: -31.66\tAverage Score: -31.9766\n",
      "\n",
      " actions= [[0.24535136 0.10415285]]\n",
      "1049825  Evaluations Remaining\n",
      "rewards= -39.30418122321758\n",
      "\n",
      " actions= [[0.53493893 0.2903893 ]]\n",
      "1049824  Evaluations Remaining\n",
      "rewards= -13.03556186551865\n",
      "Timestep 1\tScore: -52.34\tmin: -52.34\tmax: -52.34\n",
      " actions= [[0.37425059 0.34704509]]\n",
      "1049823  Evaluations Remaining\n",
      "rewards= -7.399116497231992\n",
      "Timestep 2\tScore: -59.74\tmin: -59.74\tmax: -59.74\n",
      " actions= [[1.        0.6714074]]\n",
      "1049822  Evaluations Remaining\n",
      "rewards= 2.1963888919035894\n",
      "Timestep 3\tScore: -57.54\tmin: -57.54\tmax: -57.54\n",
      " actions= [[0.3872444  0.59658039]]\n",
      "1049821  Evaluations Remaining\n",
      "rewards= 39.294441119302896\n",
      "Episode 29\tScore: -18.25\tAverage Score: -29.0225\n",
      "\n",
      " actions= [[0.27115709 0.30338028]]\n",
      "1049820  Evaluations Remaining\n",
      "rewards= -7.546674651048633\n",
      "\n",
      " actions= [[0.41442358 0.36461678]]\n",
      "1049819  Evaluations Remaining\n",
      "rewards= -41.46790288551468\n",
      "Timestep 1\tScore: -49.01\tmin: -49.01\tmax: -49.01\n",
      " actions= [[1. 0.]]\n",
      "1049818  Evaluations Remaining\n",
      "rewards= 35.77319466349621\n",
      "Timestep 2\tScore: -13.24\tmin: -13.24\tmax: -13.24\n",
      " actions= [[0.         0.76719717]]\n",
      "1049817  Evaluations Remaining\n",
      "rewards= 113.70625605677688\n",
      "Timestep 3\tScore: 100.46\tmin: 100.46\tmax: 100.46\n",
      " actions= [[1. 1.]]\n",
      "1049816  Evaluations Remaining\n",
      "rewards= 17.733602877382786\n",
      "Episode 30\tScore: 118.20\tAverage Score: -12.0320\n",
      "\n",
      " actions= [[0.25518361 0.35110977]]\n",
      "1049815  Evaluations Remaining\n",
      "rewards= 10.720792006336415\n",
      "\n",
      " actions= [[0.53838855 0.69273901]]\n",
      "1049814  Evaluations Remaining\n",
      "rewards= 10.141884701372266\n",
      "Timestep 1\tScore: 20.86\tmin: 20.86\tmax: 20.86\n",
      " actions= [[0.59547609 0.8228212 ]]\n",
      "1049813  Evaluations Remaining\n",
      "rewards= -37.28471790022805\n",
      "Timestep 2\tScore: -16.42\tmin: -16.42\tmax: -16.42\n",
      " actions= [[0.         0.14045523]]\n",
      "1049812  Evaluations Remaining\n",
      "rewards= 1.9441856468593106\n",
      "Timestep 3\tScore: -14.48\tmin: -14.48\tmax: -14.48\n",
      " actions= [[0.59578252 0.70087129]]\n",
      "1049811  Evaluations Remaining\n",
      "rewards= -0.7751644043594077\n",
      "Episode 31\tScore: -15.25\tAverage Score: -4.54.25\n",
      "\n",
      " actions= [[0.54641241 0.47048333]]\n",
      "1049810  Evaluations Remaining\n",
      "rewards= 2.2924060480045036\n",
      "\n",
      " actions= [[0. 1.]]\n",
      "1049809  Evaluations Remaining\n",
      "rewards= 25.65051145222168\n",
      "Timestep 1\tScore: 27.94\tmin: 27.94\tmax: 27.94\n",
      " actions= [[1. 1.]]\n",
      "1049808  Evaluations Remaining\n",
      "rewards= 100.38818428603842\n",
      "Timestep 2\tScore: 128.33\tmin: 128.33\tmax: 128.33\n",
      " actions= [[1. 1.]]\n",
      "1049807  Evaluations Remaining\n",
      "rewards= 0.02511468103863601\n",
      "Timestep 3\tScore: 128.36\tmin: 128.36\tmax: 128.36\n",
      " actions= [[1.         0.23621969]]\n",
      "1049806  Evaluations Remaining\n",
      "rewards= 0.24732200628538248\n",
      "Episode 32\tScore: 128.60\tAverage Score: 11.83.60\n",
      "\n",
      " actions= [[0.70702326 0.65276307]]\n",
      "1049805  Evaluations Remaining\n",
      "rewards= 3.225468921842463\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049804  Evaluations Remaining\n",
      "rewards= 11.230613663461012\n",
      "Timestep 1\tScore: 14.46\tmin: 14.46\tmax: 14.46\n",
      " actions= [[0. 1.]]\n",
      "1049803  Evaluations Remaining\n",
      "rewards= 0.26389213345955964\n",
      "Timestep 2\tScore: 14.72\tmin: 14.72\tmax: 14.72\n",
      " actions= [[1. 1.]]\n",
      "1049802  Evaluations Remaining\n",
      "rewards= 96.0348307176587\n",
      "Timestep 3\tScore: 110.75\tmin: 110.75\tmax: 110.75\n",
      " actions= [[1. 1.]]\n",
      "1049801  Evaluations Remaining\n",
      "rewards= 0.21101448225311126\n",
      "Episode 33\tScore: 110.97\tAverage Score: 33.72.97\n",
      "\n",
      " actions= [[0.83403021 0.78649765]]\n",
      "1049800  Evaluations Remaining\n",
      "rewards= -32.02775009151076\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049799  Evaluations Remaining\n",
      "rewards= -7.424862362974043\n",
      "Timestep 1\tScore: -39.45\tmin: -39.45\tmax: -39.45\n",
      " actions= [[1. 1.]]\n",
      "1049798  Evaluations Remaining\n",
      "rewards= -0.11886174210386402\n",
      "Timestep 2\tScore: -39.57\tmin: -39.57\tmax: -39.57\n",
      " actions= [[1. 1.]]\n",
      "1049797  Evaluations Remaining\n",
      "rewards= -0.11151913765616861\n",
      "Timestep 3\tScore: -39.68\tmin: -39.68\tmax: -39.68\n",
      " actions= [[1. 1.]]\n",
      "1049796  Evaluations Remaining\n",
      "rewards= -0.08644564231955965\n",
      "Episode 34\tScore: -39.77\tAverage Score: 34.29.77\n",
      "\n",
      " actions= [[0.96858573 0.94639868]]\n",
      "1049795  Evaluations Remaining\n",
      "rewards= -0.5455917421257201\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049794  Evaluations Remaining\n",
      "rewards= 5.360778973385827\n",
      "Timestep 1\tScore: 4.82\tmin: 4.82\tmax: 4.82\n",
      " actions= [[1. 1.]]\n",
      "1049793  Evaluations Remaining\n",
      "rewards= 0.2376962370203648\n",
      "Timestep 2\tScore: 5.05\tmin: 5.05\tmax: 5.05\n",
      " actions= [[1. 1.]]\n",
      "1049792  Evaluations Remaining\n",
      "rewards= -0.01573671417856959\n",
      "Timestep 3\tScore: 5.04\tmin: 5.04\tmax: 5.04\n",
      " actions= [[1. 1.]]\n",
      "1049791  Evaluations Remaining\n",
      "rewards= 0.2676266770668958\n",
      "Episode 35\tScore: 5.30\tAverage Score: 21.02\n",
      "\n",
      " actions= [[0.9548772  0.99905157]]\n",
      "1049790  Evaluations Remaining\n",
      "rewards= 27.99062404957052\n",
      "\n",
      " actions= [[1.         0.87611803]]\n",
      "1049789  Evaluations Remaining\n",
      "rewards= 0.21778325274955845\n",
      "Timestep 1\tScore: 28.21\tmin: 28.21\tmax: 28.21\n",
      " actions= [[1. 1.]]\n",
      "1049788  Evaluations Remaining\n",
      "rewards= 43.001294118242114\n",
      "Timestep 2\tScore: 71.21\tmin: 71.21\tmax: 71.21\n",
      " actions= [[0. 0.]]\n",
      "1049787  Evaluations Remaining\n",
      "rewards= 0.10384596571246396\n",
      "Timestep 3\tScore: 71.31\tmin: 71.31\tmax: 71.31\n",
      " actions= [[1. 1.]]\n",
      "1049786  Evaluations Remaining\n",
      "rewards= 13.086728081498338\n",
      "Episode 36\tScore: 84.40\tAverage Score: 17.050\n",
      "\n",
      " actions= [[0.98959655 1.        ]]\n",
      "1049785  Evaluations Remaining\n",
      "rewards= 17.298338873990794\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049784  Evaluations Remaining\n",
      "rewards= 0.12390194381487563\n",
      "Timestep 1\tScore: 17.42\tmin: 17.42\tmax: 17.42\n",
      " actions= [[1. 1.]]\n",
      "1049783  Evaluations Remaining\n",
      "rewards= 0.20998157866010914\n",
      "Timestep 2\tScore: 17.63\tmin: 17.63\tmax: 17.63\n",
      " actions= [[0.         0.85612636]]\n",
      "1049782  Evaluations Remaining\n",
      "rewards= -0.12214492144674116\n",
      "Timestep 3\tScore: 17.51\tmin: 17.51\tmax: 17.51\n",
      " actions= [[1. 1.]]\n",
      "1049781  Evaluations Remaining\n",
      "rewards= -2.848728287275283\n",
      "Episode 37\tScore: 14.66\tAverage Score: 35.726\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049780  Evaluations Remaining\n",
      "rewards= 15.783666340118428\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049779  Evaluations Remaining\n",
      "rewards= -0.15844019188777425\n",
      "Timestep 1\tScore: 15.63\tmin: 15.63\tmax: 15.63\n",
      " actions= [[1. 1.]]\n",
      "1049778  Evaluations Remaining\n",
      "rewards= 0.14016712561827305\n",
      "Timestep 2\tScore: 15.77\tmin: 15.77\tmax: 15.77\n",
      " actions= [[1. 1.]]\n",
      "1049777  Evaluations Remaining\n",
      "rewards= 0.17050182679689563\n",
      "Timestep 3\tScore: 15.94\tmin: 15.94\tmax: 15.94\n",
      " actions= [[1. 1.]]\n",
      "1049776  Evaluations Remaining\n",
      "rewards= 0.11831567689222355\n",
      "Episode 38\tScore: 16.05\tAverage Score: 40.495\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049775  Evaluations Remaining\n",
      "rewards= 14.577705212232658\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049774  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 0.23030516561277414\n",
      "Timestep 1\tScore: 14.81\tmin: 14.81\tmax: 14.81\n",
      " actions= [[1. 1.]]\n",
      "1049773  Evaluations Remaining\n",
      "rewards= -0.07769751248751877\n",
      "Timestep 2\tScore: 14.73\tmin: 14.73\tmax: 14.73\n",
      " actions= [[1. 1.]]\n",
      "1049772  Evaluations Remaining\n",
      "rewards= 0.19824318469427293\n",
      "Timestep 3\tScore: 14.93\tmin: 14.93\tmax: 14.93\n",
      " actions= [[1. 1.]]\n",
      "1049771  Evaluations Remaining\n",
      "rewards= -0.12314560552191045\n",
      "Episode 39\tScore: 14.81\tAverage Score: 43.801\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049770  Evaluations Remaining\n",
      "rewards= 14.289113541442305\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049769  Evaluations Remaining\n",
      "rewards= -0.20249386939122527\n",
      "Timestep 1\tScore: 14.09\tmin: 14.09\tmax: 14.09\n",
      " actions= [[1. 1.]]\n",
      "1049768  Evaluations Remaining\n",
      "rewards= 0.1951775937013629\n",
      "Timestep 2\tScore: 14.28\tmin: 14.28\tmax: 14.28\n",
      " actions= [[1. 1.]]\n",
      "1049767  Evaluations Remaining\n",
      "rewards= 0.07667918449819977\n",
      "Timestep 3\tScore: 14.36\tmin: 14.36\tmax: 14.36\n",
      " actions= [[0.54631629 0.2667426 ]]\n",
      "1049766  Evaluations Remaining\n",
      "rewards= 0.0819116227451957\n",
      "Episode 40\tScore: 14.44\tAverage Score: 33.424\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049765  Evaluations Remaining\n",
      "rewards= 13.491208227564528\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049764  Evaluations Remaining\n",
      "rewards= -0.19921662028948983\n",
      "Timestep 1\tScore: 13.29\tmin: 13.29\tmax: 13.29\n",
      " actions= [[1. 1.]]\n",
      "1049763  Evaluations Remaining\n",
      "rewards= -0.036484208356180936\n",
      "Timestep 2\tScore: 13.26\tmin: 13.26\tmax: 13.26\n",
      " actions= [[0. 0.]]\n",
      "1049762  Evaluations Remaining\n",
      "rewards= 0.12900733759521632\n",
      "Timestep 3\tScore: 13.38\tmin: 13.38\tmax: 13.38\n",
      " actions= [[1. 1.]]\n",
      "1049761  Evaluations Remaining\n",
      "rewards= 13.651685808293013\n",
      "Episode 41\tScore: 27.04\tAverage Score: 37.654\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049760  Evaluations Remaining\n",
      "rewards= 14.210947529805077\n",
      "\n",
      " actions= [[0.59990983 0.        ]]\n",
      "1049759  Evaluations Remaining\n",
      "rewards= 0.1280984725548806\n",
      "Timestep 1\tScore: 14.34\tmin: 14.34\tmax: 14.34\n",
      " actions= [[1. 1.]]\n",
      "1049758  Evaluations Remaining\n",
      "rewards= 44.69116038411147\n",
      "Timestep 2\tScore: 59.03\tmin: 59.03\tmax: 59.03\n",
      " actions= [[1. 1.]]\n",
      "1049757  Evaluations Remaining\n",
      "rewards= 0.00835186154591927\n",
      "Timestep 3\tScore: 59.04\tmin: 59.04\tmax: 59.04\n",
      " actions= [[1. 1.]]\n",
      "1049756  Evaluations Remaining\n",
      "rewards= 0.14584878333037254\n",
      "Episode 42\tScore: 59.18\tAverage Score: 30.718\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049755  Evaluations Remaining\n",
      "rewards= 14.597255904253755\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049754  Evaluations Remaining\n",
      "rewards= -0.27150012712085836\n",
      "Timestep 1\tScore: 14.33\tmin: 14.33\tmax: 14.33\n",
      " actions= [[1. 1.]]\n",
      "1049753  Evaluations Remaining\n",
      "rewards= 0.0519820407810303\n",
      "Timestep 2\tScore: 14.38\tmin: 14.38\tmax: 14.38\n",
      " actions= [[1. 1.]]\n",
      "1049752  Evaluations Remaining\n",
      "rewards= 0.18695445970019176\n",
      "Timestep 3\tScore: 14.56\tmin: 14.56\tmax: 14.56\n",
      " actions= [[1. 1.]]\n",
      "1049751  Evaluations Remaining\n",
      "rewards= -0.16509688673954726\n",
      "Episode 43\tScore: 14.40\tAverage Score: 21.050\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049750  Evaluations Remaining\n",
      "rewards= 14.440334377880548\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049749  Evaluations Remaining\n",
      "rewards= -0.18393060216332868\n",
      "Timestep 1\tScore: 14.26\tmin: 14.26\tmax: 14.26\n",
      " actions= [[0. 0.]]\n",
      "1049748  Evaluations Remaining\n",
      "rewards= -0.07230989036755453\n",
      "Timestep 2\tScore: 14.18\tmin: 14.18\tmax: 14.18\n",
      " actions= [[1. 0.]]\n",
      "1049747  Evaluations Remaining\n",
      "rewards= 99.41359531632132\n",
      "Timestep 3\tScore: 113.60\tmin: 113.60\tmax: 113.60\n",
      " actions= [[1. 1.]]\n",
      "1049746  Evaluations Remaining\n",
      "rewards= 96.63353177380516\n",
      "Episode 44\tScore: 210.23\tAverage Score: 46.05.23\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049745  Evaluations Remaining\n",
      "rewards= 15.977579409546541\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049744  Evaluations Remaining\n",
      "rewards= 0.17455064645522844\n",
      "Timestep 1\tScore: 16.15\tmin: 16.15\tmax: 16.15\n",
      " actions= [[1. 1.]]\n",
      "1049743  Evaluations Remaining\n",
      "rewards= -0.10088624651805844\n",
      "Timestep 2\tScore: 16.05\tmin: 16.05\tmax: 16.05\n",
      " actions= [[1. 1.]]\n",
      "1049742  Evaluations Remaining\n",
      "rewards= -0.22960530410096247\n",
      "Timestep 3\tScore: 15.82\tmin: 15.82\tmax: 15.82\n",
      " actions= [[1. 1.]]\n",
      "1049741  Evaluations Remaining\n",
      "rewards= 0.03961195699412379\n",
      "Episode 45\tScore: 15.86\tAverage Score: 47.116\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049740  Evaluations Remaining\n",
      "rewards= 15.124950440936102\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049739  Evaluations Remaining\n",
      "rewards= -0.19068575470303184\n",
      "Timestep 1\tScore: 14.93\tmin: 14.93\tmax: 14.93\n",
      " actions= [[0.         0.71778426]]\n",
      "1049738  Evaluations Remaining\n",
      "rewards= 0.18437928974970808\n",
      "Timestep 2\tScore: 15.12\tmin: 15.12\tmax: 15.12\n",
      " actions= [[1. 1.]]\n",
      "1049737  Evaluations Remaining\n",
      "rewards= 34.825474616377264\n",
      "Timestep 3\tScore: 49.94\tmin: 49.94\tmax: 49.94\n",
      " actions= [[1. 1.]]\n",
      "1049736  Evaluations Remaining\n",
      "rewards= 0.2535783764103212\n",
      "Episode 46\tScore: 50.20\tAverage Score: 43.690\n",
      "\n",
      " actions= [[0.61337108 0.36410354]]\n",
      "1049735  Evaluations Remaining\n",
      "rewards= 8.05212893319272\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049734  Evaluations Remaining\n",
      "rewards= -0.6571260735305988\n",
      "Timestep 1\tScore: 7.40\tmin: 7.40\tmax: 7.40\n",
      " actions= [[1. 1.]]\n",
      "1049733  Evaluations Remaining\n",
      "rewards= 0.13440642792019952\n",
      "Timestep 2\tScore: 7.53\tmin: 7.53\tmax: 7.53\n",
      " actions= [[1. 1.]]\n",
      "1049732  Evaluations Remaining\n",
      "rewards= 0.2159151026641104\n",
      "Timestep 3\tScore: 7.75\tmin: 7.75\tmax: 7.75\n",
      " actions= [[0.         0.56060789]]\n",
      "1049731  Evaluations Remaining\n",
      "rewards= 0.19254966708186627\n",
      "Episode 47\tScore: 7.94\tAverage Score: 43.01\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049730  Evaluations Remaining\n",
      "rewards= 15.412775524723427\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049729  Evaluations Remaining\n",
      "rewards= 0.20512422814474052\n",
      "Timestep 1\tScore: 15.62\tmin: 15.62\tmax: 15.62\n",
      " actions= [[1. 1.]]\n",
      "1049728  Evaluations Remaining\n",
      "rewards= -0.1461597219799149\n",
      "Timestep 2\tScore: 15.47\tmin: 15.47\tmax: 15.47\n",
      " actions= [[0.54176201 0.        ]]\n",
      "1049727  Evaluations Remaining\n",
      "rewards= 0.2541049329682741\n",
      "Timestep 3\tScore: 15.73\tmin: 15.73\tmax: 15.73\n",
      " actions= [[1. 1.]]\n",
      "1049726  Evaluations Remaining\n",
      "rewards= 30.11711890411446\n",
      "Episode 48\tScore: 45.84\tAverage Score: 45.994\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049725  Evaluations Remaining\n",
      "rewards= 15.205033272077204\n",
      "\n",
      " actions= [[0. 1.]]\n",
      "1049724  Evaluations Remaining\n",
      "rewards= 0.19475868266523166\n",
      "Timestep 1\tScore: 15.40\tmin: 15.40\tmax: 15.40\n",
      " actions= [[1. 0.]]\n",
      "1049723  Evaluations Remaining\n",
      "rewards= 100.48352797448506\n",
      "Timestep 2\tScore: 115.88\tmin: 115.88\tmax: 115.88\n",
      " actions= [[1. 1.]]\n",
      "1049722  Evaluations Remaining\n",
      "rewards= 98.47039472196049\n",
      "Timestep 3\tScore: 214.35\tmin: 214.35\tmax: 214.35\n",
      " actions= [[1. 1.]]\n",
      "1049721  Evaluations Remaining\n",
      "rewards= 0.026968788516685382\n",
      "Episode 49\tScore: 214.38\tAverage Score: 65.95.38\n",
      "\n",
      " actions= [[0. 0.]]\n",
      "1049720  Evaluations Remaining\n",
      "rewards= 2.5092713828290245\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049719  Evaluations Remaining\n",
      "rewards= 12.639623537637029\n",
      "Timestep 1\tScore: 15.15\tmin: 15.15\tmax: 15.15\n",
      " actions= [[1. 1.]]\n",
      "1049718  Evaluations Remaining\n",
      "rewards= 0.03170809680435438\n",
      "Timestep 2\tScore: 15.18\tmin: 15.18\tmax: 15.18\n",
      " actions= [[1. 1.]]\n",
      "1049717  Evaluations Remaining\n",
      "rewards= -0.011582899568909788\n",
      "Timestep 3\tScore: 15.17\tmin: 15.17\tmax: 15.17\n",
      " actions= [[0.27011944 0.55173564]]\n",
      "1049716  Evaluations Remaining\n",
      "rewards= 0.2223740148443789\n",
      "Episode 50\tScore: 15.39\tAverage Score: 66.059\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049715  Evaluations Remaining\n",
      "rewards= 14.283975291156565\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049714  Evaluations Remaining\n",
      "rewards= 0.0853879498974095\n",
      "Timestep 1\tScore: 14.37\tmin: 14.37\tmax: 14.37\n",
      " actions= [[1. 1.]]\n",
      "1049713  Evaluations Remaining\n",
      "rewards= -0.17952360960063496\n",
      "Timestep 2\tScore: 14.19\tmin: 14.19\tmax: 14.19\n",
      " actions= [[1. 1.]]\n",
      "1049712  Evaluations Remaining\n",
      "rewards= 0.13678950915494648\n",
      "Timestep 3\tScore: 14.33\tmin: 14.33\tmax: 14.33\n",
      " actions= [[1. 1.]]\n",
      "1049711  Evaluations Remaining\n",
      "rewards= 0.1435129860548332\n",
      "Episode 51\tScore: 14.47\tAverage Score: 64.797\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049710  Evaluations Remaining\n",
      "rewards= 15.524220701436445\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049709  Evaluations Remaining\n",
      "rewards= -0.050229390823444575\n",
      "Timestep 1\tScore: 15.47\tmin: 15.47\tmax: 15.47\n",
      " actions= [[1. 1.]]\n",
      "1049708  Evaluations Remaining\n",
      "rewards= 0.06100199007691609\n",
      "Timestep 2\tScore: 15.53\tmin: 15.53\tmax: 15.53\n",
      " actions= [[1. 1.]]\n",
      "1049707  Evaluations Remaining\n",
      "rewards= 0.04045743917529343\n",
      "Timestep 3\tScore: 15.58\tmin: 15.58\tmax: 15.58\n",
      " actions= [[1. 1.]]\n",
      "1049706  Evaluations Remaining\n",
      "rewards= -0.14999281584092872\n",
      "Episode 52\tScore: 15.43\tAverage Score: 60.413\n",
      "\n",
      " actions= [[0.26699619 0.79861078]]\n",
      "1049705  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= -59.266640115196104\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049704  Evaluations Remaining\n",
      "rewards= 43.529965047461694\n",
      "Timestep 1\tScore: -15.74\tmin: -15.74\tmax: -15.74\n",
      " actions= [[1. 1.]]\n",
      "1049703  Evaluations Remaining\n",
      "rewards= -0.23731311460405724\n",
      "Timestep 2\tScore: -15.97\tmin: -15.97\tmax: -15.97\n",
      " actions= [[0. 0.]]\n",
      "1049702  Evaluations Remaining\n",
      "rewards= 0.1891061601233366\n",
      "Timestep 3\tScore: -15.78\tmin: -15.78\tmax: -15.78\n",
      " actions= [[1. 1.]]\n",
      "1049701  Evaluations Remaining\n",
      "rewards= 11.370467582186826\n",
      "Episode 53\tScore: -4.41\tAverage Score: 58.531\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049700  Evaluations Remaining\n",
      "rewards= 16.2622224987173\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049699  Evaluations Remaining\n",
      "rewards= 0.13983488644335074\n",
      "Timestep 1\tScore: 16.40\tmin: 16.40\tmax: 16.40\n",
      " actions= [[0. 0.]]\n",
      "1049698  Evaluations Remaining\n",
      "rewards= 0.2655825461902719\n",
      "Timestep 2\tScore: 16.67\tmin: 16.67\tmax: 16.67\n",
      " actions= [[1. 1.]]\n",
      "1049697  Evaluations Remaining\n",
      "rewards= 10.843800004251943\n",
      "Timestep 3\tScore: 27.51\tmin: 27.51\tmax: 27.51\n",
      " actions= [[0.6922968  0.47861592]]\n",
      "1049696  Evaluations Remaining\n",
      "rewards= -0.05388484903987267\n",
      "Episode 54\tScore: 27.46\tAverage Score: 40.266\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049695  Evaluations Remaining\n",
      "rewards= 15.979886037215099\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049694  Evaluations Remaining\n",
      "rewards= 0.16520342641475105\n",
      "Timestep 1\tScore: 16.15\tmin: 16.15\tmax: 16.15\n",
      " actions= [[1. 1.]]\n",
      "1049693  Evaluations Remaining\n",
      "rewards= -0.18544824374252888\n",
      "Timestep 2\tScore: 15.96\tmin: 15.96\tmax: 15.96\n",
      " actions= [[1. 1.]]\n",
      "1049692  Evaluations Remaining\n",
      "rewards= 0.22951580305261476\n",
      "Timestep 3\tScore: 16.19\tmin: 16.19\tmax: 16.19\n",
      " actions= [[0. 0.]]\n",
      "1049691  Evaluations Remaining\n",
      "rewards= 0.042816300093105664\n",
      "Episode 55\tScore: 16.23\tAverage Score: 40.293\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049690  Evaluations Remaining\n",
      "rewards= 13.701871436303815\n",
      "\n",
      " actions= [[0. 0.]]\n",
      "1049689  Evaluations Remaining\n",
      "rewards= -0.014447541470636871\n",
      "Timestep 1\tScore: 13.69\tmin: 13.69\tmax: 13.69\n",
      " actions= [[1. 1.]]\n",
      "1049688  Evaluations Remaining\n",
      "rewards= 12.557882890265953\n",
      "Timestep 2\tScore: 26.25\tmin: 26.25\tmax: 26.25\n",
      " actions= [[1. 1.]]\n",
      "1049687  Evaluations Remaining\n",
      "rewards= 0.17828732510964418\n",
      "Timestep 3\tScore: 26.42\tmin: 26.42\tmax: 26.42\n",
      " actions= [[1. 1.]]\n",
      "1049686  Evaluations Remaining\n",
      "rewards= -0.0741647194001267\n",
      "Episode 56\tScore: 26.35\tAverage Score: 37.915\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049685  Evaluations Remaining\n",
      "rewards= 13.933176883496712\n",
      "\n",
      " actions= [[0.05783999 0.68965434]]\n",
      "1049684  Evaluations Remaining\n",
      "rewards= 0.17241222940489598\n",
      "Timestep 1\tScore: 14.11\tmin: 14.11\tmax: 14.11\n",
      " actions= [[1. 1.]]\n",
      "1049683  Evaluations Remaining\n",
      "rewards= 34.171686925138566\n",
      "Timestep 2\tScore: 48.28\tmin: 48.28\tmax: 48.28\n",
      " actions= [[1. 1.]]\n",
      "1049682  Evaluations Remaining\n",
      "rewards= -0.2558887667952612\n",
      "Timestep 3\tScore: 48.02\tmin: 48.02\tmax: 48.02\n",
      " actions= [[1. 1.]]\n",
      "1049681  Evaluations Remaining\n",
      "rewards= -0.21319198528873384\n",
      "Episode 57\tScore: 47.81\tAverage Score: 41.891\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049680  Evaluations Remaining\n",
      "rewards= 14.432490046626345\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049679  Evaluations Remaining\n",
      "rewards= -0.01565462530457795\n",
      "Timestep 1\tScore: 14.42\tmin: 14.42\tmax: 14.42\n",
      " actions= [[1. 1.]]\n",
      "1049678  Evaluations Remaining\n",
      "rewards= -0.16862343093574594\n",
      "Timestep 2\tScore: 14.25\tmin: 14.25\tmax: 14.25\n",
      " actions= [[1. 1.]]\n",
      "1049677  Evaluations Remaining\n",
      "rewards= 0.16259848219330753\n",
      "Timestep 3\tScore: 14.41\tmin: 14.41\tmax: 14.41\n",
      " actions= [[1. 1.]]\n",
      "1049676  Evaluations Remaining\n",
      "rewards= -0.2096124900465055\n",
      "Episode 58\tScore: 14.20\tAverage Score: 38.730\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049675  Evaluations Remaining\n",
      "rewards= 14.083109119660255\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049674  Evaluations Remaining\n",
      "rewards= 0.053505453492748156\n",
      "Timestep 1\tScore: 14.14\tmin: 14.14\tmax: 14.14\n",
      " actions= [[1. 1.]]\n",
      "1049673  Evaluations Remaining\n",
      "rewards= 0.2236088629938049\n",
      "Timestep 2\tScore: 14.36\tmin: 14.36\tmax: 14.36\n",
      " actions= [[1. 1.]]\n",
      "1049672  Evaluations Remaining\n",
      "rewards= 0.05334541892015299\n",
      "Timestep 3\tScore: 14.41\tmin: 14.41\tmax: 14.41\n",
      " actions= [[0.01069843 0.33352931]]\n",
      "1049671  Evaluations Remaining\n",
      "rewards= -0.07324366893050982\n",
      "Episode 59\tScore: 14.34\tAverage Score: 18.734\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049670  Evaluations Remaining\n",
      "rewards= 15.302164242326363\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049669  Evaluations Remaining\n",
      "rewards= 0.016968532115568813\n",
      "Timestep 1\tScore: 15.32\tmin: 15.32\tmax: 15.32\n",
      " actions= [[1. 1.]]\n",
      "1049668  Evaluations Remaining\n",
      "rewards= -0.02934904195817145\n",
      "Timestep 2\tScore: 15.29\tmin: 15.29\tmax: 15.29\n",
      " actions= [[1. 1.]]\n",
      "1049667  Evaluations Remaining\n",
      "rewards= -0.0554918408129077\n",
      "Timestep 3\tScore: 15.23\tmin: 15.23\tmax: 15.23\n",
      " actions= [[1. 1.]]\n",
      "1049666  Evaluations Remaining\n",
      "rewards= -0.22789225041821926\n",
      "Episode 60\tScore: 15.01\tAverage Score: 18.691\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049665  Evaluations Remaining\n",
      "rewards= 14.487205114065109\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049664  Evaluations Remaining\n",
      "rewards= 0.18162194699366152\n",
      "Timestep 1\tScore: 14.67\tmin: 14.67\tmax: 14.67\n",
      " actions= [[1. 1.]]\n",
      "1049663  Evaluations Remaining\n",
      "rewards= 0.037456917439782966\n",
      "Timestep 2\tScore: 14.71\tmin: 14.71\tmax: 14.71\n",
      " actions= [[1. 1.]]\n",
      "1049662  Evaluations Remaining\n",
      "rewards= -0.170751259349756\n",
      "Timestep 3\tScore: 14.54\tmin: 14.54\tmax: 14.54\n",
      " actions= [[1. 1.]]\n",
      "1049661  Evaluations Remaining\n",
      "rewards= -0.1479591185278455\n",
      "Episode 61\tScore: 14.39\tAverage Score: 18.689\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049660  Evaluations Remaining\n",
      "rewards= 13.685610563433416\n",
      "\n",
      " actions= [[0. 0.]]\n",
      "1049659  Evaluations Remaining\n",
      "rewards= 0.15550089263708644\n",
      "Timestep 1\tScore: 13.84\tmin: 13.84\tmax: 13.84\n",
      " actions= [[1. 1.]]\n",
      "1049658  Evaluations Remaining\n",
      "rewards= 11.223833529082968\n",
      "Timestep 2\tScore: 25.06\tmin: 25.06\tmax: 25.06\n",
      " actions= [[1. 1.]]\n",
      "1049657  Evaluations Remaining\n",
      "rewards= 0.15102059307479143\n",
      "Timestep 3\tScore: 25.22\tmin: 25.22\tmax: 25.22\n",
      " actions= [[0.06264476 0.7921007 ]]\n",
      "1049656  Evaluations Remaining\n",
      "rewards= 0.12812327545594604\n",
      "Episode 62\tScore: 25.34\tAverage Score: 19.674\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049655  Evaluations Remaining\n",
      "rewards= 14.778050312734814\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049654  Evaluations Remaining\n",
      "rewards= -0.08875885584614718\n",
      "Timestep 1\tScore: 14.69\tmin: 14.69\tmax: 14.69\n",
      " actions= [[0.         0.50238509]]\n",
      "1049653  Evaluations Remaining\n",
      "rewards= 0.15296535578105086\n",
      "Timestep 2\tScore: 14.84\tmin: 14.84\tmax: 14.84\n",
      " actions= [[1. 1.]]\n",
      "1049652  Evaluations Remaining\n",
      "rewards= 48.26047102673434\n",
      "Timestep 3\tScore: 63.10\tmin: 63.10\tmax: 63.10\n",
      " actions= [[0.72652648 0.15986201]]\n",
      "1049651  Evaluations Remaining\n",
      "rewards= -0.22980935228887134\n",
      "Episode 63\tScore: 62.87\tAverage Score: 26.407\n",
      "\n",
      " actions= [[1. 0.]]\n",
      "1049650  Evaluations Remaining\n",
      "rewards= 106.43574180589353\n",
      "\n",
      " actions= [[0.69921191 1.        ]]\n",
      "1049649  Evaluations Remaining\n",
      "rewards= 104.03375252958654\n",
      "Timestep 1\tScore: 210.47\tmin: 210.47\tmax: 210.47\n",
      " actions= [[1. 1.]]\n",
      "1049648  Evaluations Remaining\n",
      "rewards= 3.692145211266294\n",
      "Timestep 2\tScore: 214.16\tmin: 214.16\tmax: 214.16\n",
      " actions= [[1. 1.]]\n",
      "1049647  Evaluations Remaining\n",
      "rewards= 0.006629940343054752\n",
      "Timestep 3\tScore: 214.17\tmin: 214.17\tmax: 214.17\n",
      " actions= [[1. 1.]]\n",
      "1049646  Evaluations Remaining\n",
      "rewards= 0.2375654773658078\n",
      "Episode 64\tScore: 214.41\tAverage Score: 45.09.41\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049645  Evaluations Remaining\n",
      "rewards= 15.741711356078106\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049644  Evaluations Remaining\n",
      "rewards= 0.1961250999160682\n",
      "Timestep 1\tScore: 15.94\tmin: 15.94\tmax: 15.94\n",
      " actions= [[1. 1.]]\n",
      "1049643  Evaluations Remaining\n",
      "rewards= 0.19358701658273691\n",
      "Timestep 2\tScore: 16.13\tmin: 16.13\tmax: 16.13\n",
      " actions= [[0.         0.20766377]]\n",
      "1049642  Evaluations Remaining\n",
      "rewards= 0.12758192094817833\n",
      "Timestep 3\tScore: 16.26\tmin: 16.26\tmax: 16.26\n",
      " actions= [[1. 1.]]\n",
      "1049641  Evaluations Remaining\n",
      "rewards= -73.89713126777539\n",
      "Episode 65\tScore: -57.64\tAverage Score: 37.71.64\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049640  Evaluations Remaining\n",
      "rewards= 13.994317605887588\n",
      "\n",
      " actions= [[1.        0.4637211]]\n",
      "1049639  Evaluations Remaining\n",
      "rewards= -0.21469460934027929\n",
      "Timestep 1\tScore: 13.78\tmin: 13.78\tmax: 13.78\n",
      " actions= [[1. 1.]]\n",
      "1049638  Evaluations Remaining\n",
      "rewards= 25.24180104779313\n",
      "Timestep 2\tScore: 39.02\tmin: 39.02\tmax: 39.02\n",
      " actions= [[1. 1.]]\n",
      "1049637  Evaluations Remaining\n",
      "rewards= 0.11866241615865736\n",
      "Timestep 3\tScore: 39.14\tmin: 39.14\tmax: 39.14\n",
      " actions= [[1. 1.]]\n",
      "1049636  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 0.20130842051144304\n",
      "Episode 66\tScore: 39.34\tAverage Score: 39.014\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049635  Evaluations Remaining\n",
      "rewards= 15.991607163866972\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049634  Evaluations Remaining\n",
      "rewards= -0.16889190773039298\n",
      "Timestep 1\tScore: 15.82\tmin: 15.82\tmax: 15.82\n",
      " actions= [[0. 0.]]\n",
      "1049633  Evaluations Remaining\n",
      "rewards= 0.12149180190154718\n",
      "Timestep 2\tScore: 15.94\tmin: 15.94\tmax: 15.94\n",
      " actions= [[1. 1.]]\n",
      "1049632  Evaluations Remaining\n",
      "rewards= 12.589798840189891\n",
      "Timestep 3\tScore: 28.53\tmin: 28.53\tmax: 28.53\n",
      " actions= [[1. 1.]]\n",
      "1049631  Evaluations Remaining\n",
      "rewards= 0.11033516333528404\n",
      "Episode 67\tScore: 28.64\tAverage Score: 37.094\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049630  Evaluations Remaining\n",
      "rewards= 15.757520135498876\n",
      "\n",
      " actions= [[0.         0.92606324]]\n",
      "1049629  Evaluations Remaining\n",
      "rewards= -0.19670715653324766\n",
      "Timestep 1\tScore: 15.56\tmin: 15.56\tmax: 15.56\n",
      " actions= [[1. 1.]]\n",
      "1049628  Evaluations Remaining\n",
      "rewards= 44.18142786209143\n",
      "Timestep 2\tScore: 59.74\tmin: 59.74\tmax: 59.74\n",
      " actions= [[0. 0.]]\n",
      "1049627  Evaluations Remaining\n",
      "rewards= -0.19700690222640915\n",
      "Timestep 3\tScore: 59.55\tmin: 59.55\tmax: 59.55\n",
      " actions= [[0.         0.97646787]]\n",
      "1049626  Evaluations Remaining\n",
      "rewards= 88.15992515326323\n",
      "Episode 68\tScore: 147.71\tAverage Score: 50.44.71\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049625  Evaluations Remaining\n",
      "rewards= 13.545335581493253\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049624  Evaluations Remaining\n",
      "rewards= 0.20740822990519225\n",
      "Timestep 1\tScore: 13.75\tmin: 13.75\tmax: 13.75\n",
      " actions= [[1. 1.]]\n",
      "1049623  Evaluations Remaining\n",
      "rewards= -0.23758533341405697\n",
      "Timestep 2\tScore: 13.52\tmin: 13.52\tmax: 13.52\n",
      " actions= [[1. 1.]]\n",
      "1049622  Evaluations Remaining\n",
      "rewards= -0.14830520856482643\n",
      "Timestep 3\tScore: 13.37\tmin: 13.37\tmax: 13.37\n",
      " actions= [[1. 1.]]\n",
      "1049621  Evaluations Remaining\n",
      "rewards= -0.06210194765868282\n",
      "Episode 69\tScore: 13.30\tAverage Score: 50.340\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049620  Evaluations Remaining\n",
      "rewards= 16.466995749708246\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049619  Evaluations Remaining\n",
      "rewards= -0.19966815184309494\n",
      "Timestep 1\tScore: 16.27\tmin: 16.27\tmax: 16.27\n",
      " actions= [[1. 1.]]\n",
      "1049618  Evaluations Remaining\n",
      "rewards= 0.1315408113451504\n",
      "Timestep 2\tScore: 16.40\tmin: 16.40\tmax: 16.40\n",
      " actions= [[1. 1.]]\n",
      "1049617  Evaluations Remaining\n",
      "rewards= 0.03911794853697126\n",
      "Timestep 3\tScore: 16.44\tmin: 16.44\tmax: 16.44\n",
      " actions= [[1. 1.]]\n",
      "1049616  Evaluations Remaining\n",
      "rewards= -0.16683545326478422\n",
      "Episode 70\tScore: 16.27\tAverage Score: 50.467\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049615  Evaluations Remaining\n",
      "rewards= 14.613292894448042\n",
      "\n",
      " actions= [[0. 0.]]\n",
      "1049614  Evaluations Remaining\n",
      "rewards= 0.016868058381929174\n",
      "Timestep 1\tScore: 14.63\tmin: 14.63\tmax: 14.63\n",
      " actions= [[1. 1.]]\n",
      "1049613  Evaluations Remaining\n",
      "rewards= 11.704005146551973\n",
      "Timestep 2\tScore: 26.33\tmin: 26.33\tmax: 26.33\n",
      " actions= [[1. 1.]]\n",
      "1049612  Evaluations Remaining\n",
      "rewards= 0.20557412854812807\n",
      "Timestep 3\tScore: 26.54\tmin: 26.54\tmax: 26.54\n",
      " actions= [[1. 1.]]\n",
      "1049611  Evaluations Remaining\n",
      "rewards= 0.08078870276920025\n",
      "Episode 71\tScore: 26.62\tAverage Score: 51.692\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049610  Evaluations Remaining\n",
      "rewards= 16.33538015803715\n",
      "\n",
      " actions= [[0. 1.]]\n",
      "1049609  Evaluations Remaining\n",
      "rewards= 0.030369086218837715\n",
      "Timestep 1\tScore: 16.37\tmin: 16.37\tmax: 16.37\n",
      " actions= [[1. 1.]]\n",
      "1049608  Evaluations Remaining\n",
      "rewards= 103.02819262093342\n",
      "Timestep 2\tScore: 119.39\tmin: 119.39\tmax: 119.39\n",
      " actions= [[1. 1.]]\n",
      "1049607  Evaluations Remaining\n",
      "rewards= 0.02119079909620547\n",
      "Timestep 3\tScore: 119.42\tmin: 119.42\tmax: 119.42\n",
      " actions= [[1. 1.]]\n",
      "1049606  Evaluations Remaining\n",
      "rewards= -0.26434720798620015\n",
      "Episode 72\tScore: 119.15\tAverage Score: 61.07.15\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049605  Evaluations Remaining\n",
      "rewards= 15.58745534895097\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049604  Evaluations Remaining\n",
      "rewards= -0.06856936775554168\n",
      "Timestep 1\tScore: 15.52\tmin: 15.52\tmax: 15.52\n",
      " actions= [[1. 1.]]\n",
      "1049603  Evaluations Remaining\n",
      "rewards= -0.18291988923384306\n",
      "Timestep 2\tScore: 15.34\tmin: 15.34\tmax: 15.34\n",
      " actions= [[1. 1.]]\n",
      "1049602  Evaluations Remaining\n",
      "rewards= -0.24774501767850898\n",
      "Timestep 3\tScore: 15.09\tmin: 15.09\tmax: 15.09\n",
      " actions= [[1. 1.]]\n",
      "1049601  Evaluations Remaining\n",
      "rewards= 0.16843825339530039\n",
      "Episode 73\tScore: 15.26\tAverage Score: 56.316\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049600  Evaluations Remaining\n",
      "rewards= 13.82838334908623\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049599  Evaluations Remaining\n",
      "rewards= -0.2388369272475348\n",
      "Timestep 1\tScore: 13.59\tmin: 13.59\tmax: 13.59\n",
      " actions= [[1. 1.]]\n",
      "1049598  Evaluations Remaining\n",
      "rewards= 0.26466231019844466\n",
      "Timestep 2\tScore: 13.85\tmin: 13.85\tmax: 13.85\n",
      " actions= [[1. 1.]]\n",
      "1049597  Evaluations Remaining\n",
      "rewards= -0.1730010371874564\n",
      "Timestep 3\tScore: 13.68\tmin: 13.68\tmax: 13.68\n",
      " actions= [[1. 1.]]\n",
      "1049596  Evaluations Remaining\n",
      "rewards= -0.1178088398909578\n",
      "Episode 74\tScore: 13.56\tAverage Score: 36.226\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049595  Evaluations Remaining\n",
      "rewards= 15.36297398965111\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049594  Evaluations Remaining\n",
      "rewards= 0.13805143111333162\n",
      "Timestep 1\tScore: 15.50\tmin: 15.50\tmax: 15.50\n",
      " actions= [[1. 1.]]\n",
      "1049593  Evaluations Remaining\n",
      "rewards= 0.1792034781504448\n",
      "Timestep 2\tScore: 15.68\tmin: 15.68\tmax: 15.68\n",
      " actions= [[1. 1.]]\n",
      "1049592  Evaluations Remaining\n",
      "rewards= -0.24789498780525543\n",
      "Timestep 3\tScore: 15.43\tmin: 15.43\tmax: 15.43\n",
      " actions= [[0.         0.60161771]]\n",
      "1049591  Evaluations Remaining\n",
      "rewards= -0.08582575632738543\n",
      "Episode 75\tScore: 15.35\tAverage Score: 43.525\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049590  Evaluations Remaining\n",
      "rewards= 15.380174251922114\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049589  Evaluations Remaining\n",
      "rewards= 0.034989944058180455\n",
      "Timestep 1\tScore: 15.42\tmin: 15.42\tmax: 15.42\n",
      " actions= [[1. 1.]]\n",
      "1049588  Evaluations Remaining\n",
      "rewards= 0.20501397158740797\n",
      "Timestep 2\tScore: 15.62\tmin: 15.62\tmax: 15.62\n",
      " actions= [[1. 1.]]\n",
      "1049587  Evaluations Remaining\n",
      "rewards= 0.11964442476172632\n",
      "Timestep 3\tScore: 15.74\tmin: 15.74\tmax: 15.74\n",
      " actions= [[1. 1.]]\n",
      "1049586  Evaluations Remaining\n",
      "rewards= 0.1987604740398914\n",
      "Episode 76\tScore: 15.94\tAverage Score: 41.184\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049585  Evaluations Remaining\n",
      "rewards= 15.940405962038538\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049584  Evaluations Remaining\n",
      "rewards= 0.21213841025968838\n",
      "Timestep 1\tScore: 16.15\tmin: 16.15\tmax: 16.15\n",
      " actions= [[1. 1.]]\n",
      "1049583  Evaluations Remaining\n",
      "rewards= 0.07531269990188871\n",
      "Timestep 2\tScore: 16.23\tmin: 16.23\tmax: 16.23\n",
      " actions= [[1. 1.]]\n",
      "1049582  Evaluations Remaining\n",
      "rewards= 0.26793065409617656\n",
      "Timestep 3\tScore: 16.50\tmin: 16.50\tmax: 16.50\n",
      " actions= [[0. 1.]]\n",
      "1049581  Evaluations Remaining\n",
      "rewards= 0.16244861277321876\n",
      "Episode 77\tScore: 16.66\tAverage Score: 39.986\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049580  Evaluations Remaining\n",
      "rewards= 15.48354661550006\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049579  Evaluations Remaining\n",
      "rewards= 0.020963105390118475\n",
      "Timestep 1\tScore: 15.50\tmin: 15.50\tmax: 15.50\n",
      " actions= [[1. 1.]]\n",
      "1049578  Evaluations Remaining\n",
      "rewards= 0.2133082255222556\n",
      "Timestep 2\tScore: 15.72\tmin: 15.72\tmax: 15.72\n",
      " actions= [[1. 1.]]\n",
      "1049577  Evaluations Remaining\n",
      "rewards= 0.07867468891717788\n",
      "Timestep 3\tScore: 15.80\tmin: 15.80\tmax: 15.80\n",
      " actions= [[1. 1.]]\n",
      "1049576  Evaluations Remaining\n",
      "rewards= 0.2706516025550658\n",
      "Episode 78\tScore: 16.07\tAverage Score: 26.827\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049575  Evaluations Remaining\n",
      "rewards= 14.393345778535576\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049574  Evaluations Remaining\n",
      "rewards= -0.056111700106098006\n",
      "Timestep 1\tScore: 14.34\tmin: 14.34\tmax: 14.34\n",
      " actions= [[1. 1.]]\n",
      "1049573  Evaluations Remaining\n",
      "rewards= -0.1657103200667449\n",
      "Timestep 2\tScore: 14.17\tmin: 14.17\tmax: 14.17\n",
      " actions= [[1. 1.]]\n",
      "1049572  Evaluations Remaining\n",
      "rewards= 0.1968714940426728\n",
      "Timestep 3\tScore: 14.37\tmin: 14.37\tmax: 14.37\n",
      " actions= [[1. 1.]]\n",
      "1049571  Evaluations Remaining\n",
      "rewards= 0.22775077773974894\n",
      "Episode 79\tScore: 14.60\tAverage Score: 26.950\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049570  Evaluations Remaining\n",
      "rewards= 13.945348633535408\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049569  Evaluations Remaining\n",
      "rewards= 0.16548710002997824\n",
      "Timestep 1\tScore: 14.11\tmin: 14.11\tmax: 14.11\n",
      " actions= [[1. 1.]]\n",
      "1049568  Evaluations Remaining\n",
      "rewards= 0.1568691018621009\n",
      "Timestep 2\tScore: 14.27\tmin: 14.27\tmax: 14.27\n",
      " actions= [[1. 1.]]\n",
      "1049567  Evaluations Remaining\n",
      "rewards= 0.05364964710746278\n",
      "Timestep 3\tScore: 14.32\tmin: 14.32\tmax: 14.32\n",
      " actions= [[1. 1.]]\n",
      "1049566  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 0.08004766484834569\n",
      "Episode 80\tScore: 14.40\tAverage Score: 26.760\n",
      "\n",
      " actions= [[0.16886895 0.        ]]\n",
      "1049565  Evaluations Remaining\n",
      "rewards= 2.681516698637265\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049564  Evaluations Remaining\n",
      "rewards= 4.153377980981684\n",
      "Timestep 1\tScore: 6.83\tmin: 6.83\tmax: 6.83\n",
      " actions= [[1. 1.]]\n",
      "1049563  Evaluations Remaining\n",
      "rewards= 0.23525969534830526\n",
      "Timestep 2\tScore: 7.07\tmin: 7.07\tmax: 7.07\n",
      " actions= [[1. 1.]]\n",
      "1049562  Evaluations Remaining\n",
      "rewards= -0.06152960682656028\n",
      "Timestep 3\tScore: 7.01\tmin: 7.01\tmax: 7.01\n",
      " actions= [[0. 0.]]\n",
      "1049561  Evaluations Remaining\n",
      "rewards= 0.1613084423568818\n",
      "Episode 81\tScore: 7.17\tAverage Score: 24.81\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049560  Evaluations Remaining\n",
      "rewards= 13.682740103053614\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049559  Evaluations Remaining\n",
      "rewards= -0.09970713888733496\n",
      "Timestep 1\tScore: 13.58\tmin: 13.58\tmax: 13.58\n",
      " actions= [[1. 1.]]\n",
      "1049558  Evaluations Remaining\n",
      "rewards= -0.21271409311202794\n",
      "Timestep 2\tScore: 13.37\tmin: 13.37\tmax: 13.37\n",
      " actions= [[1. 1.]]\n",
      "1049557  Evaluations Remaining\n",
      "rewards= 0.20847782915453816\n",
      "Timestep 3\tScore: 13.58\tmin: 13.58\tmax: 13.58\n",
      " actions= [[1. 1.]]\n",
      "1049556  Evaluations Remaining\n",
      "rewards= -0.09879068461602891\n",
      "Episode 82\tScore: 13.48\tAverage Score: 14.258\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049555  Evaluations Remaining\n",
      "rewards= 14.361465248722167\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049554  Evaluations Remaining\n",
      "rewards= 0.06606773641762542\n",
      "Timestep 1\tScore: 14.43\tmin: 14.43\tmax: 14.43\n",
      " actions= [[1. 1.]]\n",
      "1049553  Evaluations Remaining\n",
      "rewards= 0.2444554278909581\n",
      "Timestep 2\tScore: 14.67\tmin: 14.67\tmax: 14.67\n",
      " actions= [[1. 1.]]\n",
      "1049552  Evaluations Remaining\n",
      "rewards= -0.17398982615115344\n",
      "Timestep 3\tScore: 14.50\tmin: 14.50\tmax: 14.50\n",
      " actions= [[1. 1.]]\n",
      "1049551  Evaluations Remaining\n",
      "rewards= 0.1754661696334181\n",
      "Episode 83\tScore: 14.67\tAverage Score: 14.197\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049550  Evaluations Remaining\n",
      "rewards= 14.476700665015217\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049549  Evaluations Remaining\n",
      "rewards= -0.012676936062025579\n",
      "Timestep 1\tScore: 14.46\tmin: 14.46\tmax: 14.46\n",
      " actions= [[0. 1.]]\n",
      "1049548  Evaluations Remaining\n",
      "rewards= -0.24544238696218024\n",
      "Timestep 2\tScore: 14.22\tmin: 14.22\tmax: 14.22\n",
      " actions= [[1. 1.]]\n",
      "1049547  Evaluations Remaining\n",
      "rewards= 89.18398177104667\n",
      "Timestep 3\tScore: 103.40\tmin: 103.40\tmax: 103.40\n",
      " actions= [[1. 1.]]\n",
      "1049546  Evaluations Remaining\n",
      "rewards= -0.14438849562516287\n",
      "Episode 84\tScore: 103.26\tAverage Score: 23.16.26\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049545  Evaluations Remaining\n",
      "rewards= 15.39667534704698\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049544  Evaluations Remaining\n",
      "rewards= 0.15652110230943084\n",
      "Timestep 1\tScore: 15.55\tmin: 15.55\tmax: 15.55\n",
      " actions= [[1. 1.]]\n",
      "1049543  Evaluations Remaining\n",
      "rewards= -0.26201753414983386\n",
      "Timestep 2\tScore: 15.29\tmin: 15.29\tmax: 15.29\n",
      " actions= [[1. 1.]]\n",
      "1049542  Evaluations Remaining\n",
      "rewards= 0.03125506396493938\n",
      "Timestep 3\tScore: 15.32\tmin: 15.32\tmax: 15.32\n",
      " actions= [[1. 1.]]\n",
      "1049541  Evaluations Remaining\n",
      "rewards= 0.055636663416139154\n",
      "Episode 85\tScore: 15.38\tAverage Score: 23.168\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049540  Evaluations Remaining\n",
      "rewards= 15.600090206958464\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049539  Evaluations Remaining\n",
      "rewards= -0.12452765621557083\n",
      "Timestep 1\tScore: 15.48\tmin: 15.48\tmax: 15.48\n",
      " actions= [[1. 1.]]\n",
      "1049538  Evaluations Remaining\n",
      "rewards= -0.20755288293660135\n",
      "Timestep 2\tScore: 15.27\tmin: 15.27\tmax: 15.27\n",
      " actions= [[1. 1.]]\n",
      "1049537  Evaluations Remaining\n",
      "rewards= 0.24130623646802052\n",
      "Timestep 3\tScore: 15.51\tmin: 15.51\tmax: 15.51\n",
      " actions= [[1. 1.]]\n",
      "1049536  Evaluations Remaining\n",
      "rewards= -0.2077865100369478\n",
      "Episode 86\tScore: 15.30\tAverage Score: 23.100\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049535  Evaluations Remaining\n",
      "rewards= 15.71399279754433\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049534  Evaluations Remaining\n",
      "rewards= -0.2247542288802471\n",
      "Timestep 1\tScore: 15.49\tmin: 15.49\tmax: 15.49\n",
      " actions= [[1. 1.]]\n",
      "1049533  Evaluations Remaining\n",
      "rewards= -0.14616489584994818\n",
      "Timestep 2\tScore: 15.34\tmin: 15.34\tmax: 15.34\n",
      " actions= [[1. 1.]]\n",
      "1049532  Evaluations Remaining\n",
      "rewards= -0.22034992541358012\n",
      "Timestep 3\tScore: 15.12\tmin: 15.12\tmax: 15.12\n",
      " actions= [[1. 1.]]\n",
      "1049531  Evaluations Remaining\n",
      "rewards= -0.042730358547798275\n",
      "Episode 87\tScore: 15.08\tAverage Score: 22.948\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049530  Evaluations Remaining\n",
      "rewards= 14.399238718191908\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049529  Evaluations Remaining\n",
      "rewards= -0.13899250028884014\n",
      "Timestep 1\tScore: 14.26\tmin: 14.26\tmax: 14.26\n",
      " actions= [[1. 1.]]\n",
      "1049528  Evaluations Remaining\n",
      "rewards= -0.09833777037912217\n",
      "Timestep 2\tScore: 14.16\tmin: 14.16\tmax: 14.16\n",
      " actions= [[0. 0.]]\n",
      "1049527  Evaluations Remaining\n",
      "rewards= -0.262486738784971\n",
      "Timestep 3\tScore: 13.90\tmin: 13.90\tmax: 13.90\n",
      " actions= [[1. 1.]]\n",
      "1049526  Evaluations Remaining\n",
      "rewards= 11.676967649327176\n",
      "Episode 88\tScore: 25.58\tAverage Score: 23.898\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049525  Evaluations Remaining\n",
      "rewards= 15.486745861534791\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049524  Evaluations Remaining\n",
      "rewards= 0.007453480539622248\n",
      "Timestep 1\tScore: 15.49\tmin: 15.49\tmax: 15.49\n",
      " actions= [[1. 1.]]\n",
      "1049523  Evaluations Remaining\n",
      "rewards= -0.1720088455886284\n",
      "Timestep 2\tScore: 15.32\tmin: 15.32\tmax: 15.32\n",
      " actions= [[1. 1.]]\n",
      "1049522  Evaluations Remaining\n",
      "rewards= 0.09393625333436617\n",
      "Timestep 3\tScore: 15.42\tmin: 15.42\tmax: 15.42\n",
      " actions= [[1. 1.]]\n",
      "1049521  Evaluations Remaining\n",
      "rewards= 0.05968979914279782\n",
      "Episode 89\tScore: 15.48\tAverage Score: 23.988\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049520  Evaluations Remaining\n",
      "rewards= 16.31115674301555\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049519  Evaluations Remaining\n",
      "rewards= 0.1445104922535303\n",
      "Timestep 1\tScore: 16.46\tmin: 16.46\tmax: 16.46\n",
      " actions= [[1. 1.]]\n",
      "1049518  Evaluations Remaining\n",
      "rewards= -0.0936518847985428\n",
      "Timestep 2\tScore: 16.36\tmin: 16.36\tmax: 16.36\n",
      " actions= [[1. 1.]]\n",
      "1049517  Evaluations Remaining\n",
      "rewards= -0.2065201850665077\n",
      "Timestep 3\tScore: 16.16\tmin: 16.16\tmax: 16.16\n",
      " actions= [[1. 1.]]\n",
      "1049516  Evaluations Remaining\n",
      "rewards= 0.07622063999862316\n",
      "Episode 90\tScore: 16.23\tAverage Score: 24.163\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049515  Evaluations Remaining\n",
      "rewards= 13.621494312792747\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049514  Evaluations Remaining\n",
      "rewards= -0.1431281698622926\n",
      "Timestep 1\tScore: 13.48\tmin: 13.48\tmax: 13.48\n",
      " actions= [[1. 1.]]\n",
      "1049513  Evaluations Remaining\n",
      "rewards= 0.24339593688510552\n",
      "Timestep 2\tScore: 13.72\tmin: 13.72\tmax: 13.72\n",
      " actions= [[1. 1.]]\n",
      "1049512  Evaluations Remaining\n",
      "rewards= -0.26475313500073616\n",
      "Timestep 3\tScore: 13.46\tmin: 13.46\tmax: 13.46\n",
      " actions= [[0.         0.92468235]]\n",
      "1049511  Evaluations Remaining\n",
      "rewards= -0.1972536740442159\n",
      "Episode 91\tScore: 13.26\tAverage Score: 24.776\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049510  Evaluations Remaining\n",
      "rewards= 15.043679054080624\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049509  Evaluations Remaining\n",
      "rewards= 0.045087915201237116\n",
      "Timestep 1\tScore: 15.09\tmin: 15.09\tmax: 15.09\n",
      " actions= [[1. 1.]]\n",
      "1049508  Evaluations Remaining\n",
      "rewards= 0.011626797339652661\n",
      "Timestep 2\tScore: 15.10\tmin: 15.10\tmax: 15.10\n",
      " actions= [[1. 1.]]\n",
      "1049507  Evaluations Remaining\n",
      "rewards= -0.1435771518715918\n",
      "Timestep 3\tScore: 14.96\tmin: 14.96\tmax: 14.96\n",
      " actions= [[1. 1.]]\n",
      "1049506  Evaluations Remaining\n",
      "rewards= -0.14228436994745186\n",
      "Episode 92\tScore: 14.81\tAverage Score: 24.901\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049505  Evaluations Remaining\n",
      "rewards= 15.633475375478175\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049504  Evaluations Remaining\n",
      "rewards= -0.03116586433657753\n",
      "Timestep 1\tScore: 15.60\tmin: 15.60\tmax: 15.60\n",
      " actions= [[1. 1.]]\n",
      "1049503  Evaluations Remaining\n",
      "rewards= 0.05839851326690537\n",
      "Timestep 2\tScore: 15.66\tmin: 15.66\tmax: 15.66\n",
      " actions= [[1. 1.]]\n",
      "1049502  Evaluations Remaining\n",
      "rewards= -0.015280192578450702\n",
      "Timestep 3\tScore: 15.65\tmin: 15.65\tmax: 15.65\n",
      " actions= [[1. 1.]]\n",
      "1049501  Evaluations Remaining\n",
      "rewards= 0.12519283340891452\n",
      "Episode 93\tScore: 15.77\tAverage Score: 25.017\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049500  Evaluations Remaining\n",
      "rewards= 14.484136164606259\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049499  Evaluations Remaining\n",
      "rewards= -0.1273632135716185\n",
      "Timestep 1\tScore: 14.36\tmin: 14.36\tmax: 14.36\n",
      " actions= [[1. 1.]]\n",
      "1049498  Evaluations Remaining\n",
      "rewards= 0.2084986040866923\n",
      "Timestep 2\tScore: 14.57\tmin: 14.57\tmax: 14.57\n",
      " actions= [[1. 1.]]\n",
      "1049497  Evaluations Remaining\n",
      "rewards= -0.00011400796262028834\n",
      "Timestep 3\tScore: 14.57\tmin: 14.57\tmax: 14.57\n",
      " actions= [[1. 1.]]\n",
      "1049496  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= -0.15459451587267958\n",
      "Episode 94\tScore: 14.41\tAverage Score: 16.131\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049495  Evaluations Remaining\n",
      "rewards= 15.779009057943787\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049494  Evaluations Remaining\n",
      "rewards= -0.2671468748974588\n",
      "Timestep 1\tScore: 15.51\tmin: 15.51\tmax: 15.51\n",
      " actions= [[0.         0.42391595]]\n",
      "1049493  Evaluations Remaining\n",
      "rewards= -0.1989956660116703\n",
      "Timestep 2\tScore: 15.31\tmin: 15.31\tmax: 15.31\n",
      " actions= [[1. 1.]]\n",
      "1049492  Evaluations Remaining\n",
      "rewards= 26.92004942806731\n",
      "Timestep 3\tScore: 42.23\tmin: 42.23\tmax: 42.23\n",
      " actions= [[1. 1.]]\n",
      "1049491  Evaluations Remaining\n",
      "rewards= 0.13781752829644534\n",
      "Episode 95\tScore: 42.37\tAverage Score: 18.837\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049490  Evaluations Remaining\n",
      "rewards= 16.123289516089574\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049489  Evaluations Remaining\n",
      "rewards= -0.024954038928810096\n",
      "Timestep 1\tScore: 16.10\tmin: 16.10\tmax: 16.10\n",
      " actions= [[1. 1.]]\n",
      "1049488  Evaluations Remaining\n",
      "rewards= 0.05876935709048903\n",
      "Timestep 2\tScore: 16.16\tmin: 16.16\tmax: 16.16\n",
      " actions= [[1. 1.]]\n",
      "1049487  Evaluations Remaining\n",
      "rewards= 0.14540339987484296\n",
      "Timestep 3\tScore: 16.30\tmin: 16.30\tmax: 16.30\n",
      " actions= [[1. 1.]]\n",
      "1049486  Evaluations Remaining\n",
      "rewards= -0.04807059090428867\n",
      "Episode 96\tScore: 16.25\tAverage Score: 18.925\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049485  Evaluations Remaining\n",
      "rewards= 13.987580572871506\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049484  Evaluations Remaining\n",
      "rewards= -0.23394425903982663\n",
      "Timestep 1\tScore: 13.75\tmin: 13.75\tmax: 13.75\n",
      " actions= [[1. 1.]]\n",
      "1049483  Evaluations Remaining\n",
      "rewards= 0.056762686416392594\n",
      "Timestep 2\tScore: 13.81\tmin: 13.81\tmax: 13.81\n",
      " actions= [[1. 1.]]\n",
      "1049482  Evaluations Remaining\n",
      "rewards= -0.009611053948237913\n",
      "Timestep 3\tScore: 13.80\tmin: 13.80\tmax: 13.80\n",
      " actions= [[1. 1.]]\n",
      "1049481  Evaluations Remaining\n",
      "rewards= 0.1784355263913473\n",
      "Episode 97\tScore: 13.98\tAverage Score: 18.818\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049480  Evaluations Remaining\n",
      "rewards= 15.617216450156784\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049479  Evaluations Remaining\n",
      "rewards= -0.13716568901762471\n",
      "Timestep 1\tScore: 15.48\tmin: 15.48\tmax: 15.48\n",
      " actions= [[1. 1.]]\n",
      "1049478  Evaluations Remaining\n",
      "rewards= 0.12474748780633194\n",
      "Timestep 2\tScore: 15.60\tmin: 15.60\tmax: 15.60\n",
      " actions= [[1. 1.]]\n",
      "1049477  Evaluations Remaining\n",
      "rewards= -0.05351753797919567\n",
      "Timestep 3\tScore: 15.55\tmin: 15.55\tmax: 15.55\n",
      " actions= [[1. 1.]]\n",
      "1049476  Evaluations Remaining\n",
      "rewards= 0.08068513907786024\n",
      "Episode 98\tScore: 15.63\tAverage Score: 17.823\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049475  Evaluations Remaining\n",
      "rewards= 15.757327015792075\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049474  Evaluations Remaining\n",
      "rewards= 0.22360358062212304\n",
      "Timestep 1\tScore: 15.98\tmin: 15.98\tmax: 15.98\n",
      " actions= [[1. 1.]]\n",
      "1049473  Evaluations Remaining\n",
      "rewards= 0.2212612334311932\n",
      "Timestep 2\tScore: 16.20\tmin: 16.20\tmax: 16.20\n",
      " actions= [[1. 1.]]\n",
      "1049472  Evaluations Remaining\n",
      "rewards= 0.11591496625202558\n",
      "Timestep 3\tScore: 16.32\tmin: 16.32\tmax: 16.32\n",
      " actions= [[1. 1.]]\n",
      "1049471  Evaluations Remaining\n",
      "rewards= -0.13100837931659948\n",
      "Episode 99\tScore: 16.19\tAverage Score: 17.899\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049470  Evaluations Remaining\n",
      "rewards= 16.049355439083183\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049469  Evaluations Remaining\n",
      "rewards= -0.11176420282699828\n",
      "Timestep 1\tScore: 15.94\tmin: 15.94\tmax: 15.94\n",
      " actions= [[1. 1.]]\n",
      "1049468  Evaluations Remaining\n",
      "rewards= 0.024289311221956655\n",
      "Timestep 2\tScore: 15.96\tmin: 15.96\tmax: 15.96\n",
      " actions= [[1. 1.]]\n",
      "1049467  Evaluations Remaining\n",
      "rewards= 0.17449185177415494\n",
      "Timestep 3\tScore: 16.14\tmin: 16.14\tmax: 16.14\n",
      " actions= [[1. 1.]]\n",
      "1049466  Evaluations Remaining\n",
      "rewards= 0.20265313890204606\n",
      "Episode 100\tScore: 16.34\tAverage Score: 17.90\n",
      "Episode 100\tAverage Score: 17.90\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049465  Evaluations Remaining\n",
      "rewards= 13.55336342059324\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049464  Evaluations Remaining\n",
      "rewards= 0.22441827799473035\n",
      "Timestep 1\tScore: 13.78\tmin: 13.78\tmax: 13.78\n",
      " actions= [[1. 1.]]\n",
      "1049463  Evaluations Remaining\n",
      "rewards= -0.1249676645600406\n",
      "Timestep 2\tScore: 13.65\tmin: 13.65\tmax: 13.65\n",
      " actions= [[1. 1.]]\n",
      "1049462  Evaluations Remaining\n",
      "rewards= 0.17601172318473912\n",
      "Timestep 3\tScore: 13.83\tmin: 13.83\tmax: 13.83\n",
      " actions= [[1. 1.]]\n",
      "1049461  Evaluations Remaining\n",
      "rewards= 0.09729088375044803\n",
      "Episode 101\tScore: 13.93\tAverage Score: 17.97\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049460  Evaluations Remaining\n",
      "rewards= 14.214471759819975\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049459  Evaluations Remaining\n",
      "rewards= 0.22296464563798857\n",
      "Timestep 1\tScore: 14.44\tmin: 14.44\tmax: 14.44\n",
      " actions= [[1. 1.]]\n",
      "1049458  Evaluations Remaining\n",
      "rewards= -0.24643933470407386\n",
      "Timestep 2\tScore: 14.19\tmin: 14.19\tmax: 14.19\n",
      " actions= [[1. 1.]]\n",
      "1049457  Evaluations Remaining\n",
      "rewards= -0.0949473437986188\n",
      "Timestep 3\tScore: 14.10\tmin: 14.10\tmax: 14.10\n",
      " actions= [[1. 1.]]\n",
      "1049456  Evaluations Remaining\n",
      "rewards= -0.2618959699944967\n",
      "Episode 102\tScore: 13.83\tAverage Score: 17.87\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049455  Evaluations Remaining\n",
      "rewards= 14.22584872341665\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049454  Evaluations Remaining\n",
      "rewards= 0.013861380475519436\n",
      "Timestep 1\tScore: 14.24\tmin: 14.24\tmax: 14.24\n",
      " actions= [[1. 1.]]\n",
      "1049453  Evaluations Remaining\n",
      "rewards= -0.2709061109051265\n",
      "Timestep 2\tScore: 13.97\tmin: 13.97\tmax: 13.97\n",
      " actions= [[1. 1.]]\n",
      "1049452  Evaluations Remaining\n",
      "rewards= -0.26913940505599676\n",
      "Timestep 3\tScore: 13.70\tmin: 13.70\tmax: 13.70\n",
      " actions= [[1. 1.]]\n",
      "1049451  Evaluations Remaining\n",
      "rewards= 0.08319942036588834\n",
      "Episode 103\tScore: 13.78\tAverage Score: 17.67\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049450  Evaluations Remaining\n",
      "rewards= 15.830868385746728\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049449  Evaluations Remaining\n",
      "rewards= -0.15378910433699255\n",
      "Timestep 1\tScore: 15.68\tmin: 15.68\tmax: 15.68\n",
      " actions= [[1. 1.]]\n",
      "1049448  Evaluations Remaining\n",
      "rewards= -0.2572397647456972\n",
      "Timestep 2\tScore: 15.42\tmin: 15.42\tmax: 15.42\n",
      " actions= [[1. 1.]]\n",
      "1049447  Evaluations Remaining\n",
      "rewards= 0.23314308364681224\n",
      "Timestep 3\tScore: 15.65\tmin: 15.65\tmax: 15.65\n",
      " actions= [[1. 1.]]\n",
      "1049446  Evaluations Remaining\n",
      "rewards= 0.0007045189226704274\n",
      "Episode 104\tScore: 15.65\tAverage Score: 17.80\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049445  Evaluations Remaining\n",
      "rewards= 15.543450182692105\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049444  Evaluations Remaining\n",
      "rewards= 0.1301792911396551\n",
      "Timestep 1\tScore: 15.67\tmin: 15.67\tmax: 15.67\n",
      " actions= [[1. 1.]]\n",
      "1049443  Evaluations Remaining\n",
      "rewards= 0.21287601800689515\n",
      "Timestep 2\tScore: 15.89\tmin: 15.89\tmax: 15.89\n",
      " actions= [[1. 1.]]\n",
      "1049442  Evaluations Remaining\n",
      "rewards= -0.2692315707096151\n",
      "Timestep 3\tScore: 15.62\tmin: 15.62\tmax: 15.62\n",
      " actions= [[1. 1.]]\n",
      "1049441  Evaluations Remaining\n",
      "rewards= 0.2036959878835476\n",
      "Episode 105\tScore: 15.82\tAverage Score: 15.14\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049440  Evaluations Remaining\n",
      "rewards= 13.598238072676823\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049439  Evaluations Remaining\n",
      "rewards= -0.04287303152417632\n",
      "Timestep 1\tScore: 13.56\tmin: 13.56\tmax: 13.56\n",
      " actions= [[1. 0.]]\n",
      "1049438  Evaluations Remaining\n",
      "rewards= -0.1596891922359398\n",
      "Timestep 2\tScore: 13.40\tmin: 13.40\tmax: 13.40\n",
      " actions= [[1.         0.46639185]]\n",
      "1049437  Evaluations Remaining\n",
      "rewards= 21.457451449671527\n",
      "Timestep 3\tScore: 34.85\tmin: 34.85\tmax: 34.85\n",
      " actions= [[1. 1.]]\n",
      "1049436  Evaluations Remaining\n",
      "rewards= 25.091822493943855\n",
      "Episode 106\tScore: 59.94\tAverage Score: 19.51\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049435  Evaluations Remaining\n",
      "rewards= 13.878773071752464\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049434  Evaluations Remaining\n",
      "rewards= -0.17432380096479827\n",
      "Timestep 1\tScore: 13.70\tmin: 13.70\tmax: 13.70\n",
      " actions= [[1. 1.]]\n",
      "1049433  Evaluations Remaining\n",
      "rewards= -0.13240025240853814\n",
      "Timestep 2\tScore: 13.57\tmin: 13.57\tmax: 13.57\n",
      " actions= [[1. 1.]]\n",
      "1049432  Evaluations Remaining\n",
      "rewards= -0.07913053632459288\n",
      "Timestep 3\tScore: 13.49\tmin: 13.49\tmax: 13.49\n",
      " actions= [[0.41749179 0.        ]]\n",
      "1049431  Evaluations Remaining\n",
      "rewards= -0.22311329342521447\n",
      "Episode 107\tScore: 13.27\tAverage Score: 19.44\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049430  Evaluations Remaining\n",
      "rewards= 14.971606587923647\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049429  Evaluations Remaining\n",
      "rewards= 0.1142060342746114\n",
      "Timestep 1\tScore: 15.09\tmin: 15.09\tmax: 15.09\n",
      " actions= [[1. 1.]]\n",
      "1049428  Evaluations Remaining\n",
      "rewards= -0.21140845204551972\n",
      "Timestep 2\tScore: 14.87\tmin: 14.87\tmax: 14.87\n",
      " actions= [[1. 1.]]\n",
      "1049427  Evaluations Remaining\n",
      "rewards= -0.04655644996868835\n",
      "Timestep 3\tScore: 14.83\tmin: 14.83\tmax: 14.83\n",
      " actions= [[1. 1.]]\n",
      "1049426  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= -0.07622610546689046\n",
      "Episode 108\tScore: 14.75\tAverage Score: 19.35\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049425  Evaluations Remaining\n",
      "rewards= 15.895804675915027\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049424  Evaluations Remaining\n",
      "rewards= -0.11420738478169978\n",
      "Timestep 1\tScore: 15.78\tmin: 15.78\tmax: 15.78\n",
      " actions= [[1. 1.]]\n",
      "1049423  Evaluations Remaining\n",
      "rewards= -0.23079051288378283\n",
      "Timestep 2\tScore: 15.55\tmin: 15.55\tmax: 15.55\n",
      " actions= [[1. 1.]]\n",
      "1049422  Evaluations Remaining\n",
      "rewards= 0.1729166504856532\n",
      "Timestep 3\tScore: 15.72\tmin: 15.72\tmax: 15.72\n",
      " actions= [[1. 1.]]\n",
      "1049421  Evaluations Remaining\n",
      "rewards= 0.21462227341918094\n",
      "Episode 109\tScore: 15.94\tAverage Score: 19.33\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049420  Evaluations Remaining\n",
      "rewards= 14.75010062307674\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049419  Evaluations Remaining\n",
      "rewards= -0.09671016164271906\n",
      "Timestep 1\tScore: 14.65\tmin: 14.65\tmax: 14.65\n",
      " actions= [[1. 1.]]\n",
      "1049418  Evaluations Remaining\n",
      "rewards= 0.2172252222210873\n",
      "Timestep 2\tScore: 14.87\tmin: 14.87\tmax: 14.87\n",
      " actions= [[1. 1.]]\n",
      "1049417  Evaluations Remaining\n",
      "rewards= 0.02894649376231717\n",
      "Timestep 3\tScore: 14.90\tmin: 14.90\tmax: 14.90\n",
      " actions= [[1. 1.]]\n",
      "1049416  Evaluations Remaining\n",
      "rewards= 0.16057212881544025\n",
      "Episode 110\tScore: 15.06\tAverage Score: 19.20\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049415  Evaluations Remaining\n",
      "rewards= 16.373773193487974\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049414  Evaluations Remaining\n",
      "rewards= -0.09534808216231694\n",
      "Timestep 1\tScore: 16.28\tmin: 16.28\tmax: 16.28\n",
      " actions= [[1. 1.]]\n",
      "1049413  Evaluations Remaining\n",
      "rewards= 0.043751774178944824\n",
      "Timestep 2\tScore: 16.32\tmin: 16.32\tmax: 16.32\n",
      " actions= [[1. 1.]]\n",
      "1049412  Evaluations Remaining\n",
      "rewards= 0.12483671248790218\n",
      "Timestep 3\tScore: 16.45\tmin: 16.45\tmax: 16.45\n",
      " actions= [[0. 0.]]\n",
      "1049411  Evaluations Remaining\n",
      "rewards= -0.1413490036887013\n",
      "Episode 111\tScore: 16.31\tAverage Score: 19.44\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049410  Evaluations Remaining\n",
      "rewards= 15.880668600188907\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049409  Evaluations Remaining\n",
      "rewards= -0.21565444293307134\n",
      "Timestep 1\tScore: 15.67\tmin: 15.67\tmax: 15.67\n",
      " actions= [[1. 1.]]\n",
      "1049408  Evaluations Remaining\n",
      "rewards= -0.02450330197788375\n",
      "Timestep 2\tScore: 15.64\tmin: 15.64\tmax: 15.64\n",
      " actions= [[1. 1.]]\n",
      "1049407  Evaluations Remaining\n",
      "rewards= -0.029010029837322815\n",
      "Timestep 3\tScore: 15.61\tmin: 15.61\tmax: 15.61\n",
      " actions= [[1. 1.]]\n",
      "1049406  Evaluations Remaining\n",
      "rewards= -0.2008238325485192\n",
      "Episode 112\tScore: 15.41\tAverage Score: 19.59\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049405  Evaluations Remaining\n",
      "rewards= 13.585423869040586\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049404  Evaluations Remaining\n",
      "rewards= 0.17342413397957612\n",
      "Timestep 1\tScore: 13.76\tmin: 13.76\tmax: 13.76\n",
      " actions= [[0.07309048 0.        ]]\n",
      "1049403  Evaluations Remaining\n",
      "rewards= 0.07622340721157883\n",
      "Timestep 2\tScore: 13.84\tmin: 13.84\tmax: 13.84\n",
      " actions= [[1. 1.]]\n",
      "1049402  Evaluations Remaining\n",
      "rewards= 23.24406477357305\n",
      "Timestep 3\tScore: 37.08\tmin: 37.08\tmax: 37.08\n",
      " actions= [[1. 1.]]\n",
      "1049401  Evaluations Remaining\n",
      "rewards= 0.031533380277826595\n",
      "Episode 113\tScore: 37.11\tAverage Score: 21.93\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049400  Evaluations Remaining\n",
      "rewards= 14.244857377197977\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049399  Evaluations Remaining\n",
      "rewards= 0.18826892427630026\n",
      "Timestep 1\tScore: 14.43\tmin: 14.43\tmax: 14.43\n",
      " actions= [[1. 1.]]\n",
      "1049398  Evaluations Remaining\n",
      "rewards= -0.14313744567168474\n",
      "Timestep 2\tScore: 14.29\tmin: 14.29\tmax: 14.29\n",
      " actions= [[1. 1.]]\n",
      "1049397  Evaluations Remaining\n",
      "rewards= -0.06337777806369926\n",
      "Timestep 3\tScore: 14.23\tmin: 14.23\tmax: 14.23\n",
      " actions= [[1. 1.]]\n",
      "1049396  Evaluations Remaining\n",
      "rewards= 0.19690385898142493\n",
      "Episode 114\tScore: 14.42\tAverage Score: 21.80\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049395  Evaluations Remaining\n",
      "rewards= 16.004847561825734\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049394  Evaluations Remaining\n",
      "rewards= -0.1982310327374628\n",
      "Timestep 1\tScore: 15.81\tmin: 15.81\tmax: 15.81\n",
      " actions= [[1. 1.]]\n",
      "1049393  Evaluations Remaining\n",
      "rewards= -0.08959899745036459\n",
      "Timestep 2\tScore: 15.72\tmin: 15.72\tmax: 15.72\n",
      " actions= [[1. 1.]]\n",
      "1049392  Evaluations Remaining\n",
      "rewards= -0.06525565608832773\n",
      "Timestep 3\tScore: 15.65\tmin: 15.65\tmax: 15.65\n",
      " actions= [[1. 1.]]\n",
      "1049391  Evaluations Remaining\n",
      "rewards= 0.2662953526656793\n",
      "Episode 115\tScore: 15.92\tAverage Score: 21.81\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049390  Evaluations Remaining\n",
      "rewards= 13.787753421744059\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049389  Evaluations Remaining\n",
      "rewards= 0.10903260074864995\n",
      "Timestep 1\tScore: 13.90\tmin: 13.90\tmax: 13.90\n",
      " actions= [[1. 1.]]\n",
      "1049388  Evaluations Remaining\n",
      "rewards= -0.18524775332289067\n",
      "Timestep 2\tScore: 13.71\tmin: 13.71\tmax: 13.71\n",
      " actions= [[1. 1.]]\n",
      "1049387  Evaluations Remaining\n",
      "rewards= -0.14754035182589265\n",
      "Timestep 3\tScore: 13.56\tmin: 13.56\tmax: 13.56\n",
      " actions= [[1. 1.]]\n",
      "1049386  Evaluations Remaining\n",
      "rewards= -0.14212862049179842\n",
      "Episode 116\tScore: 13.42\tAverage Score: 17.16\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049385  Evaluations Remaining\n",
      "rewards= 14.271127125952113\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049384  Evaluations Remaining\n",
      "rewards= -0.04324962364538143\n",
      "Timestep 1\tScore: 14.23\tmin: 14.23\tmax: 14.23\n",
      " actions= [[1. 1.]]\n",
      "1049383  Evaluations Remaining\n",
      "rewards= 0.22453854798732786\n",
      "Timestep 2\tScore: 14.45\tmin: 14.45\tmax: 14.45\n",
      " actions= [[1. 1.]]\n",
      "1049382  Evaluations Remaining\n",
      "rewards= -0.04819325939099928\n",
      "Timestep 3\tScore: 14.40\tmin: 14.40\tmax: 14.40\n",
      " actions= [[1. 1.]]\n",
      "1049381  Evaluations Remaining\n",
      "rewards= -0.2219175794048578\n",
      "Episode 117\tScore: 14.18\tAverage Score: 17.25\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049380  Evaluations Remaining\n",
      "rewards= 14.34532194301712\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049379  Evaluations Remaining\n",
      "rewards= 0.002330838001528779\n",
      "Timestep 1\tScore: 14.35\tmin: 14.35\tmax: 14.35\n",
      " actions= [[1. 1.]]\n",
      "1049378  Evaluations Remaining\n",
      "rewards= -0.20601428335501026\n",
      "Timestep 2\tScore: 14.14\tmin: 14.14\tmax: 14.14\n",
      " actions= [[1. 1.]]\n",
      "1049377  Evaluations Remaining\n",
      "rewards= -0.10598945093018042\n",
      "Timestep 3\tScore: 14.04\tmin: 14.04\tmax: 14.04\n",
      " actions= [[1. 1.]]\n",
      "1049376  Evaluations Remaining\n",
      "rewards= 0.2297521304441763\n",
      "Episode 118\tScore: 14.27\tAverage Score: 17.20\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049375  Evaluations Remaining\n",
      "rewards= 13.75491085074072\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049374  Evaluations Remaining\n",
      "rewards= 0.0461129269217877\n",
      "Timestep 1\tScore: 13.80\tmin: 13.80\tmax: 13.80\n",
      " actions= [[1. 1.]]\n",
      "1049373  Evaluations Remaining\n",
      "rewards= 0.051594356996886415\n",
      "Timestep 2\tScore: 13.85\tmin: 13.85\tmax: 13.85\n",
      " actions= [[1. 1.]]\n",
      "1049372  Evaluations Remaining\n",
      "rewards= 0.23808258301332064\n",
      "Timestep 3\tScore: 14.09\tmin: 14.09\tmax: 14.09\n",
      " actions= [[1. 1.]]\n",
      "1049371  Evaluations Remaining\n",
      "rewards= 0.009228109878270274\n",
      "Episode 119\tScore: 14.10\tAverage Score: 17.02\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049370  Evaluations Remaining\n",
      "rewards= 13.949454932018284\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049369  Evaluations Remaining\n",
      "rewards= -0.04559268780645098\n",
      "Timestep 1\tScore: 13.90\tmin: 13.90\tmax: 13.90\n",
      " actions= [[1. 1.]]\n",
      "1049368  Evaluations Remaining\n",
      "rewards= 0.07461056391573084\n",
      "Timestep 2\tScore: 13.98\tmin: 13.98\tmax: 13.98\n",
      " actions= [[1. 1.]]\n",
      "1049367  Evaluations Remaining\n",
      "rewards= 0.17923421988354482\n",
      "Timestep 3\tScore: 14.16\tmin: 14.16\tmax: 14.16\n",
      " actions= [[1. 1.]]\n",
      "1049366  Evaluations Remaining\n",
      "rewards= 0.22279796414532882\n",
      "Episode 120\tScore: 14.38\tAverage Score: 16.95\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049365  Evaluations Remaining\n",
      "rewards= 15.391556893937903\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049364  Evaluations Remaining\n",
      "rewards= 0.009284414415363873\n",
      "Timestep 1\tScore: 15.40\tmin: 15.40\tmax: 15.40\n",
      " actions= [[1. 1.]]\n",
      "1049363  Evaluations Remaining\n",
      "rewards= 0.10051781238909108\n",
      "Timestep 2\tScore: 15.50\tmin: 15.50\tmax: 15.50\n",
      " actions= [[1. 1.]]\n",
      "1049362  Evaluations Remaining\n",
      "rewards= -0.04697173367409091\n",
      "Timestep 3\tScore: 15.45\tmin: 15.45\tmax: 15.45\n",
      " actions= [[1. 1.]]\n",
      "1049361  Evaluations Remaining\n",
      "rewards= -0.2398584596968032\n",
      "Episode 121\tScore: 15.21\tAverage Score: 16.84\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049360  Evaluations Remaining\n",
      "rewards= 14.505877447857959\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049359  Evaluations Remaining\n",
      "rewards= -0.1811516727915783\n",
      "Timestep 1\tScore: 14.32\tmin: 14.32\tmax: 14.32\n",
      " actions= [[1. 1.]]\n",
      "1049358  Evaluations Remaining\n",
      "rewards= -0.07269464511596668\n",
      "Timestep 2\tScore: 14.25\tmin: 14.25\tmax: 14.25\n",
      " actions= [[1. 1.]]\n",
      "1049357  Evaluations Remaining\n",
      "rewards= 0.25549732824802085\n",
      "Timestep 3\tScore: 14.51\tmin: 14.51\tmax: 14.51\n",
      " actions= [[1. 1.]]\n",
      "1049356  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 0.20385772872035846\n",
      "Episode 122\tScore: 14.71\tAverage Score: 16.77\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049355  Evaluations Remaining\n",
      "rewards= 14.279342295621523\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049354  Evaluations Remaining\n",
      "rewards= 0.0727501153825072\n",
      "Timestep 1\tScore: 14.35\tmin: 14.35\tmax: 14.35\n",
      " actions= [[1. 1.]]\n",
      "1049353  Evaluations Remaining\n",
      "rewards= -0.15055762720776\n",
      "Timestep 2\tScore: 14.20\tmin: 14.20\tmax: 14.20\n",
      " actions= [[0. 0.]]\n",
      "1049352  Evaluations Remaining\n",
      "rewards= 0.21726227891437144\n",
      "Timestep 3\tScore: 14.42\tmin: 14.42\tmax: 14.42\n",
      " actions= [[0.11949569 0.84363099]]\n",
      "1049351  Evaluations Remaining\n",
      "rewards= 58.42991504661667\n",
      "Episode 123\tScore: 72.85\tAverage Score: 20.35\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049350  Evaluations Remaining\n",
      "rewards= 15.385234815835606\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049349  Evaluations Remaining\n",
      "rewards= 0.07874039205796901\n",
      "Timestep 1\tScore: 15.46\tmin: 15.46\tmax: 15.46\n",
      " actions= [[1. 1.]]\n",
      "1049348  Evaluations Remaining\n",
      "rewards= -0.08173267929068517\n",
      "Timestep 2\tScore: 15.38\tmin: 15.38\tmax: 15.38\n",
      " actions= [[1. 1.]]\n",
      "1049347  Evaluations Remaining\n",
      "rewards= 0.05713579410709535\n",
      "Timestep 3\tScore: 15.44\tmin: 15.44\tmax: 15.44\n",
      " actions= [[1. 1.]]\n",
      "1049346  Evaluations Remaining\n",
      "rewards= -0.14646352282055242\n",
      "Episode 124\tScore: 15.29\tAverage Score: 20.43\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049345  Evaluations Remaining\n",
      "rewards= 15.616913185679607\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049344  Evaluations Remaining\n",
      "rewards= -0.20990767439039537\n",
      "Timestep 1\tScore: 15.41\tmin: 15.41\tmax: 15.41\n",
      " actions= [[1. 1.]]\n",
      "1049343  Evaluations Remaining\n",
      "rewards= -0.10726257965918196\n",
      "Timestep 2\tScore: 15.30\tmin: 15.30\tmax: 15.30\n",
      " actions= [[1. 1.]]\n",
      "1049342  Evaluations Remaining\n",
      "rewards= -0.1092135084558934\n",
      "Timestep 3\tScore: 15.19\tmin: 15.19\tmax: 15.19\n",
      " actions= [[1. 1.]]\n",
      "1049341  Evaluations Remaining\n",
      "rewards= 0.1083971358515039\n",
      "Episode 125\tScore: 15.30\tAverage Score: 20.37\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049340  Evaluations Remaining\n",
      "rewards= 15.037391205545104\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049339  Evaluations Remaining\n",
      "rewards= -0.17043703270677657\n",
      "Timestep 1\tScore: 14.87\tmin: 14.87\tmax: 14.87\n",
      " actions= [[1. 1.]]\n",
      "1049338  Evaluations Remaining\n",
      "rewards= 0.16446370854566172\n",
      "Timestep 2\tScore: 15.03\tmin: 15.03\tmax: 15.03\n",
      " actions= [[1. 1.]]\n",
      "1049337  Evaluations Remaining\n",
      "rewards= -0.2478330931355548\n",
      "Timestep 3\tScore: 14.78\tmin: 14.78\tmax: 14.78\n",
      " actions= [[1. 1.]]\n",
      "1049336  Evaluations Remaining\n",
      "rewards= 0.04262687203004001\n",
      "Episode 126\tScore: 14.83\tAverage Score: 20.51\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049335  Evaluations Remaining\n",
      "rewards= 14.506246629102712\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049334  Evaluations Remaining\n",
      "rewards= 0.2707839378785746\n",
      "Timestep 1\tScore: 14.78\tmin: 14.78\tmax: 14.78\n",
      " actions= [[1. 1.]]\n",
      "1049333  Evaluations Remaining\n",
      "rewards= -0.14514451838695175\n",
      "Timestep 2\tScore: 14.63\tmin: 14.63\tmax: 14.63\n",
      " actions= [[1. 1.]]\n",
      "1049332  Evaluations Remaining\n",
      "rewards= -0.2024062294921074\n",
      "Timestep 3\tScore: 14.43\tmin: 14.43\tmax: 14.43\n",
      " actions= [[1. 1.]]\n",
      "1049331  Evaluations Remaining\n",
      "rewards= 0.09257685498777368\n",
      "Episode 127\tScore: 14.52\tAverage Score: 20.55\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049330  Evaluations Remaining\n",
      "rewards= 14.143066052351866\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049329  Evaluations Remaining\n",
      "rewards= -0.05504908514696716\n",
      "Timestep 1\tScore: 14.09\tmin: 14.09\tmax: 14.09\n",
      " actions= [[1. 1.]]\n",
      "1049328  Evaluations Remaining\n",
      "rewards= -0.06373564143012755\n",
      "Timestep 2\tScore: 14.02\tmin: 14.02\tmax: 14.02\n",
      " actions= [[1. 1.]]\n",
      "1049327  Evaluations Remaining\n",
      "rewards= -0.17353053726313838\n",
      "Timestep 3\tScore: 13.85\tmin: 13.85\tmax: 13.85\n",
      " actions= [[1. 1.]]\n",
      "1049326  Evaluations Remaining\n",
      "rewards= -0.008340586828928576\n",
      "Episode 128\tScore: 13.84\tAverage Score: 20.50\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049325  Evaluations Remaining\n",
      "rewards= 15.609056591796913\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049324  Evaluations Remaining\n",
      "rewards= 0.12477924379186467\n",
      "Timestep 1\tScore: 15.73\tmin: 15.73\tmax: 15.73\n",
      " actions= [[1. 1.]]\n",
      "1049323  Evaluations Remaining\n",
      "rewards= -0.16770236993709142\n",
      "Timestep 2\tScore: 15.57\tmin: 15.57\tmax: 15.57\n",
      " actions= [[1. 1.]]\n",
      "1049322  Evaluations Remaining\n",
      "rewards= -0.13254801388400894\n",
      "Timestep 3\tScore: 15.43\tmin: 15.43\tmax: 15.43\n",
      " actions= [[1. 1.]]\n",
      "1049321  Evaluations Remaining\n",
      "rewards= 0.14299731172102925\n",
      "Episode 129\tScore: 15.58\tAverage Score: 20.65\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049320  Evaluations Remaining\n",
      "rewards= 15.867229867866186\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049319  Evaluations Remaining\n",
      "rewards= -0.24014236379547782\n",
      "Timestep 1\tScore: 15.63\tmin: 15.63\tmax: 15.63\n",
      " actions= [[1. 1.]]\n",
      "1049318  Evaluations Remaining\n",
      "rewards= 0.11714545359905815\n",
      "Timestep 2\tScore: 15.74\tmin: 15.74\tmax: 15.74\n",
      " actions= [[1. 1.]]\n",
      "1049317  Evaluations Remaining\n",
      "rewards= -0.24372827655246532\n",
      "Timestep 3\tScore: 15.50\tmin: 15.50\tmax: 15.50\n",
      " actions= [[0.45611054 0.        ]]\n",
      "1049316  Evaluations Remaining\n",
      "rewards= -0.09990571558898642\n",
      "Episode 130\tScore: 15.40\tAverage Score: 20.75\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049315  Evaluations Remaining\n",
      "rewards= 14.76604283413296\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049314  Evaluations Remaining\n",
      "rewards= -0.24597008781488539\n",
      "Timestep 1\tScore: 14.52\tmin: 14.52\tmax: 14.52\n",
      " actions= [[1. 1.]]\n",
      "1049313  Evaluations Remaining\n",
      "rewards= -0.018888481907748833\n",
      "Timestep 2\tScore: 14.50\tmin: 14.50\tmax: 14.50\n",
      " actions= [[0.67398513 0.        ]]\n",
      "1049312  Evaluations Remaining\n",
      "rewards= -0.1873322416500467\n",
      "Timestep 3\tScore: 14.31\tmin: 14.31\tmax: 14.31\n",
      " actions= [[1. 1.]]\n",
      "1049311  Evaluations Remaining\n",
      "rewards= 63.27494435314943\n",
      "Episode 131\tScore: 77.59\tAverage Score: 26.99\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049310  Evaluations Remaining\n",
      "rewards= 15.398877105320633\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049309  Evaluations Remaining\n",
      "rewards= -0.005642985183823335\n",
      "Timestep 1\tScore: 15.39\tmin: 15.39\tmax: 15.39\n",
      " actions= [[1. 1.]]\n",
      "1049308  Evaluations Remaining\n",
      "rewards= -0.04768319910647145\n",
      "Timestep 2\tScore: 15.35\tmin: 15.35\tmax: 15.35\n",
      " actions= [[1. 1.]]\n",
      "1049307  Evaluations Remaining\n",
      "rewards= 0.03615180825027631\n",
      "Timestep 3\tScore: 15.38\tmin: 15.38\tmax: 15.38\n",
      " actions= [[1. 1.]]\n",
      "1049306  Evaluations Remaining\n",
      "rewards= -0.20295043083737418\n",
      "Episode 132\tScore: 15.18\tAverage Score: 27.04\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049305  Evaluations Remaining\n",
      "rewards= 15.985728521889186\n",
      "\n",
      " actions= [[0.         0.48710326]]\n",
      "1049304  Evaluations Remaining\n",
      "rewards= -0.12077637034487587\n",
      "Timestep 1\tScore: 15.86\tmin: 15.86\tmax: 15.86\n",
      " actions= [[0.04003288 0.33982323]]\n",
      "1049303  Evaluations Remaining\n",
      "rewards= 40.86510778729811\n",
      "Timestep 2\tScore: 56.73\tmin: 56.73\tmax: 56.73\n",
      " actions= [[1. 1.]]\n",
      "1049302  Evaluations Remaining\n",
      "rewards= -16.01335602646249\n",
      "Timestep 3\tScore: 40.72\tmin: 40.72\tmax: 40.72\n",
      " actions= [[1. 1.]]\n",
      "1049301  Evaluations Remaining\n",
      "rewards= -0.20308061702156976\n",
      "Episode 133\tScore: 40.51\tAverage Score: 23.80\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049300  Evaluations Remaining\n",
      "rewards= 15.421807303097175\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049299  Evaluations Remaining\n",
      "rewards= -0.19970663754319107\n",
      "Timestep 1\tScore: 15.22\tmin: 15.22\tmax: 15.22\n",
      " actions= [[1. 1.]]\n",
      "1049298  Evaluations Remaining\n",
      "rewards= 0.1952203369046206\n",
      "Timestep 2\tScore: 15.42\tmin: 15.42\tmax: 15.42\n",
      " actions= [[1. 1.]]\n",
      "1049297  Evaluations Remaining\n",
      "rewards= 0.0778619602580024\n",
      "Timestep 3\tScore: 15.50\tmin: 15.50\tmax: 15.50\n",
      " actions= [[1. 1.]]\n",
      "1049296  Evaluations Remaining\n",
      "rewards= 0.14201682856680709\n",
      "Episode 134\tScore: 15.64\tAverage Score: 23.84\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049295  Evaluations Remaining\n",
      "rewards= 14.336102808872047\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049294  Evaluations Remaining\n",
      "rewards= 0.2247580871662116\n",
      "Timestep 1\tScore: 14.56\tmin: 14.56\tmax: 14.56\n",
      " actions= [[1. 1.]]\n",
      "1049293  Evaluations Remaining\n",
      "rewards= 0.06957200907887717\n",
      "Timestep 2\tScore: 14.63\tmin: 14.63\tmax: 14.63\n",
      " actions= [[1. 1.]]\n",
      "1049292  Evaluations Remaining\n",
      "rewards= -0.15187885185057048\n",
      "Timestep 3\tScore: 14.48\tmin: 14.48\tmax: 14.48\n",
      " actions= [[1. 1.]]\n",
      "1049291  Evaluations Remaining\n",
      "rewards= -0.1362034822816205\n",
      "Episode 135\tScore: 14.34\tAverage Score: 23.74\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049290  Evaluations Remaining\n",
      "rewards= 13.736530801256924\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049289  Evaluations Remaining\n",
      "rewards= 0.04658808250308777\n",
      "Timestep 1\tScore: 13.78\tmin: 13.78\tmax: 13.78\n",
      " actions= [[1. 1.]]\n",
      "1049288  Evaluations Remaining\n",
      "rewards= 0.09357141294552473\n",
      "Timestep 2\tScore: 13.88\tmin: 13.88\tmax: 13.88\n",
      " actions= [[1. 1.]]\n",
      "1049287  Evaluations Remaining\n",
      "rewards= -0.13886569551553896\n",
      "Timestep 3\tScore: 13.74\tmin: 13.74\tmax: 13.74\n",
      " actions= [[1. 1.]]\n",
      "1049286  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 0.02239772243148863\n",
      "Episode 136\tScore: 13.76\tAverage Score: 23.64\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049285  Evaluations Remaining\n",
      "rewards= 14.899336231753114\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049284  Evaluations Remaining\n",
      "rewards= 0.07328059699596645\n",
      "Timestep 1\tScore: 14.97\tmin: 14.97\tmax: 14.97\n",
      " actions= [[1. 1.]]\n",
      "1049283  Evaluations Remaining\n",
      "rewards= -0.09349734737414739\n",
      "Timestep 2\tScore: 14.88\tmin: 14.88\tmax: 14.88\n",
      " actions= [[1. 1.]]\n",
      "1049282  Evaluations Remaining\n",
      "rewards= 0.0182390846735494\n",
      "Timestep 3\tScore: 14.90\tmin: 14.90\tmax: 14.90\n",
      " actions= [[1. 1.]]\n",
      "1049281  Evaluations Remaining\n",
      "rewards= -0.027462375731071464\n",
      "Episode 137\tScore: 14.87\tAverage Score: 23.67\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049280  Evaluations Remaining\n",
      "rewards= 13.568256753583295\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049279  Evaluations Remaining\n",
      "rewards= 0.11132142652277599\n",
      "Timestep 1\tScore: 13.68\tmin: 13.68\tmax: 13.68\n",
      " actions= [[1. 1.]]\n",
      "1049278  Evaluations Remaining\n",
      "rewards= -0.23194623856691043\n",
      "Timestep 2\tScore: 13.45\tmin: 13.45\tmax: 13.45\n",
      " actions= [[1. 1.]]\n",
      "1049277  Evaluations Remaining\n",
      "rewards= 0.12269273883441167\n",
      "Timestep 3\tScore: 13.57\tmin: 13.57\tmax: 13.57\n",
      " actions= [[1. 1.]]\n",
      "1049276  Evaluations Remaining\n",
      "rewards= -0.09288115583335488\n",
      "Episode 138\tScore: 13.48\tAverage Score: 23.63\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049275  Evaluations Remaining\n",
      "rewards= 15.774445521338341\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049274  Evaluations Remaining\n",
      "rewards= 0.044100481965448246\n",
      "Timestep 1\tScore: 15.82\tmin: 15.82\tmax: 15.82\n",
      " actions= [[1. 1.]]\n",
      "1049273  Evaluations Remaining\n",
      "rewards= 0.12216511747596259\n",
      "Timestep 2\tScore: 15.94\tmin: 15.94\tmax: 15.94\n",
      " actions= [[1. 1.]]\n",
      "1049272  Evaluations Remaining\n",
      "rewards= -0.24088909476888176\n",
      "Timestep 3\tScore: 15.70\tmin: 15.70\tmax: 15.70\n",
      " actions= [[1. 1.]]\n",
      "1049271  Evaluations Remaining\n",
      "rewards= -0.15792377471309216\n",
      "Episode 139\tScore: 15.54\tAverage Score: 23.63\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049270  Evaluations Remaining\n",
      "rewards= 15.273770950297221\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049269  Evaluations Remaining\n",
      "rewards= 0.1363990547088747\n",
      "Timestep 1\tScore: 15.41\tmin: 15.41\tmax: 15.41\n",
      " actions= [[1. 1.]]\n",
      "1049268  Evaluations Remaining\n",
      "rewards= -0.04720905081046034\n",
      "Timestep 2\tScore: 15.36\tmin: 15.36\tmax: 15.36\n",
      " actions= [[1. 1.]]\n",
      "1049267  Evaluations Remaining\n",
      "rewards= 0.07182711976587663\n",
      "Timestep 3\tScore: 15.43\tmin: 15.43\tmax: 15.43\n",
      " actions= [[1. 1.]]\n",
      "1049266  Evaluations Remaining\n",
      "rewards= -0.20678337543042202\n",
      "Episode 140\tScore: 15.23\tAverage Score: 23.61\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049265  Evaluations Remaining\n",
      "rewards= 15.887134239153196\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049264  Evaluations Remaining\n",
      "rewards= -0.14193762674457622\n",
      "Timestep 1\tScore: 15.75\tmin: 15.75\tmax: 15.75\n",
      " actions= [[1. 1.]]\n",
      "1049263  Evaluations Remaining\n",
      "rewards= 0.008086653317166625\n",
      "Timestep 2\tScore: 15.75\tmin: 15.75\tmax: 15.75\n",
      " actions= [[1. 1.]]\n",
      "1049262  Evaluations Remaining\n",
      "rewards= -0.17594917551595612\n",
      "Timestep 3\tScore: 15.58\tmin: 15.58\tmax: 15.58\n",
      " actions= [[1. 1.]]\n",
      "1049261  Evaluations Remaining\n",
      "rewards= -0.07166575763217953\n",
      "Episode 141\tScore: 15.51\tAverage Score: 17.41\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049260  Evaluations Remaining\n",
      "rewards= 15.547371265966623\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049259  Evaluations Remaining\n",
      "rewards= 0.20322677386811883\n",
      "Timestep 1\tScore: 15.75\tmin: 15.75\tmax: 15.75\n",
      " actions= [[1. 1.]]\n",
      "1049258  Evaluations Remaining\n",
      "rewards= -0.22074497640708035\n",
      "Timestep 2\tScore: 15.53\tmin: 15.53\tmax: 15.53\n",
      " actions= [[1. 1.]]\n",
      "1049257  Evaluations Remaining\n",
      "rewards= -0.19655042840501435\n",
      "Timestep 3\tScore: 15.33\tmin: 15.33\tmax: 15.33\n",
      " actions= [[1. 1.]]\n",
      "1049256  Evaluations Remaining\n",
      "rewards= -0.034639280345325485\n",
      "Episode 142\tScore: 15.30\tAverage Score: 17.42\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049255  Evaluations Remaining\n",
      "rewards= 14.292357813663592\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049254  Evaluations Remaining\n",
      "rewards= 0.05212329186335385\n",
      "Timestep 1\tScore: 14.34\tmin: 14.34\tmax: 14.34\n",
      " actions= [[1. 1.]]\n",
      "1049253  Evaluations Remaining\n",
      "rewards= 0.07582265393037968\n",
      "Timestep 2\tScore: 14.42\tmin: 14.42\tmax: 14.42\n",
      " actions= [[1. 1.]]\n",
      "1049252  Evaluations Remaining\n",
      "rewards= 0.054674398589059425\n",
      "Timestep 3\tScore: 14.47\tmin: 14.47\tmax: 14.47\n",
      " actions= [[1. 1.]]\n",
      "1049251  Evaluations Remaining\n",
      "rewards= -0.11761312679846814\n",
      "Episode 143\tScore: 14.36\tAverage Score: 14.80\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049250  Evaluations Remaining\n",
      "rewards= 14.721575928965144\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049249  Evaluations Remaining\n",
      "rewards= -0.06198135685564976\n",
      "Timestep 1\tScore: 14.66\tmin: 14.66\tmax: 14.66\n",
      " actions= [[1. 1.]]\n",
      "1049248  Evaluations Remaining\n",
      "rewards= -0.23764351460913202\n",
      "Timestep 2\tScore: 14.42\tmin: 14.42\tmax: 14.42\n",
      " actions= [[1. 1.]]\n",
      "1049247  Evaluations Remaining\n",
      "rewards= 0.04340351346544846\n",
      "Timestep 3\tScore: 14.47\tmin: 14.47\tmax: 14.47\n",
      " actions= [[1. 1.]]\n",
      "1049246  Evaluations Remaining\n",
      "rewards= 0.08908583354354915\n",
      "Episode 144\tScore: 14.55\tAverage Score: 14.69\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049245  Evaluations Remaining\n",
      "rewards= 16.04189727238984\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049244  Evaluations Remaining\n",
      "rewards= 0.22753862153705073\n",
      "Timestep 1\tScore: 16.27\tmin: 16.27\tmax: 16.27\n",
      " actions= [[1. 1.]]\n",
      "1049243  Evaluations Remaining\n",
      "rewards= -0.11633492110597832\n",
      "Timestep 2\tScore: 16.15\tmin: 16.15\tmax: 16.15\n",
      " actions= [[1. 1.]]\n",
      "1049242  Evaluations Remaining\n",
      "rewards= -0.09891087653964004\n",
      "Timestep 3\tScore: 16.05\tmin: 16.05\tmax: 16.05\n",
      " actions= [[1. 1.]]\n",
      "1049241  Evaluations Remaining\n",
      "rewards= -0.17204978976887197\n",
      "Episode 145\tScore: 15.88\tAverage Score: 14.85\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049240  Evaluations Remaining\n",
      "rewards= 16.270609391846648\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049239  Evaluations Remaining\n",
      "rewards= 0.1535022285779455\n",
      "Timestep 1\tScore: 16.42\tmin: 16.42\tmax: 16.42\n",
      " actions= [[1. 1.]]\n",
      "1049238  Evaluations Remaining\n",
      "rewards= -0.04513671247524975\n",
      "Timestep 2\tScore: 16.38\tmin: 16.38\tmax: 16.38\n",
      " actions= [[1. 1.]]\n",
      "1049237  Evaluations Remaining\n",
      "rewards= -0.15515155693035787\n",
      "Timestep 3\tScore: 16.22\tmin: 16.22\tmax: 16.22\n",
      " actions= [[1. 1.]]\n",
      "1049236  Evaluations Remaining\n",
      "rewards= 0.025311671454385287\n",
      "Episode 146\tScore: 16.25\tAverage Score: 15.10\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049235  Evaluations Remaining\n",
      "rewards= 14.496450914785916\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049234  Evaluations Remaining\n",
      "rewards= 0.1732346835964096\n",
      "Timestep 1\tScore: 14.67\tmin: 14.67\tmax: 14.67\n",
      " actions= [[1. 1.]]\n",
      "1049233  Evaluations Remaining\n",
      "rewards= -0.23439789335731165\n",
      "Timestep 2\tScore: 14.44\tmin: 14.44\tmax: 14.44\n",
      " actions= [[1. 1.]]\n",
      "1049232  Evaluations Remaining\n",
      "rewards= 0.22027807854588666\n",
      "Timestep 3\tScore: 14.66\tmin: 14.66\tmax: 14.66\n",
      " actions= [[1. 1.]]\n",
      "1049231  Evaluations Remaining\n",
      "rewards= 0.0757570187014589\n",
      "Episode 147\tScore: 14.73\tAverage Score: 15.08\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049230  Evaluations Remaining\n",
      "rewards= 14.865654946711059\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049229  Evaluations Remaining\n",
      "rewards= 0.07314795644427807\n",
      "Timestep 1\tScore: 14.94\tmin: 14.94\tmax: 14.94\n",
      " actions= [[1. 1.]]\n",
      "1049228  Evaluations Remaining\n",
      "rewards= -0.07980385559333314\n",
      "Timestep 2\tScore: 14.86\tmin: 14.86\tmax: 14.86\n",
      " actions= [[1. 1.]]\n",
      "1049227  Evaluations Remaining\n",
      "rewards= -0.2031565196882381\n",
      "Timestep 3\tScore: 14.66\tmin: 14.66\tmax: 14.66\n",
      " actions= [[1. 1.]]\n",
      "1049226  Evaluations Remaining\n",
      "rewards= -0.0022571139191205347\n",
      "Episode 148\tScore: 14.65\tAverage Score: 15.20\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049225  Evaluations Remaining\n",
      "rewards= 16.29456258144232\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049224  Evaluations Remaining\n",
      "rewards= 0.2197973844709713\n",
      "Timestep 1\tScore: 16.51\tmin: 16.51\tmax: 16.51\n",
      " actions= [[1. 1.]]\n",
      "1049223  Evaluations Remaining\n",
      "rewards= -0.08606476955439346\n",
      "Timestep 2\tScore: 16.43\tmin: 16.43\tmax: 16.43\n",
      " actions= [[0.06270894 0.        ]]\n",
      "1049222  Evaluations Remaining\n",
      "rewards= -0.1797620020702082\n",
      "Timestep 3\tScore: 16.25\tmin: 16.25\tmax: 16.25\n",
      " actions= [[1. 1.]]\n",
      "1049221  Evaluations Remaining\n",
      "rewards= 24.81336494543235\n",
      "Episode 149\tScore: 41.06\tAverage Score: 17.75\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049220  Evaluations Remaining\n",
      "rewards= 13.785672510177557\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049219  Evaluations Remaining\n",
      "rewards= 0.17037769013585802\n",
      "Timestep 1\tScore: 13.96\tmin: 13.96\tmax: 13.96\n",
      " actions= [[1. 1.]]\n",
      "1049218  Evaluations Remaining\n",
      "rewards= 0.04221561783666461\n",
      "Timestep 2\tScore: 14.00\tmin: 14.00\tmax: 14.00\n",
      " actions= [[0. 0.]]\n",
      "1049217  Evaluations Remaining\n",
      "rewards= 0.03884619182370708\n",
      "Timestep 3\tScore: 14.04\tmin: 14.04\tmax: 14.04\n",
      " actions= [[1. 1.]]\n",
      "1049216  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 12.622142450424807\n",
      "Episode 150\tScore: 26.66\tAverage Score: 18.90\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049215  Evaluations Remaining\n",
      "rewards= 14.988146797403717\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049214  Evaluations Remaining\n",
      "rewards= 0.23075598635543182\n",
      "Timestep 1\tScore: 15.22\tmin: 15.22\tmax: 15.22\n",
      " actions= [[1. 1.]]\n",
      "1049213  Evaluations Remaining\n",
      "rewards= -0.020321904876775765\n",
      "Timestep 2\tScore: 15.20\tmin: 15.20\tmax: 15.20\n",
      " actions= [[1. 1.]]\n",
      "1049212  Evaluations Remaining\n",
      "rewards= 0.18500128685462158\n",
      "Timestep 3\tScore: 15.38\tmin: 15.38\tmax: 15.38\n",
      " actions= [[1. 1.]]\n",
      "1049211  Evaluations Remaining\n",
      "rewards= -0.25344377454799094\n",
      "Episode 151\tScore: 15.13\tAverage Score: 18.86\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049210  Evaluations Remaining\n",
      "rewards= 13.593339389098718\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049209  Evaluations Remaining\n",
      "rewards= -0.018218055858774118\n",
      "Timestep 1\tScore: 13.58\tmin: 13.58\tmax: 13.58\n",
      " actions= [[1. 1.]]\n",
      "1049208  Evaluations Remaining\n",
      "rewards= -0.03373615068301472\n",
      "Timestep 2\tScore: 13.54\tmin: 13.54\tmax: 13.54\n",
      " actions= [[1. 1.]]\n",
      "1049207  Evaluations Remaining\n",
      "rewards= -0.10820335976006934\n",
      "Timestep 3\tScore: 13.43\tmin: 13.43\tmax: 13.43\n",
      " actions= [[1. 1.]]\n",
      "1049206  Evaluations Remaining\n",
      "rewards= 0.26007675995253887\n",
      "Episode 152\tScore: 13.69\tAverage Score: 18.70\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049205  Evaluations Remaining\n",
      "rewards= 13.862102055948212\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049204  Evaluations Remaining\n",
      "rewards= -0.22933792831751987\n",
      "Timestep 1\tScore: 13.63\tmin: 13.63\tmax: 13.63\n",
      " actions= [[1. 1.]]\n",
      "1049203  Evaluations Remaining\n",
      "rewards= 0.11904538374074347\n",
      "Timestep 2\tScore: 13.75\tmin: 13.75\tmax: 13.75\n",
      " actions= [[0.33970008 0.        ]]\n",
      "1049202  Evaluations Remaining\n",
      "rewards= 0.21371953899392704\n",
      "Timestep 3\tScore: 13.97\tmin: 13.97\tmax: 13.97\n",
      " actions= [[1. 1.]]\n",
      "1049201  Evaluations Remaining\n",
      "rewards= 11.417452543753054\n",
      "Episode 153\tScore: 25.38\tAverage Score: 19.80\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049200  Evaluations Remaining\n",
      "rewards= 16.182219837470488\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049199  Evaluations Remaining\n",
      "rewards= -0.004184839270556573\n",
      "Timestep 1\tScore: 16.18\tmin: 16.18\tmax: 16.18\n",
      " actions= [[1. 1.]]\n",
      "1049198  Evaluations Remaining\n",
      "rewards= 0.006744081996291396\n",
      "Timestep 2\tScore: 16.18\tmin: 16.18\tmax: 16.18\n",
      " actions= [[1. 1.]]\n",
      "1049197  Evaluations Remaining\n",
      "rewards= -0.24897562927517658\n",
      "Timestep 3\tScore: 15.94\tmin: 15.94\tmax: 15.94\n",
      " actions= [[1. 1.]]\n",
      "1049196  Evaluations Remaining\n",
      "rewards= -0.007382953789530244\n",
      "Episode 154\tScore: 15.93\tAverage Score: 19.94\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049195  Evaluations Remaining\n",
      "rewards= 15.728658494090334\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049194  Evaluations Remaining\n",
      "rewards= 0.07765330300564299\n",
      "Timestep 1\tScore: 15.81\tmin: 15.81\tmax: 15.81\n",
      " actions= [[1. 1.]]\n",
      "1049193  Evaluations Remaining\n",
      "rewards= 0.0973498721275381\n",
      "Timestep 2\tScore: 15.90\tmin: 15.90\tmax: 15.90\n",
      " actions= [[1. 1.]]\n",
      "1049192  Evaluations Remaining\n",
      "rewards= -0.2570069730448825\n",
      "Timestep 3\tScore: 15.65\tmin: 15.65\tmax: 15.65\n",
      " actions= [[1. 1.]]\n",
      "1049191  Evaluations Remaining\n",
      "rewards= -0.006322507662650967\n",
      "Episode 155\tScore: 15.64\tAverage Score: 19.91\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049190  Evaluations Remaining\n",
      "rewards= 13.946503754650013\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049189  Evaluations Remaining\n",
      "rewards= 0.19662164261230863\n",
      "Timestep 1\tScore: 14.14\tmin: 14.14\tmax: 14.14\n",
      " actions= [[1. 1.]]\n",
      "1049188  Evaluations Remaining\n",
      "rewards= -0.24947229196773035\n",
      "Timestep 2\tScore: 13.89\tmin: 13.89\tmax: 13.89\n",
      " actions= [[1. 1.]]\n",
      "1049187  Evaluations Remaining\n",
      "rewards= 0.21598745217698756\n",
      "Timestep 3\tScore: 14.11\tmin: 14.11\tmax: 14.11\n",
      " actions= [[1. 1.]]\n",
      "1049186  Evaluations Remaining\n",
      "rewards= 0.12405979380898291\n",
      "Episode 156\tScore: 14.23\tAverage Score: 19.71\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049185  Evaluations Remaining\n",
      "rewards= 13.729581029648308\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049184  Evaluations Remaining\n",
      "rewards= 0.09203972832540419\n",
      "Timestep 1\tScore: 13.82\tmin: 13.82\tmax: 13.82\n",
      " actions= [[1. 1.]]\n",
      "1049183  Evaluations Remaining\n",
      "rewards= 0.10388847930536649\n",
      "Timestep 2\tScore: 13.93\tmin: 13.93\tmax: 13.93\n",
      " actions= [[1. 1.]]\n",
      "1049182  Evaluations Remaining\n",
      "rewards= 0.20403834126460474\n",
      "Timestep 3\tScore: 14.13\tmin: 14.13\tmax: 14.13\n",
      " actions= [[1. 1.]]\n",
      "1049181  Evaluations Remaining\n",
      "rewards= -0.06341736042521973\n",
      "Episode 157\tScore: 14.07\tAverage Score: 19.64\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049180  Evaluations Remaining\n",
      "rewards= 13.627493236080387\n",
      "\n",
      " actions= [[0. 0.]]\n",
      "1049179  Evaluations Remaining\n",
      "rewards= 0.026279366554543326\n",
      "Timestep 1\tScore: 13.65\tmin: 13.65\tmax: 13.65\n",
      " actions= [[1. 1.]]\n",
      "1049178  Evaluations Remaining\n",
      "rewards= 12.531647664581914\n",
      "Timestep 2\tScore: 26.19\tmin: 26.19\tmax: 26.19\n",
      " actions= [[1. 1.]]\n",
      "1049177  Evaluations Remaining\n",
      "rewards= -0.021434010199773645\n",
      "Timestep 3\tScore: 26.16\tmin: 26.16\tmax: 26.16\n",
      " actions= [[1. 1.]]\n",
      "1049176  Evaluations Remaining\n",
      "rewards= -0.23836349395561518\n",
      "Episode 158\tScore: 25.93\tAverage Score: 20.77\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049175  Evaluations Remaining\n",
      "rewards= 16.10994376027033\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049174  Evaluations Remaining\n",
      "rewards= 0.031581232082280586\n",
      "Timestep 1\tScore: 16.14\tmin: 16.14\tmax: 16.14\n",
      " actions= [[1. 1.]]\n",
      "1049173  Evaluations Remaining\n",
      "rewards= -0.1770954306798611\n",
      "Timestep 2\tScore: 15.96\tmin: 15.96\tmax: 15.96\n",
      " actions= [[1. 1.]]\n",
      "1049172  Evaluations Remaining\n",
      "rewards= -0.17945722826543253\n",
      "Timestep 3\tScore: 15.78\tmin: 15.78\tmax: 15.78\n",
      " actions= [[1. 1.]]\n",
      "1049171  Evaluations Remaining\n",
      "rewards= -0.054726142993289706\n",
      "Episode 159\tScore: 15.73\tAverage Score: 18.24\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049170  Evaluations Remaining\n",
      "rewards= 16.023969717182677\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049169  Evaluations Remaining\n",
      "rewards= 0.1150635227701402\n",
      "Timestep 1\tScore: 16.14\tmin: 16.14\tmax: 16.14\n",
      " actions= [[1. 1.]]\n",
      "1049168  Evaluations Remaining\n",
      "rewards= -0.2675084170993207\n",
      "Timestep 2\tScore: 15.87\tmin: 15.87\tmax: 15.87\n",
      " actions= [[1. 1.]]\n",
      "1049167  Evaluations Remaining\n",
      "rewards= -0.02396476544009518\n",
      "Timestep 3\tScore: 15.85\tmin: 15.85\tmax: 15.85\n",
      " actions= [[1. 1.]]\n",
      "1049166  Evaluations Remaining\n",
      "rewards= 0.1673712243860912\n",
      "Episode 160\tScore: 16.01\tAverage Score: 17.17\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049165  Evaluations Remaining\n",
      "rewards= 15.288126541141436\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049164  Evaluations Remaining\n",
      "rewards= -0.13842032495410228\n",
      "Timestep 1\tScore: 15.15\tmin: 15.15\tmax: 15.15\n",
      " actions= [[1. 1.]]\n",
      "1049163  Evaluations Remaining\n",
      "rewards= 0.049938810568867176\n",
      "Timestep 2\tScore: 15.20\tmin: 15.20\tmax: 15.20\n",
      " actions= [[0. 0.]]\n",
      "1049162  Evaluations Remaining\n",
      "rewards= -0.23968370752183832\n",
      "Timestep 3\tScore: 14.96\tmin: 14.96\tmax: 14.96\n",
      " actions= [[1. 1.]]\n",
      "1049161  Evaluations Remaining\n",
      "rewards= 12.579962760103998\n",
      "Episode 161\tScore: 27.54\tAverage Score: 18.42\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049160  Evaluations Remaining\n",
      "rewards= 16.27603710942212\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049159  Evaluations Remaining\n",
      "rewards= 0.12852161506221327\n",
      "Timestep 1\tScore: 16.40\tmin: 16.40\tmax: 16.40\n",
      " actions= [[1. 1.]]\n",
      "1049158  Evaluations Remaining\n",
      "rewards= -0.17039810736405325\n",
      "Timestep 2\tScore: 16.23\tmin: 16.23\tmax: 16.23\n",
      " actions= [[1. 1.]]\n",
      "1049157  Evaluations Remaining\n",
      "rewards= 0.09721457955462709\n",
      "Timestep 3\tScore: 16.33\tmin: 16.33\tmax: 16.33\n",
      " actions= [[1. 1.]]\n",
      "1049156  Evaluations Remaining\n",
      "rewards= -0.13163297590611345\n",
      "Episode 162\tScore: 16.20\tAverage Score: 18.67\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049155  Evaluations Remaining\n",
      "rewards= 16.11839775554234\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049154  Evaluations Remaining\n",
      "rewards= 0.08392095949003764\n",
      "Timestep 1\tScore: 16.20\tmin: 16.20\tmax: 16.20\n",
      " actions= [[1. 1.]]\n",
      "1049153  Evaluations Remaining\n",
      "rewards= -0.224249786287277\n",
      "Timestep 2\tScore: 15.98\tmin: 15.98\tmax: 15.98\n",
      " actions= [[1. 1.]]\n",
      "1049152  Evaluations Remaining\n",
      "rewards= 0.13978023286563035\n",
      "Timestep 3\tScore: 16.12\tmin: 16.12\tmax: 16.12\n",
      " actions= [[1. 1.]]\n",
      "1049151  Evaluations Remaining\n",
      "rewards= -0.025904417246997546\n",
      "Episode 163\tScore: 16.09\tAverage Score: 17.74\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049150  Evaluations Remaining\n",
      "rewards= 15.335302181757754\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049149  Evaluations Remaining\n",
      "rewards= -0.13993050385139316\n",
      "Timestep 1\tScore: 15.20\tmin: 15.20\tmax: 15.20\n",
      " actions= [[1. 1.]]\n",
      "1049148  Evaluations Remaining\n",
      "rewards= -0.20851278166176002\n",
      "Timestep 2\tScore: 14.99\tmin: 14.99\tmax: 14.99\n",
      " actions= [[1. 1.]]\n",
      "1049147  Evaluations Remaining\n",
      "rewards= -0.008175433575058122\n",
      "Timestep 3\tScore: 14.98\tmin: 14.98\tmax: 14.98\n",
      " actions= [[1. 1.]]\n",
      "1049146  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 0.25504168677355166\n",
      "Episode 164\tScore: 15.23\tAverage Score: 17.67\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049145  Evaluations Remaining\n",
      "rewards= 13.815264409123932\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049144  Evaluations Remaining\n",
      "rewards= -0.18274090234612306\n",
      "Timestep 1\tScore: 13.63\tmin: 13.63\tmax: 13.63\n",
      " actions= [[1. 1.]]\n",
      "1049143  Evaluations Remaining\n",
      "rewards= 0.2531504588271978\n",
      "Timestep 2\tScore: 13.89\tmin: 13.89\tmax: 13.89\n",
      " actions= [[1. 1.]]\n",
      "1049142  Evaluations Remaining\n",
      "rewards= 0.03488176683166655\n",
      "Timestep 3\tScore: 13.92\tmin: 13.92\tmax: 13.92\n",
      " actions= [[1. 1.]]\n",
      "1049141  Evaluations Remaining\n",
      "rewards= 0.09835017093568466\n",
      "Episode 165\tScore: 14.02\tAverage Score: 17.51\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049140  Evaluations Remaining\n",
      "rewards= 13.629427966575035\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049139  Evaluations Remaining\n",
      "rewards= 0.022003479572031193\n",
      "Timestep 1\tScore: 13.65\tmin: 13.65\tmax: 13.65\n",
      " actions= [[0. 0.]]\n",
      "1049138  Evaluations Remaining\n",
      "rewards= 0.1538428762431332\n",
      "Timestep 2\tScore: 13.81\tmin: 13.81\tmax: 13.81\n",
      " actions= [[1. 1.]]\n",
      "1049137  Evaluations Remaining\n",
      "rewards= 11.693679818740613\n",
      "Timestep 3\tScore: 25.50\tmin: 25.50\tmax: 25.50\n",
      " actions= [[1. 1.]]\n",
      "1049136  Evaluations Remaining\n",
      "rewards= -0.14498253072635148\n",
      "Episode 166\tScore: 25.35\tAverage Score: 18.62\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049135  Evaluations Remaining\n",
      "rewards= 13.747845078761435\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049134  Evaluations Remaining\n",
      "rewards= -0.1442349912012184\n",
      "Timestep 1\tScore: 13.60\tmin: 13.60\tmax: 13.60\n",
      " actions= [[1. 1.]]\n",
      "1049133  Evaluations Remaining\n",
      "rewards= 0.18258369739105662\n",
      "Timestep 2\tScore: 13.79\tmin: 13.79\tmax: 13.79\n",
      " actions= [[1. 1.]]\n",
      "1049132  Evaluations Remaining\n",
      "rewards= -0.16098836782399673\n",
      "Timestep 3\tScore: 13.63\tmin: 13.63\tmax: 13.63\n",
      " actions= [[1. 1.]]\n",
      "1049131  Evaluations Remaining\n",
      "rewards= -0.1231907010233444\n",
      "Episode 167\tScore: 13.50\tAverage Score: 18.56\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049130  Evaluations Remaining\n",
      "rewards= 14.228137222195281\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049129  Evaluations Remaining\n",
      "rewards= -0.08272236275101008\n",
      "Timestep 1\tScore: 14.15\tmin: 14.15\tmax: 14.15\n",
      " actions= [[1. 1.]]\n",
      "1049128  Evaluations Remaining\n",
      "rewards= 0.24477083956573953\n",
      "Timestep 2\tScore: 14.39\tmin: 14.39\tmax: 14.39\n",
      " actions= [[1. 1.]]\n",
      "1049127  Evaluations Remaining\n",
      "rewards= -0.07216469850708096\n",
      "Timestep 3\tScore: 14.32\tmin: 14.32\tmax: 14.32\n",
      " actions= [[1. 1.]]\n",
      "1049126  Evaluations Remaining\n",
      "rewards= -0.2199676609564878\n",
      "Episode 168\tScore: 14.10\tAverage Score: 17.38\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049125  Evaluations Remaining\n",
      "rewards= 15.536091726035888\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049124  Evaluations Remaining\n",
      "rewards= -0.21614793194653448\n",
      "Timestep 1\tScore: 15.32\tmin: 15.32\tmax: 15.32\n",
      " actions= [[1. 1.]]\n",
      "1049123  Evaluations Remaining\n",
      "rewards= 0.05432577159023744\n",
      "Timestep 2\tScore: 15.37\tmin: 15.37\tmax: 15.37\n",
      " actions= [[1. 1.]]\n",
      "1049122  Evaluations Remaining\n",
      "rewards= -0.06344435242829993\n",
      "Timestep 3\tScore: 15.31\tmin: 15.31\tmax: 15.31\n",
      " actions= [[1. 1.]]\n",
      "1049121  Evaluations Remaining\n",
      "rewards= -0.07305374086373773\n",
      "Episode 169\tScore: 15.24\tAverage Score: 17.33\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049120  Evaluations Remaining\n",
      "rewards= 13.794735528514774\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049119  Evaluations Remaining\n",
      "rewards= -0.13815154359593596\n",
      "Timestep 1\tScore: 13.66\tmin: 13.66\tmax: 13.66\n",
      " actions= [[1. 1.]]\n",
      "1049118  Evaluations Remaining\n",
      "rewards= -0.2464679145812716\n",
      "Timestep 2\tScore: 13.41\tmin: 13.41\tmax: 13.41\n",
      " actions= [[1. 1.]]\n",
      "1049117  Evaluations Remaining\n",
      "rewards= -0.2521023015979429\n",
      "Timestep 3\tScore: 13.16\tmin: 13.16\tmax: 13.16\n",
      " actions= [[1. 1.]]\n",
      "1049116  Evaluations Remaining\n",
      "rewards= -0.11032560973041372\n",
      "Episode 170\tScore: 13.05\tAverage Score: 17.03\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049115  Evaluations Remaining\n",
      "rewards= 16.36497058882102\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049114  Evaluations Remaining\n",
      "rewards= -0.1418728491398129\n",
      "Timestep 1\tScore: 16.22\tmin: 16.22\tmax: 16.22\n",
      " actions= [[1. 1.]]\n",
      "1049113  Evaluations Remaining\n",
      "rewards= 0.16771315954025035\n",
      "Timestep 2\tScore: 16.39\tmin: 16.39\tmax: 16.39\n",
      " actions= [[1. 1.]]\n",
      "1049112  Evaluations Remaining\n",
      "rewards= 0.2017866239251771\n",
      "Timestep 3\tScore: 16.59\tmin: 16.59\tmax: 16.59\n",
      " actions= [[1. 1.]]\n",
      "1049111  Evaluations Remaining\n",
      "rewards= -0.012412914524961849\n",
      "Episode 171\tScore: 16.58\tAverage Score: 15.94\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049110  Evaluations Remaining\n",
      "rewards= 13.884960324703313\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049109  Evaluations Remaining\n",
      "rewards= -0.16593592172724714\n",
      "Timestep 1\tScore: 13.72\tmin: 13.72\tmax: 13.72\n",
      " actions= [[1. 1.]]\n",
      "1049108  Evaluations Remaining\n",
      "rewards= 0.19602555992655502\n",
      "Timestep 2\tScore: 13.92\tmin: 13.92\tmax: 13.92\n",
      " actions= [[1. 1.]]\n",
      "1049107  Evaluations Remaining\n",
      "rewards= 0.08858244513710112\n",
      "Timestep 3\tScore: 14.00\tmin: 14.00\tmax: 14.00\n",
      " actions= [[1. 1.]]\n",
      "1049106  Evaluations Remaining\n",
      "rewards= -0.11023283463497213\n",
      "Episode 172\tScore: 13.89\tAverage Score: 15.71\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049105  Evaluations Remaining\n",
      "rewards= 16.120912810771816\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049104  Evaluations Remaining\n",
      "rewards= -0.11514546809580306\n",
      "Timestep 1\tScore: 16.01\tmin: 16.01\tmax: 16.01\n",
      " actions= [[1. 1.]]\n",
      "1049103  Evaluations Remaining\n",
      "rewards= 0.12511273598082528\n",
      "Timestep 2\tScore: 16.13\tmin: 16.13\tmax: 16.13\n",
      " actions= [[1. 1.]]\n",
      "1049102  Evaluations Remaining\n",
      "rewards= -0.15469568103837084\n",
      "Timestep 3\tScore: 15.98\tmin: 15.98\tmax: 15.98\n",
      " actions= [[0. 0.]]\n",
      "1049101  Evaluations Remaining\n",
      "rewards= 0.09134795614166613\n",
      "Episode 173\tScore: 16.07\tAverage Score: 15.70\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049100  Evaluations Remaining\n",
      "rewards= 13.556816064599058\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049099  Evaluations Remaining\n",
      "rewards= -0.16771638277578838\n",
      "Timestep 1\tScore: 13.39\tmin: 13.39\tmax: 13.39\n",
      " actions= [[1. 1.]]\n",
      "1049098  Evaluations Remaining\n",
      "rewards= 0.25572614977836716\n",
      "Timestep 2\tScore: 13.64\tmin: 13.64\tmax: 13.64\n",
      " actions= [[1. 1.]]\n",
      "1049097  Evaluations Remaining\n",
      "rewards= -0.12348226854340094\n",
      "Timestep 3\tScore: 13.52\tmin: 13.52\tmax: 13.52\n",
      " actions= [[1. 1.]]\n",
      "1049096  Evaluations Remaining\n",
      "rewards= -0.08297989083105772\n",
      "Episode 174\tScore: 13.44\tAverage Score: 15.52\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049095  Evaluations Remaining\n",
      "rewards= 14.956770449889053\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049094  Evaluations Remaining\n",
      "rewards= -0.177954249363657\n",
      "Timestep 1\tScore: 14.78\tmin: 14.78\tmax: 14.78\n",
      " actions= [[1. 1.]]\n",
      "1049093  Evaluations Remaining\n",
      "rewards= -0.2263392752865312\n",
      "Timestep 2\tScore: 14.55\tmin: 14.55\tmax: 14.55\n",
      " actions= [[1. 1.]]\n",
      "1049092  Evaluations Remaining\n",
      "rewards= -0.2510221466092255\n",
      "Timestep 3\tScore: 14.30\tmin: 14.30\tmax: 14.30\n",
      " actions= [[1. 1.]]\n",
      "1049091  Evaluations Remaining\n",
      "rewards= 0.05393310387159822\n",
      "Episode 175\tScore: 14.36\tAverage Score: 15.56\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049090  Evaluations Remaining\n",
      "rewards= 13.542366328236053\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049089  Evaluations Remaining\n",
      "rewards= 0.14003860138375535\n",
      "Timestep 1\tScore: 13.68\tmin: 13.68\tmax: 13.68\n",
      " actions= [[1. 1.]]\n",
      "1049088  Evaluations Remaining\n",
      "rewards= 0.17394646070777853\n",
      "Timestep 2\tScore: 13.86\tmin: 13.86\tmax: 13.86\n",
      " actions= [[1. 1.]]\n",
      "1049087  Evaluations Remaining\n",
      "rewards= -0.23519725810476544\n",
      "Timestep 3\tScore: 13.62\tmin: 13.62\tmax: 13.62\n",
      " actions= [[1. 1.]]\n",
      "1049086  Evaluations Remaining\n",
      "rewards= -0.18459218740651684\n",
      "Episode 176\tScore: 13.44\tAverage Score: 14.37\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049085  Evaluations Remaining\n",
      "rewards= 14.914097454650744\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049084  Evaluations Remaining\n",
      "rewards= -0.18808462355386224\n",
      "Timestep 1\tScore: 14.73\tmin: 14.73\tmax: 14.73\n",
      " actions= [[1. 1.]]\n",
      "1049083  Evaluations Remaining\n",
      "rewards= 0.2382073760327552\n",
      "Timestep 2\tScore: 14.96\tmin: 14.96\tmax: 14.96\n",
      " actions= [[1. 1.]]\n",
      "1049082  Evaluations Remaining\n",
      "rewards= -0.00653685480971955\n",
      "Timestep 3\tScore: 14.96\tmin: 14.96\tmax: 14.96\n",
      " actions= [[1. 1.]]\n",
      "1049081  Evaluations Remaining\n",
      "rewards= -0.0441549402952881\n",
      "Episode 177\tScore: 14.91\tAverage Score: 14.51\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049080  Evaluations Remaining\n",
      "rewards= 14.278693731987701\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049079  Evaluations Remaining\n",
      "rewards= -0.20321991169403297\n",
      "Timestep 1\tScore: 14.08\tmin: 14.08\tmax: 14.08\n",
      " actions= [[1. 1.]]\n",
      "1049078  Evaluations Remaining\n",
      "rewards= 0.12074998166541029\n",
      "Timestep 2\tScore: 14.20\tmin: 14.20\tmax: 14.20\n",
      " actions= [[1. 1.]]\n",
      "1049077  Evaluations Remaining\n",
      "rewards= -0.019769995345389813\n",
      "Timestep 3\tScore: 14.18\tmin: 14.18\tmax: 14.18\n",
      " actions= [[1. 1.]]\n",
      "1049076  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 0.18409228564340596\n",
      "Episode 178\tScore: 14.36\tAverage Score: 14.53\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049075  Evaluations Remaining\n",
      "rewards= 16.44430983938643\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049074  Evaluations Remaining\n",
      "rewards= -0.09904742781319076\n",
      "Timestep 1\tScore: 16.35\tmin: 16.35\tmax: 16.35\n",
      " actions= [[1. 1.]]\n",
      "1049073  Evaluations Remaining\n",
      "rewards= -0.0725640720369678\n",
      "Timestep 2\tScore: 16.27\tmin: 16.27\tmax: 16.27\n",
      " actions= [[1. 1.]]\n",
      "1049072  Evaluations Remaining\n",
      "rewards= 0.06531213047630757\n",
      "Timestep 3\tScore: 16.34\tmin: 16.34\tmax: 16.34\n",
      " actions= [[1. 1.]]\n",
      "1049071  Evaluations Remaining\n",
      "rewards= -0.06406010574218213\n",
      "Episode 179\tScore: 16.27\tAverage Score: 14.64\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049070  Evaluations Remaining\n",
      "rewards= 14.738120232906246\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049069  Evaluations Remaining\n",
      "rewards= -0.21615682654747204\n",
      "Timestep 1\tScore: 14.52\tmin: 14.52\tmax: 14.52\n",
      " actions= [[1. 1.]]\n",
      "1049068  Evaluations Remaining\n",
      "rewards= 0.025404497578825236\n",
      "Timestep 2\tScore: 14.55\tmin: 14.55\tmax: 14.55\n",
      " actions= [[1. 1.]]\n",
      "1049067  Evaluations Remaining\n",
      "rewards= 0.06221878180583307\n",
      "Timestep 3\tScore: 14.61\tmin: 14.61\tmax: 14.61\n",
      " actions= [[1. 1.]]\n",
      "1049066  Evaluations Remaining\n",
      "rewards= 0.2578106269124123\n",
      "Episode 180\tScore: 14.87\tAverage Score: 14.82\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049065  Evaluations Remaining\n",
      "rewards= 15.026962999746946\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049064  Evaluations Remaining\n",
      "rewards= -0.02572017632354129\n",
      "Timestep 1\tScore: 15.00\tmin: 15.00\tmax: 15.00\n",
      " actions= [[1. 1.]]\n",
      "1049063  Evaluations Remaining\n",
      "rewards= 0.2315625826918284\n",
      "Timestep 2\tScore: 15.23\tmin: 15.23\tmax: 15.23\n",
      " actions= [[1. 1.]]\n",
      "1049062  Evaluations Remaining\n",
      "rewards= 0.059048963562526424\n",
      "Timestep 3\tScore: 15.29\tmin: 15.29\tmax: 15.29\n",
      " actions= [[1. 1.]]\n",
      "1049061  Evaluations Remaining\n",
      "rewards= 0.27081974582722923\n",
      "Episode 181\tScore: 15.56\tAverage Score: 14.72\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049060  Evaluations Remaining\n",
      "rewards= 14.681411062842272\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049059  Evaluations Remaining\n",
      "rewards= -0.2533706398426099\n",
      "Timestep 1\tScore: 14.43\tmin: 14.43\tmax: 14.43\n",
      " actions= [[1. 1.]]\n",
      "1049058  Evaluations Remaining\n",
      "rewards= -0.22761647500512439\n",
      "Timestep 2\tScore: 14.20\tmin: 14.20\tmax: 14.20\n",
      " actions= [[1. 1.]]\n",
      "1049057  Evaluations Remaining\n",
      "rewards= -0.06902676138253039\n",
      "Timestep 3\tScore: 14.13\tmin: 14.13\tmax: 14.13\n",
      " actions= [[1. 1.]]\n",
      "1049056  Evaluations Remaining\n",
      "rewards= 0.23511817823755887\n",
      "Episode 182\tScore: 14.37\tAverage Score: 14.76\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049055  Evaluations Remaining\n",
      "rewards= 16.216110338797037\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049054  Evaluations Remaining\n",
      "rewards= -0.1578738405978224\n",
      "Timestep 1\tScore: 16.06\tmin: 16.06\tmax: 16.06\n",
      " actions= [[1. 1.]]\n",
      "1049053  Evaluations Remaining\n",
      "rewards= -0.26584287540945395\n",
      "Timestep 2\tScore: 15.79\tmin: 15.79\tmax: 15.79\n",
      " actions= [[1. 1.]]\n",
      "1049052  Evaluations Remaining\n",
      "rewards= 0.051326163625473153\n",
      "Timestep 3\tScore: 15.84\tmin: 15.84\tmax: 15.84\n",
      " actions= [[1. 1.]]\n",
      "1049051  Evaluations Remaining\n",
      "rewards= -0.1719735537621343\n",
      "Episode 183\tScore: 15.67\tAverage Score: 14.72\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049050  Evaluations Remaining\n",
      "rewards= 15.239623891408907\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049049  Evaluations Remaining\n",
      "rewards= -0.043207689363292445\n",
      "Timestep 1\tScore: 15.20\tmin: 15.20\tmax: 15.20\n",
      " actions= [[1. 1.]]\n",
      "1049048  Evaluations Remaining\n",
      "rewards= -0.25380417286629164\n",
      "Timestep 2\tScore: 14.94\tmin: 14.94\tmax: 14.94\n",
      " actions= [[1. 1.]]\n",
      "1049047  Evaluations Remaining\n",
      "rewards= -0.19093858150530485\n",
      "Timestep 3\tScore: 14.75\tmin: 14.75\tmax: 14.75\n",
      " actions= [[1. 1.]]\n",
      "1049046  Evaluations Remaining\n",
      "rewards= -0.18643655059279807\n",
      "Episode 184\tScore: 14.57\tAverage Score: 14.84\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049045  Evaluations Remaining\n",
      "rewards= 15.915272595144614\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049044  Evaluations Remaining\n",
      "rewards= -0.2302957756695152\n",
      "Timestep 1\tScore: 15.68\tmin: 15.68\tmax: 15.68\n",
      " actions= [[1. 1.]]\n",
      "1049043  Evaluations Remaining\n",
      "rewards= -0.08218780713057372\n",
      "Timestep 2\tScore: 15.60\tmin: 15.60\tmax: 15.60\n",
      " actions= [[1. 1.]]\n",
      "1049042  Evaluations Remaining\n",
      "rewards= -0.0746837196687955\n",
      "Timestep 3\tScore: 15.53\tmin: 15.53\tmax: 15.53\n",
      " actions= [[1. 1.]]\n",
      "1049041  Evaluations Remaining\n",
      "rewards= -0.004881256423830305\n",
      "Episode 185\tScore: 15.52\tAverage Score: 14.95\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049040  Evaluations Remaining\n",
      "rewards= 15.154581837772827\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049039  Evaluations Remaining\n",
      "rewards= -0.2631122427532011\n",
      "Timestep 1\tScore: 14.89\tmin: 14.89\tmax: 14.89\n",
      " actions= [[1. 1.]]\n",
      "1049038  Evaluations Remaining\n",
      "rewards= 0.18987786823963493\n",
      "Timestep 2\tScore: 15.08\tmin: 15.08\tmax: 15.08\n",
      " actions= [[1. 1.]]\n",
      "1049037  Evaluations Remaining\n",
      "rewards= 0.2439015924694936\n",
      "Timestep 3\tScore: 15.33\tmin: 15.33\tmax: 15.33\n",
      " actions= [[1. 1.]]\n",
      "1049036  Evaluations Remaining\n",
      "rewards= 0.13397648796684303\n",
      "Episode 186\tScore: 15.46\tAverage Score: 15.16\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049035  Evaluations Remaining\n",
      "rewards= 14.475134471508841\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049034  Evaluations Remaining\n",
      "rewards= -0.2630954607458724\n",
      "Timestep 1\tScore: 14.21\tmin: 14.21\tmax: 14.21\n",
      " actions= [[1. 1.]]\n",
      "1049033  Evaluations Remaining\n",
      "rewards= 0.08731010244635673\n",
      "Timestep 2\tScore: 14.30\tmin: 14.30\tmax: 14.30\n",
      " actions= [[1. 1.]]\n",
      "1049032  Evaluations Remaining\n",
      "rewards= -0.11286440710648193\n",
      "Timestep 3\tScore: 14.19\tmin: 14.19\tmax: 14.19\n",
      " actions= [[1. 1.]]\n",
      "1049031  Evaluations Remaining\n",
      "rewards= 0.19660051127955658\n",
      "Episode 187\tScore: 14.38\tAverage Score: 15.10\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049030  Evaluations Remaining\n",
      "rewards= 16.15260227893117\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049029  Evaluations Remaining\n",
      "rewards= 0.19275058601869866\n",
      "Timestep 1\tScore: 16.35\tmin: 16.35\tmax: 16.35\n",
      " actions= [[1. 1.]]\n",
      "1049028  Evaluations Remaining\n",
      "rewards= 0.050429623405056745\n",
      "Timestep 2\tScore: 16.40\tmin: 16.40\tmax: 16.40\n",
      " actions= [[1. 1.]]\n",
      "1049027  Evaluations Remaining\n",
      "rewards= 0.13822135834866378\n",
      "Timestep 3\tScore: 16.53\tmin: 16.53\tmax: 16.53\n",
      " actions= [[1. 1.]]\n",
      "1049026  Evaluations Remaining\n",
      "rewards= -0.16967892021436004\n",
      "Episode 188\tScore: 16.36\tAverage Score: 15.30\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049025  Evaluations Remaining\n",
      "rewards= 14.470487928850163\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049024  Evaluations Remaining\n",
      "rewards= -0.1356778760591597\n",
      "Timestep 1\tScore: 14.33\tmin: 14.33\tmax: 14.33\n",
      " actions= [[1. 1.]]\n",
      "1049023  Evaluations Remaining\n",
      "rewards= -0.2546123375018561\n",
      "Timestep 2\tScore: 14.08\tmin: 14.08\tmax: 14.08\n",
      " actions= [[1. 1.]]\n",
      "1049022  Evaluations Remaining\n",
      "rewards= -0.06654916782592712\n",
      "Timestep 3\tScore: 14.01\tmin: 14.01\tmax: 14.01\n",
      " actions= [[1. 1.]]\n",
      "1049021  Evaluations Remaining\n",
      "rewards= -0.2505564662597384\n",
      "Episode 189\tScore: 13.76\tAverage Score: 15.05\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049020  Evaluations Remaining\n",
      "rewards= 15.396358664755699\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049019  Evaluations Remaining\n",
      "rewards= 0.12013349713355082\n",
      "Timestep 1\tScore: 15.52\tmin: 15.52\tmax: 15.52\n",
      " actions= [[1. 1.]]\n",
      "1049018  Evaluations Remaining\n",
      "rewards= 0.17663590493949766\n",
      "Timestep 2\tScore: 15.69\tmin: 15.69\tmax: 15.69\n",
      " actions= [[1. 1.]]\n",
      "1049017  Evaluations Remaining\n",
      "rewards= -0.2264347984111117\n",
      "Timestep 3\tScore: 15.47\tmin: 15.47\tmax: 15.47\n",
      " actions= [[1. 1.]]\n",
      "1049016  Evaluations Remaining\n",
      "rewards= -0.22239458076981933\n",
      "Episode 190\tScore: 15.24\tAverage Score: 15.09\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049015  Evaluations Remaining\n",
      "rewards= 15.226327680392846\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049014  Evaluations Remaining\n",
      "rewards= -0.08563612747094362\n",
      "Timestep 1\tScore: 15.14\tmin: 15.14\tmax: 15.14\n",
      " actions= [[1. 1.]]\n",
      "1049013  Evaluations Remaining\n",
      "rewards= -0.0506033760430884\n",
      "Timestep 2\tScore: 15.09\tmin: 15.09\tmax: 15.09\n",
      " actions= [[1. 1.]]\n",
      "1049012  Evaluations Remaining\n",
      "rewards= 0.12197620974154866\n",
      "Timestep 3\tScore: 15.21\tmin: 15.21\tmax: 15.21\n",
      " actions= [[1. 1.]]\n",
      "1049011  Evaluations Remaining\n",
      "rewards= 0.03440179652796704\n",
      "Episode 191\tScore: 15.25\tAverage Score: 15.06\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049010  Evaluations Remaining\n",
      "rewards= 14.88946543665067\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049009  Evaluations Remaining\n",
      "rewards= -0.19423366259100572\n",
      "Timestep 1\tScore: 14.70\tmin: 14.70\tmax: 14.70\n",
      " actions= [[1. 1.]]\n",
      "1049008  Evaluations Remaining\n",
      "rewards= 0.0647355730042447\n",
      "Timestep 2\tScore: 14.76\tmin: 14.76\tmax: 14.76\n",
      " actions= [[1. 1.]]\n",
      "1049007  Evaluations Remaining\n",
      "rewards= -0.0242292371653825\n",
      "Timestep 3\tScore: 14.74\tmin: 14.74\tmax: 14.74\n",
      " actions= [[1. 1.]]\n",
      "1049006  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= -0.2376755857900199\n",
      "Episode 192\tScore: 14.50\tAverage Score: 15.07\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049005  Evaluations Remaining\n",
      "rewards= 14.28187210580907\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049004  Evaluations Remaining\n",
      "rewards= 0.17611605653176454\n",
      "Timestep 1\tScore: 14.46\tmin: 14.46\tmax: 14.46\n",
      " actions= [[1. 1.]]\n",
      "1049003  Evaluations Remaining\n",
      "rewards= -0.11536859287445722\n",
      "Timestep 2\tScore: 14.34\tmin: 14.34\tmax: 14.34\n",
      " actions= [[1. 1.]]\n",
      "1049002  Evaluations Remaining\n",
      "rewards= 0.20902223060015546\n",
      "Timestep 3\tScore: 14.55\tmin: 14.55\tmax: 14.55\n",
      " actions= [[1. 1.]]\n",
      "1049001  Evaluations Remaining\n",
      "rewards= -0.07856068716660047\n",
      "Episode 193\tScore: 14.47\tAverage Score: 14.95\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1049000  Evaluations Remaining\n",
      "rewards= 15.19056440089859\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1048999  Evaluations Remaining\n",
      "rewards= -0.19370765013893765\n",
      "Timestep 1\tScore: 15.00\tmin: 15.00\tmax: 15.00\n",
      " actions= [[1. 1.]]\n",
      "1048998  Evaluations Remaining\n",
      "rewards= 0.2701655592565477\n",
      "Timestep 2\tScore: 15.27\tmin: 15.27\tmax: 15.27\n",
      " actions= [[1. 1.]]\n",
      "1048997  Evaluations Remaining\n",
      "rewards= 0.15500864628196132\n",
      "Timestep 3\tScore: 15.42\tmin: 15.42\tmax: 15.42\n",
      " actions= [[1. 1.]]\n",
      "1048996  Evaluations Remaining\n",
      "rewards= -0.19389293049178669\n",
      "Episode 194\tScore: 15.23\tAverage Score: 15.02\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1048995  Evaluations Remaining\n",
      "rewards= 13.928516764084286\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1048994  Evaluations Remaining\n",
      "rewards= 0.0758650905211149\n",
      "Timestep 1\tScore: 14.00\tmin: 14.00\tmax: 14.00\n",
      " actions= [[1. 1.]]\n",
      "1048993  Evaluations Remaining\n",
      "rewards= -0.15704728500897724\n",
      "Timestep 2\tScore: 13.85\tmin: 13.85\tmax: 13.85\n",
      " actions= [[1. 1.]]\n",
      "1048992  Evaluations Remaining\n",
      "rewards= 0.17628843570890984\n",
      "Timestep 3\tScore: 14.02\tmin: 14.02\tmax: 14.02\n",
      " actions= [[1. 1.]]\n",
      "1048991  Evaluations Remaining\n",
      "rewards= 0.07541942988487493\n",
      "Episode 195\tScore: 14.10\tAverage Score: 14.88\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1048990  Evaluations Remaining\n",
      "rewards= 14.889025707614394\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1048989  Evaluations Remaining\n",
      "rewards= 0.2459488214934189\n",
      "Timestep 1\tScore: 15.13\tmin: 15.13\tmax: 15.13\n",
      " actions= [[1. 1.]]\n",
      "1048988  Evaluations Remaining\n",
      "rewards= -0.04432321514695392\n",
      "Timestep 2\tScore: 15.09\tmin: 15.09\tmax: 15.09\n",
      " actions= [[1. 1.]]\n",
      "1048987  Evaluations Remaining\n",
      "rewards= -0.12833292127533058\n",
      "Timestep 3\tScore: 14.96\tmin: 14.96\tmax: 14.96\n",
      " actions= [[1. 1.]]\n",
      "1048986  Evaluations Remaining\n",
      "rewards= -0.02981220052214617\n",
      "Episode 196\tScore: 14.93\tAverage Score: 14.82\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1048985  Evaluations Remaining\n",
      "rewards= 15.991609425694696\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1048984  Evaluations Remaining\n",
      "rewards= 0.2649730882281198\n",
      "Timestep 1\tScore: 16.26\tmin: 16.26\tmax: 16.26\n",
      " actions= [[1. 1.]]\n",
      "1048983  Evaluations Remaining\n",
      "rewards= -0.07092761149615923\n",
      "Timestep 2\tScore: 16.19\tmin: 16.19\tmax: 16.19\n",
      " actions= [[1. 1.]]\n",
      "1048982  Evaluations Remaining\n",
      "rewards= 0.1254886821965453\n",
      "Timestep 3\tScore: 16.31\tmin: 16.31\tmax: 16.31\n",
      " actions= [[1. 1.]]\n",
      "1048981  Evaluations Remaining\n",
      "rewards= -0.18202600156867277\n",
      "Episode 197\tScore: 16.13\tAverage Score: 15.00\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1048980  Evaluations Remaining\n",
      "rewards= 14.264856841257666\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1048979  Evaluations Remaining\n",
      "rewards= -0.2249105642889817\n",
      "Timestep 1\tScore: 14.04\tmin: 14.04\tmax: 14.04\n",
      " actions= [[1. 1.]]\n",
      "1048978  Evaluations Remaining\n",
      "rewards= -0.003465845989970351\n",
      "Timestep 2\tScore: 14.04\tmin: 14.04\tmax: 14.04\n",
      " actions= [[1. 1.]]\n",
      "1048977  Evaluations Remaining\n",
      "rewards= 0.09716419477669369\n",
      "Timestep 3\tScore: 14.13\tmin: 14.13\tmax: 14.13\n",
      " actions= [[1. 1.]]\n",
      "1048976  Evaluations Remaining\n",
      "rewards= -0.09552563193130581\n",
      "Episode 198\tScore: 14.04\tAverage Score: 14.77\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1048975  Evaluations Remaining\n",
      "rewards= 16.32062588684614\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1048974  Evaluations Remaining\n",
      "rewards= 0.009835772610237381\n",
      "Timestep 1\tScore: 16.33\tmin: 16.33\tmax: 16.33\n",
      " actions= [[1. 1.]]\n",
      "1048973  Evaluations Remaining\n",
      "rewards= -0.026902071102261615\n",
      "Timestep 2\tScore: 16.30\tmin: 16.30\tmax: 16.30\n",
      " actions= [[1. 1.]]\n",
      "1048972  Evaluations Remaining\n",
      "rewards= -0.2603166188431052\n",
      "Timestep 3\tScore: 16.04\tmin: 16.04\tmax: 16.04\n",
      " actions= [[1. 1.]]\n",
      "1048971  Evaluations Remaining\n",
      "rewards= -0.26297413205569287\n",
      "Episode 199\tScore: 15.78\tAverage Score: 14.97\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1048970  Evaluations Remaining\n",
      "rewards= 14.644629977469867\n",
      "\n",
      " actions= [[1. 1.]]\n",
      "1048969  Evaluations Remaining\n",
      "rewards= -0.13485249857961668\n",
      "Timestep 1\tScore: 14.51\tmin: 14.51\tmax: 14.51\n",
      " actions= [[1. 1.]]\n",
      "1048968  Evaluations Remaining\n",
      "rewards= -0.20673696659292862\n",
      "Timestep 2\tScore: 14.30\tmin: 14.30\tmax: 14.30\n",
      " actions= [[1. 1.]]\n",
      "1048967  Evaluations Remaining\n",
      "rewards= 0.0164286193618004\n",
      "Timestep 3\tScore: 14.32\tmin: 14.32\tmax: 14.32\n",
      " actions= [[1. 1.]]\n",
      "1048966  Evaluations Remaining\n",
      "rewards= -0.03878897739320486\n",
      "Episode 200\tScore: 14.28\tAverage Score: 14.87\n",
      "Episode 200\tAverage Score: 14.87\n"
     ]
    }
   ],
   "source": [
    "def ddpg(n_episodes=200, max_t=15,target_score=600):\n",
    "    \"\"\" Deep Deterministic Policy Gradients\n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "    \"\"\"\n",
    "    scores_window = deque(maxlen=10)\n",
    "    scores = np.zeros(num_agents)\n",
    "    scores_episode = []\n",
    "    state_size=3\n",
    "    agent = Agent(state_size, action_size, random_seed=0)\n",
    "    epsilon=0.5\n",
    "\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        epsilon = 0.99*epsilon\n",
    "        agent.reset()\n",
    "        env.reset() \n",
    "        scores = np.zeros(num_agents) \n",
    "        next_states = np.array([0,0,0]).reshape(1,3)\n",
    "        for t in range(max_t):\n",
    "            states = next_states\n",
    "            actions = np.array(agent.act(states),dtype=\"float64\")\n",
    "            if epsilon > random.random() :\n",
    "                actions = np.random.randn(num_agents, action_size)    \n",
    "            actions = np.clip(actions, 0, 1)\n",
    "            print(\"\\n actions=\",actions)\n",
    "#             print(\"actions1=\",actions1)\n",
    "            next_states, rewards, dones, _ = env.evaluateAction(actions[0])  # send the action to the environment  \n",
    "            print(\"rewards=\",rewards)\n",
    "            next_states = np.append(actions[0],[rewards]).reshape(1, 3)\n",
    "            agent.step(t,states, actions, rewards, next_states, dones) \n",
    "            scores += rewards\n",
    "            if t % 20:\n",
    "                print('\\rTimestep {}\\tScore: {:.2f}\\tmin: {:.2f}\\tmax: {:.2f}'\n",
    "                      .format(t, np.mean(scores), np.min(scores), np.max(scores)), end=\"\") \n",
    "            if dones:\n",
    "                break \n",
    "        score = np.mean(scores)\n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores_episode.append(score)\n",
    "        epsilon = epsilon*0.99\n",
    "        print('\\rEpisode {}\\tScore: {:.2f}\\tAverage Score: {:.2f}'.format(i_episode, score, np.mean(scores_window)), end=\"\\n\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=target_score:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "            torch.save(Agent.actor_local.state_dict(), 'models/arm_actor.pth')\n",
    "            torch.save(Agent.critic_local.state_dict(), 'models/arm_critic.pth')\n",
    "            break\n",
    "            \n",
    "    return scores_episode\n",
    "\n",
    "scores = ddpg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.plot the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.title(\"KDD-2019-DRL-Malaria\")\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

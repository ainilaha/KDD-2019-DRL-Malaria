{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Start the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "# !pip3 install git+https://github.com/slremy/netsapi --user --upgrade\n",
    "from netsapi.challenge import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ChallengeSeqDecEnvironment(experimentCount = 1050000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_agents=1\n",
    "states = env.state\n",
    "states = np.array([states]).reshape(1, 1)\n",
    "state_size = states.shape[1]\n",
    "action_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of each action: 2\n",
      "There are 1 agents. Each observes a state with length: 1\n",
      "The state for the first agent looks like: [[1]]\n"
     ]
    }
   ],
   "source": [
    "print('Size of each action:', action_size)\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "1050000  Evaluations Remaining\n",
      "reward= 2.5183539074210244\n",
      "(1, 2)\n",
      "1049999  Evaluations Remaining\n",
      "reward= 10.237901956475731\n",
      "(1, 2)\n",
      "1049998  Evaluations Remaining\n",
      "reward= 57.73631140132107\n",
      "(1, 2)\n",
      "1049997  Evaluations Remaining\n",
      "reward= 106.91226729023971\n",
      "(1, 2)\n",
      "1049996  Evaluations Remaining\n",
      "reward= -0.1564864635595451\n",
      "True\n",
      "Total score (averaged over agents) this episode: 177.248348091898\n"
     ]
    }
   ],
   "source": [
    "env.reset()     # reset the environment    \n",
    "states = np.array([env.state]).reshape(1, 1) # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, 0, 1)                  # all actions between -1 and 1\n",
    "    print(actions.shape)\n",
    " \n",
    "    next_states, reward, done, _ = env.evaluateAction(actions[0])           # send all actions to tne environment\n",
    "    scores += reward                        # update the score (for each agent)\n",
    "    print(\"reward=\",reward)\n",
    "    states = next_states                              # roll over states to next time step\n",
    "    if np.any(done): \n",
    "        print(done)\n",
    "        # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.random.randn(1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Take Actions with DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import deque\n",
    "from ddpg_agent import Agent\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising ReplayBuffer\n",
      "actions= [[0.33799848 0.99142018]]\n",
      "1049995  Evaluations Remaining\n",
      "rewards= 62.74838383090377\n",
      "actions= [[0. 1.]]\n",
      "1049994  Evaluations Remaining\n",
      "rewards= 0.18291515094208322\n",
      "Timestep 1\tScore: 62.93\tmin: 62.93\tmax: 62.93actions= [[0. 0.]]\n",
      "1049993  Evaluations Remaining\n",
      "rewards= -0.03697142316134361\n",
      "Timestep 2\tScore: 62.89\tmin: 62.89\tmax: 62.89actions= [[0. 0.]]\n",
      "1049992  Evaluations Remaining\n",
      "rewards= 0.14627628209763843\n",
      "Timestep 3\tScore: 63.04\tmin: 63.04\tmax: 63.04actions= [[0.30980161 0.42169529]]\n",
      "1049991  Evaluations Remaining\n",
      "rewards= 48.3163137150599\n",
      "Episode 1\tScore: 111.36\tAverage Score: 111.36.36\n",
      "actions= [[0.         0.11155517]]\n",
      "1049990  Evaluations Remaining\n",
      "rewards= 39.99678069179324\n",
      "actions= [[0. 0.]]\n",
      "1049989  Evaluations Remaining\n",
      "rewards= -0.08391191489663186\n",
      "Timestep 1\tScore: 39.91\tmin: 39.91\tmax: 39.91actions= [[0.24219146 0.39465699]]\n",
      "1049988  Evaluations Remaining\n",
      "rewards= 15.966391669567528\n",
      "Timestep 2\tScore: 55.88\tmin: 55.88\tmax: 55.88actions= [[0. 0.]]\n",
      "1049987  Evaluations Remaining\n",
      "rewards= 0.24386120409203116\n",
      "Timestep 3\tScore: 56.12\tmin: 56.12\tmax: 56.12actions= [[0.3546105 0.4657886]]\n",
      "1049986  Evaluations Remaining\n",
      "rewards= 37.006818540760314\n",
      "Episode 2\tScore: 93.13\tAverage Score: 102.243\n",
      "actions= [[0.28968554 1.        ]]\n",
      "1049985  Evaluations Remaining\n",
      "rewards= 81.59994460734289\n",
      "actions= [[0. 0.]]\n",
      "1049984  Evaluations Remaining\n",
      "rewards= 0.18256701342185755\n",
      "Timestep 1\tScore: 81.78\tmin: 81.78\tmax: 81.78actions= [[0.2720136  0.22814365]]\n",
      "1049983  Evaluations Remaining\n",
      "rewards= -54.51908158205793\n",
      "Timestep 2\tScore: 27.26\tmin: 27.26\tmax: 27.26actions= [[0. 0.]]\n",
      "1049982  Evaluations Remaining\n",
      "rewards= 0.07849155362467819\n",
      "Timestep 3\tScore: 27.34\tmin: 27.34\tmax: 27.34actions= [[0. 1.]]\n",
      "1049981  Evaluations Remaining\n",
      "rewards= 95.75507592481422\n",
      "Episode 3\tScore: 123.10\tAverage Score: 109.19.10\n",
      "actions= [[0.26432457 0.58365695]]\n",
      "1049980  Evaluations Remaining\n",
      "rewards= 24.267097898343547\n",
      "actions= [[0.11860957 0.15587035]]\n",
      "1049979  Evaluations Remaining\n",
      "rewards= 5.604155535366914\n",
      "Timestep 1\tScore: 29.87\tmin: 29.87\tmax: 29.87actions= [[0.         0.44797293]]\n",
      "1049978  Evaluations Remaining\n",
      "rewards= 13.664127144286631\n",
      "Timestep 2\tScore: 43.54\tmin: 43.54\tmax: 43.54actions= [[0.37412613 0.68432988]]\n",
      "1049977  Evaluations Remaining\n",
      "rewards= 14.271723636199326\n",
      "Timestep 3\tScore: 57.81\tmin: 57.81\tmax: 57.81actions= [[0.94811912 0.        ]]\n",
      "1049976  Evaluations Remaining\n",
      "rewards= 35.235434455350706\n",
      "Episode 4\tScore: 93.04\tAverage Score: 105.164\n",
      "actions= [[0.08645808 0.03766264]]\n",
      "1049975  Evaluations Remaining\n",
      "rewards= 3.9098894302475133\n",
      "actions= [[0.51132351 1.        ]]\n",
      "1049974  Evaluations Remaining\n",
      "rewards= 21.62127032007206\n",
      "Timestep 1\tScore: 25.53\tmin: 25.53\tmax: 25.53actions= [[0. 1.]]\n",
      "1049973  Evaluations Remaining\n",
      "rewards= 0.1695492046958953\n",
      "Timestep 2\tScore: 25.70\tmin: 25.70\tmax: 25.70actions= [[0.52566739 0.        ]]\n",
      "1049972  Evaluations Remaining\n",
      "rewards= 29.038796039067343\n",
      "Timestep 3\tScore: 54.74\tmin: 54.74\tmax: 54.74actions= [[0.00780471 1.        ]]\n",
      "1049971  Evaluations Remaining\n",
      "rewards= 90.9585591788499\n",
      "Episode 5\tScore: 145.70\tAverage Score: 113.26.70\n",
      "actions= [[0.        0.0811267]]\n",
      "1049970  Evaluations Remaining\n",
      "rewards= 17.70916037902383\n",
      "actions= [[0.12285262 0.22716561]]\n",
      "1049969  Evaluations Remaining\n",
      "rewards= 8.665523121005346\n",
      "Timestep 1\tScore: 26.37\tmin: 26.37\tmax: 26.37actions= [[0. 0.]]\n",
      "1049968  Evaluations Remaining\n",
      "rewards= 0.12479235671375433\n",
      "Timestep 2\tScore: 26.50\tmin: 26.50\tmax: 26.50actions= [[0.36408868 0.29205638]]\n",
      "1049967  Evaluations Remaining\n",
      "rewards= -13.176903354075009\n",
      "Timestep 3\tScore: 13.32\tmin: 13.32\tmax: 13.32actions= [[0.46701288 0.41695011]]\n",
      "1049966  Evaluations Remaining\n",
      "rewards= -15.113741030631859\n",
      "Episode 6\tScore: -1.79\tAverage Score: 90.6479\n",
      "actions= [[0.         0.45990323]]\n",
      "1049965  Evaluations Remaining\n",
      "rewards= 21.382453933278068\n",
      "actions= [[0.21641538 0.22768061]]\n",
      "1049964  Evaluations Remaining\n",
      "rewards= -34.8322074787339\n",
      "Timestep 1\tScore: -13.45\tmin: -13.45\tmax: -13.45actions= [[0.33043778 0.19966714]]\n",
      "1049963  Evaluations Remaining\n",
      "rewards= -79.34725093875795\n",
      "Timestep 2\tScore: -92.80\tmin: -92.80\tmax: -92.80actions= [[0.36586121 0.28543255]]\n",
      "1049962  Evaluations Remaining\n",
      "rewards= -33.72233556064234\n",
      "Timestep 3\tScore: -126.52\tmin: -126.52\tmax: -126.52actions= [[0.55617114 0.28674672]]\n",
      "1049961  Evaluations Remaining\n",
      "rewards= -68.12157215436874\n",
      "Episode 7\tScore: -194.64\tAverage Score: 33.08194.64\n",
      "actions= [[0. 0.]]\n",
      "1049960  Evaluations Remaining\n",
      "rewards= 2.67298254731054\n",
      "actions= [[0.         0.10697689]]\n",
      "1049959  Evaluations Remaining\n",
      "rewards= 31.74441038502894\n",
      "Timestep 1\tScore: 34.42\tmin: 34.42\tmax: 34.42actions= [[0.23238592 0.07103011]]\n",
      "1049958  Evaluations Remaining\n",
      "rewards= -19.314615050379\n",
      "Timestep 2\tScore: 15.10\tmin: 15.10\tmax: 15.10actions= [[0.36723149 0.1569012 ]]\n",
      "1049957  Evaluations Remaining\n",
      "rewards= -101.91232699887408\n",
      "Timestep 3\tScore: -86.81\tmin: -86.81\tmax: -86.81actions= [[0.30512643 0.25006038]]\n",
      "1049956  Evaluations Remaining\n",
      "rewards= -20.507025782342765\n",
      "Episode 8\tScore: -107.32\tAverage Score: -13.0007.32\n",
      "actions= [[1. 0.]]\n",
      "1049955  Evaluations Remaining\n",
      "rewards= 100.49130194580746\n",
      "actions= [[1. 0.]]\n",
      "1049954  Evaluations Remaining\n",
      "rewards= -0.25418884744811887\n",
      "Timestep 1\tScore: 100.24\tmin: 100.24\tmax: 100.24actions= [[0.03246913 0.        ]]\n",
      "1049953  Evaluations Remaining\n",
      "rewards= 0.092311325996564\n",
      "Timestep 2\tScore: 100.33\tmin: 100.33\tmax: 100.33actions= [[0.33956346 0.17514287]]\n",
      "1049952  Evaluations Remaining\n",
      "rewards= -100.5038357828997\n",
      "Timestep 3\tScore: -0.17\tmin: -0.17\tmax: -0.17actions= [[0.69384182 0.3730982 ]]\n",
      "1049951  Evaluations Remaining\n",
      "rewards= -0.9248542178711774\n",
      "Episode 9\tScore: -1.10\tAverage Score: -31.830\n",
      "actions= [[0. 0.]]\n",
      "1049950  Evaluations Remaining\n",
      "rewards= 2.5043635295342512\n",
      "actions= [[0.8895995  0.06855005]]\n",
      "1049949  Evaluations Remaining\n",
      "rewards= 34.66260391126452\n",
      "Timestep 1\tScore: 37.17\tmin: 37.17\tmax: 37.17actions= [[0.02727415 0.0128109 ]]\n",
      "1049948  Evaluations Remaining\n",
      "rewards= 0.7604706987296712\n",
      "Timestep 2\tScore: 37.93\tmin: 37.93\tmax: 37.93actions= [[0.05075444 0.07228634]]\n",
      "1049947  Evaluations Remaining\n",
      "rewards= 11.261519696475393\n",
      "Timestep 3\tScore: 49.19\tmin: 49.19\tmax: 49.19actions= [[0. 0.]]\n",
      "1049946  Evaluations Remaining\n",
      "rewards= -0.10474653472650175\n",
      "Episode 10\tScore: 49.08\tAverage Score: -51.15\n",
      "actions= [[0.46770109 0.        ]]\n",
      "1049945  Evaluations Remaining\n",
      "rewards= 21.376841837100834\n",
      "actions= [[0.         0.30014364]]\n",
      "1049944  Evaluations Remaining\n",
      "rewards= 10.586860657865161\n",
      "Timestep 1\tScore: 31.96\tmin: 31.96\tmax: 31.96actions= [[0. 0.]]\n",
      "1049943  Evaluations Remaining\n",
      "rewards= -0.217483842722769\n",
      "Timestep 2\tScore: 31.75\tmin: 31.75\tmax: 31.75actions= [[0.54356716 0.        ]]\n",
      "1049942  Evaluations Remaining\n",
      "rewards= 26.410612185091754\n",
      "Timestep 3\tScore: 58.16\tmin: 58.16\tmax: 58.16actions= [[0.         0.62798082]]\n",
      "1049941  Evaluations Remaining\n",
      "rewards= 37.99373265712489\n",
      "Episode 11\tScore: 96.15\tAverage Score: -31.56\n",
      "actions= [[0.         0.29309836]]\n",
      "1049940  Evaluations Remaining\n",
      "rewards= 13.094572701133462\n",
      "actions= [[0.0957421  0.07477055]]\n",
      "1049939  Evaluations Remaining\n",
      "rewards= 1.9088632765837406\n",
      "Timestep 1\tScore: 15.00\tmin: 15.00\tmax: 15.00actions= [[0. 1.]]\n",
      "1049938  Evaluations Remaining\n",
      "rewards= 89.23935442289671\n",
      "Timestep 2\tScore: 104.24\tmin: 104.24\tmax: 104.24actions= [[1.         0.00614323]]\n",
      "1049937  Evaluations Remaining\n",
      "rewards= 89.42378244406636\n",
      "Timestep 3\tScore: 193.67\tmin: 193.67\tmax: 193.67actions= [[0.17412055 0.2598536 ]]\n",
      "1049936  Evaluations Remaining\n",
      "rewards= 15.034335700630564\n",
      "Episode 12\tScore: 208.70\tAverage Score: 49.10.70\n",
      "actions= [[0.05031428 0.05382128]]\n",
      "1049935  Evaluations Remaining\n",
      "rewards= 8.905882956825097\n",
      "actions= [[0.10824686 0.11834756]]\n",
      "1049934  Evaluations Remaining\n",
      "rewards= 16.51772835799621\n",
      "Timestep 1\tScore: 25.42\tmin: 25.42\tmax: 25.42actions= [[0. 0.]]\n",
      "1049933  Evaluations Remaining\n",
      "rewards= 0.1148737750244484\n",
      "Timestep 2\tScore: 25.54\tmin: 25.54\tmax: 25.54actions= [[1. 0.]]\n",
      "1049932  Evaluations Remaining\n",
      "rewards= 93.79518465131937\n",
      "Timestep 3\tScore: 119.33\tmin: 119.33\tmax: 119.33actions= [[0.53175722 0.        ]]\n",
      "1049931  Evaluations Remaining\n",
      "rewards= 0.2688988248611275\n",
      "Episode 13\tScore: 119.60\tAverage Score: 94.49.60\n",
      "actions= [[1. 0.]]\n",
      "1049930  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 103.90806904772782\n",
      "actions= [[0.91475889 0.        ]]\n",
      "1049929  Evaluations Remaining\n",
      "rewards= -0.08711304418544996\n",
      "Timestep 1\tScore: 103.82\tmin: 103.82\tmax: 103.82actions= [[0.14483629 0.07096702]]\n",
      "1049928  Evaluations Remaining\n",
      "rewards= 13.380915887698794\n",
      "Timestep 2\tScore: 117.20\tmin: 117.20\tmax: 117.20actions= [[0.20826422 0.16228896]]\n",
      "1049927  Evaluations Remaining\n",
      "rewards= -19.79899352250086\n",
      "Timestep 3\tScore: 97.40\tmin: 97.40\tmax: 97.40actions= [[0.23551352 0.27404426]]\n",
      "1049926  Evaluations Remaining\n",
      "rewards= -13.231705666505361\n",
      "Episode 14\tScore: 84.17\tAverage Score: 111.54\n",
      "actions= [[0.01694316 0.09141508]]\n",
      "1049925  Evaluations Remaining\n",
      "rewards= 21.905015459027215\n",
      "actions= [[0.16476093 0.10501895]]\n",
      "1049924  Evaluations Remaining\n",
      "rewards= -6.070867828544676\n",
      "Timestep 1\tScore: 15.83\tmin: 15.83\tmax: 15.83actions= [[0.25448424 0.09562354]]\n",
      "1049923  Evaluations Remaining\n",
      "rewards= -20.222353476550023\n",
      "Timestep 2\tScore: -4.39\tmin: -4.39\tmax: -4.39actions= [[0.40137616 0.15132938]]\n",
      "1049922  Evaluations Remaining\n",
      "rewards= -91.82791824103828\n",
      "Timestep 3\tScore: -96.22\tmin: -96.22\tmax: -96.22actions= [[0.39204544 0.16102929]]\n",
      "1049921  Evaluations Remaining\n",
      "rewards= -50.75548769419404\n",
      "Episode 15\tScore: -146.97\tAverage Score: 72.3346.97\n",
      "actions= [[0.        0.0941522]]\n",
      "1049920  Evaluations Remaining\n",
      "rewards= 28.993276754558106\n",
      "actions= [[0.         0.09352601]]\n",
      "1049919  Evaluations Remaining\n",
      "rewards= 19.107813695896493\n",
      "Timestep 1\tScore: 48.10\tmin: 48.10\tmax: 48.10actions= [[0.11398479 0.12515768]]\n",
      "1049918  Evaluations Remaining\n",
      "rewards= 10.959174252282528\n",
      "Timestep 2\tScore: 59.06\tmin: 59.06\tmax: 59.06actions= [[1.        0.4814405]]\n",
      "1049917  Evaluations Remaining\n",
      "rewards= 46.84041413270278\n",
      "Timestep 3\tScore: 105.90\tmin: 105.90\tmax: 105.90actions= [[0.17357684 0.05499675]]\n",
      "1049916  Evaluations Remaining\n",
      "rewards= 2.615320764534792\n",
      "Episode 16\tScore: 108.52\tAverage Score: 74.80.52\n",
      "actions= [[0. 0.]]\n",
      "1049915  Evaluations Remaining\n",
      "rewards= 2.709423223581141\n",
      "actions= [[0. 0.]]\n",
      "1049914  Evaluations Remaining\n",
      "rewards= -0.2505397163947829\n",
      "Timestep 1\tScore: 2.46\tmin: 2.46\tmax: 2.46actions= [[0.42594287 0.        ]]\n",
      "1049913  Evaluations Remaining\n",
      "rewards= 13.856390855791705\n",
      "Timestep 2\tScore: 16.32\tmin: 16.32\tmax: 16.32actions= [[0.2505807 0.3136031]]\n",
      "1049912  Evaluations Remaining\n",
      "rewards= 0.2293336596407678\n",
      "Timestep 3\tScore: 16.54\tmin: 16.54\tmax: 16.54actions= [[0.38993439 0.44394478]]\n",
      "1049911  Evaluations Remaining\n",
      "rewards= -10.21840437914514\n",
      "Episode 17\tScore: 6.33\tAverage Score: 34.33\n",
      "actions= [[0.         0.07943288]]\n",
      "1049910  Evaluations Remaining\n",
      "rewards= 18.16877977743298\n",
      "actions= [[0.06111941 0.19970535]]\n",
      "1049909  Evaluations Remaining\n",
      "rewards= 33.01758251115587\n",
      "Timestep 1\tScore: 51.19\tmin: 51.19\tmax: 51.19actions= [[0.16779943 0.23390341]]\n",
      "1049908  Evaluations Remaining\n",
      "rewards= -5.3506083097880435\n",
      "Timestep 2\tScore: 45.84\tmin: 45.84\tmax: 45.84actions= [[0. 0.]]\n",
      "1049907  Evaluations Remaining\n",
      "rewards= -0.028715251318434554\n",
      "Timestep 3\tScore: 45.81\tmin: 45.81\tmax: 45.81actions= [[0.16395873 0.31641573]]\n",
      "1049906  Evaluations Remaining\n",
      "rewards= -0.5422397160809407\n",
      "Episode 18\tScore: 45.26\tAverage Score: 19.466\n",
      "actions= [[0.06726459 0.        ]]\n",
      "1049905  Evaluations Remaining\n",
      "rewards= 2.5508398424444385\n",
      "actions= [[0.05329176 0.02015652]]\n",
      "1049904  Evaluations Remaining\n",
      "rewards= 0.6811905097598987\n",
      "Timestep 1\tScore: 3.23\tmin: 3.23\tmax: 3.23actions= [[0.09102385 0.08575545]]\n",
      "1049903  Evaluations Remaining\n",
      "rewards= 9.251796614967764\n",
      "Timestep 2\tScore: 12.48\tmin: 12.48\tmax: 12.48actions= [[0.         0.54141604]]\n",
      "1049902  Evaluations Remaining\n",
      "rewards= 23.736177672873453\n",
      "Timestep 3\tScore: 36.22\tmin: 36.22\tmax: 36.22actions= [[0.1024807  0.16007419]]\n",
      "1049901  Evaluations Remaining\n",
      "rewards= 4.304640480671221\n",
      "Episode 19\tScore: 40.52\tAverage Score: 10.732\n",
      "actions= [[1. 0.]]\n",
      "1049900  Evaluations Remaining\n",
      "rewards= 93.4745399859998\n",
      "actions= [[0.01789728 0.01829972]]\n",
      "1049899  Evaluations Remaining\n",
      "rewards= 1.061480976053347\n",
      "Timestep 1\tScore: 94.54\tmin: 94.54\tmax: 94.54actions= [[0.09783331 0.17338845]]\n",
      "1049898  Evaluations Remaining\n",
      "rewards= 28.82595348870771\n",
      "Timestep 2\tScore: 123.36\tmin: 123.36\tmax: 123.36actions= [[0.13958888 0.2328835 ]]\n",
      "1049897  Evaluations Remaining\n",
      "rewards= 9.445596803426872\n",
      "Timestep 3\tScore: 132.81\tmin: 132.81\tmax: 132.81actions= [[0.19159791 0.24802598]]\n",
      "1049896  Evaluations Remaining\n",
      "rewards= -9.427505484127826\n",
      "Episode 20\tScore: 123.38\tAverage Score: 64.80.38\n",
      "actions= [[0.10244466 0.11354368]]\n",
      "1049895  Evaluations Remaining\n",
      "rewards= 19.435933696383906\n",
      "actions= [[0.15006851 0.28114009]]\n",
      "1049894  Evaluations Remaining\n",
      "rewards= 0.2983071150516685\n",
      "Timestep 1\tScore: 19.73\tmin: 19.73\tmax: 19.73actions= [[0.12854484 0.24556702]]\n",
      "1049893  Evaluations Remaining\n",
      "rewards= 20.7985456290522\n",
      "Timestep 2\tScore: 40.53\tmin: 40.53\tmax: 40.53actions= [[1.         0.09177045]]\n",
      "1049892  Evaluations Remaining\n",
      "rewards= 32.65892802843435\n",
      "Timestep 3\tScore: 73.19\tmin: 73.19\tmax: 73.19actions= [[0.40887739 0.        ]]\n",
      "1049891  Evaluations Remaining\n",
      "rewards= -0.06116740611692251\n",
      "Episode 21\tScore: 73.13\tAverage Score: 57.733\n",
      "actions= [[0. 1.]]\n",
      "1049890  Evaluations Remaining\n",
      "rewards= 100.75516310955332\n",
      "actions= [[0.21103189 0.17674548]]\n",
      "1049889  Evaluations Remaining\n",
      "rewards= 0.6161968930797168\n",
      "Timestep 1\tScore: 101.37\tmin: 101.37\tmax: 101.37actions= [[0.97148862 1.        ]]\n",
      "1049888  Evaluations Remaining\n",
      "rewards= 3.686585846607509\n",
      "Timestep 2\tScore: 105.06\tmin: 105.06\tmax: 105.06actions= [[0.19158824 0.4025304 ]]\n",
      "1049887  Evaluations Remaining\n",
      "rewards= 0.1275659525733861\n",
      "Timestep 3\tScore: 105.19\tmin: 105.19\tmax: 105.19actions= [[0.33109242 0.4221676 ]]\n",
      "1049886  Evaluations Remaining\n",
      "rewards= -33.622135968412984\n",
      "Episode 22\tScore: 71.56\tAverage Score: 70.776\n",
      "actions= [[0.         0.23482875]]\n",
      "1049885  Evaluations Remaining\n",
      "rewards= 25.07559771271636\n",
      "actions= [[0.         0.73360864]]\n",
      "1049884  Evaluations Remaining\n",
      "rewards= 32.1660069676544\n",
      "Timestep 1\tScore: 57.24\tmin: 57.24\tmax: 57.24actions= [[1.         0.79098413]]\n",
      "1049883  Evaluations Remaining\n",
      "rewards= 8.341972257085477\n",
      "Timestep 2\tScore: 65.58\tmin: 65.58\tmax: 65.58actions= [[0.0764941  0.18002021]]\n",
      "1049882  Evaluations Remaining\n",
      "rewards= 3.8084980240473256\n",
      "Timestep 3\tScore: 69.39\tmin: 69.39\tmax: 69.39actions= [[0.         0.97879326]]\n",
      "1049881  Evaluations Remaining\n",
      "rewards= 105.96651309877936\n",
      "Episode 23\tScore: 175.36\tAverage Score: 96.79.36\n",
      "actions= [[0.05955061 0.10513724]]\n",
      "1049880  Evaluations Remaining\n",
      "rewards= 25.0611459205613\n",
      "actions= [[0.22190362 0.14357458]]\n",
      "1049879  Evaluations Remaining\n",
      "rewards= -35.16908622124926\n",
      "Timestep 1\tScore: -10.11\tmin: -10.11\tmax: -10.11actions= [[1.         0.01062354]]\n",
      "1049878  Evaluations Remaining\n",
      "rewards= 58.994272756667584\n",
      "Timestep 2\tScore: 48.89\tmin: 48.89\tmax: 48.89actions= [[1. 0.]]\n",
      "1049877  Evaluations Remaining\n",
      "rewards= 0.23533912163670268\n",
      "Timestep 3\tScore: 49.12\tmin: 49.12\tmax: 49.12actions= [[0.47289053 0.37545037]]\n",
      "1049876  Evaluations Remaining\n",
      "rewards= 14.078496323949611\n",
      "Episode 24\tScore: 63.20\tAverage Score: 101.33\n",
      "actions= [[0.25042126 0.71471812]]\n",
      "1049875  Evaluations Remaining\n",
      "rewards= -15.17974454503348\n",
      "actions= [[0.08576919 0.12356993]]\n",
      "1049874  Evaluations Remaining\n",
      "rewards= 1.6045092398405525\n",
      "Timestep 1\tScore: -13.58\tmin: -13.58\tmax: -13.58actions= [[0.4459303 1.       ]]\n",
      "1049873  Evaluations Remaining\n",
      "rewards= 3.974448059217608\n",
      "Timestep 2\tScore: -9.60\tmin: -9.60\tmax: -9.60actions= [[0.72436563 1.        ]]\n",
      "1049872  Evaluations Remaining\n",
      "rewards= 13.075370744389996\n",
      "Timestep 3\tScore: 3.47\tmin: 3.47\tmax: 3.47actions= [[0.         0.86763516]]\n",
      "1049871  Evaluations Remaining\n",
      "rewards= -0.10104817087760809\n",
      "Episode 25\tScore: 3.37\tAverage Score: 77.33\n",
      "actions= [[0.0294909  0.36271325]]\n",
      "1049870  Evaluations Remaining\n",
      "rewards= 12.39473901578465\n",
      "actions= [[0.09614246 0.11729867]]\n",
      "1049869  Evaluations Remaining\n",
      "rewards= 5.738255721249107\n",
      "Timestep 1\tScore: 18.13\tmin: 18.13\tmax: 18.13actions= [[0.17054072 0.269586  ]]\n",
      "1049868  Evaluations Remaining\n",
      "rewards= -3.22620482145157\n",
      "Timestep 2\tScore: 14.91\tmin: 14.91\tmax: 14.91actions= [[0.24743436 0.35454836]]\n",
      "1049867  Evaluations Remaining\n",
      "rewards= -11.4441669273494\n",
      "Timestep 3\tScore: 3.46\tmin: 3.46\tmax: 3.46actions= [[0.34952876 0.489167  ]]\n",
      "1049866  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= -4.2742648718022425\n",
      "Episode 26\tScore: -0.81\tAverage Score: 62.541\n",
      "actions= [[0.10472085 0.        ]]\n",
      "1049865  Evaluations Remaining\n",
      "rewards= 2.657308712548765\n",
      "actions= [[0.17367338 0.0813415 ]]\n",
      "1049864  Evaluations Remaining\n",
      "rewards= -3.851056799837651\n",
      "Timestep 1\tScore: -1.19\tmin: -1.19\tmax: -1.19actions= [[0.30870202 0.1133804 ]]\n",
      "1049863  Evaluations Remaining\n",
      "rewards= -54.208633147194014\n",
      "Timestep 2\tScore: -55.40\tmin: -55.40\tmax: -55.40actions= [[0.42136747 0.16348062]]\n",
      "1049862  Evaluations Remaining\n",
      "rewards= -99.13515488816053\n",
      "Timestep 3\tScore: -154.54\tmin: -154.54\tmax: -154.54actions= [[1. 1.]]\n",
      "1049861  Evaluations Remaining\n",
      "rewards= 32.53003706126298\n",
      "Episode 27\tScore: -122.01\tAverage Score: 23.8222.01\n",
      "actions= [[0.         0.07879168]]\n",
      "1049860  Evaluations Remaining\n",
      "rewards= 18.752709139412037\n",
      "actions= [[0.06295254 0.20479731]]\n",
      "1049859  Evaluations Remaining\n",
      "rewards= 34.39897098216556\n",
      "Timestep 1\tScore: 53.15\tmin: 53.15\tmax: 53.15actions= [[0.87742342 0.91283399]]\n",
      "1049858  Evaluations Remaining\n",
      "rewards= -16.358400866108006\n",
      "Timestep 2\tScore: 36.79\tmin: 36.79\tmax: 36.79actions= [[0.13399241 0.        ]]\n",
      "1049857  Evaluations Remaining\n",
      "rewards= -0.06865882259226774\n",
      "Timestep 3\tScore: 36.72\tmin: 36.72\tmax: 36.72actions= [[1. 0.]]\n",
      "1049856  Evaluations Remaining\n",
      "rewards= 74.34815810042338\n",
      "Episode 28\tScore: 111.07\tAverage Score: 10.97.07\n",
      "actions= [[0.0477663 0.       ]]\n",
      "1049855  Evaluations Remaining\n",
      "rewards= 2.8896873260723646\n",
      "actions= [[0.01616959 0.09448939]]\n",
      "1049854  Evaluations Remaining\n",
      "rewards= 23.17214256395439\n",
      "Timestep 1\tScore: 26.06\tmin: 26.06\tmax: 26.06actions= [[0.04961612 0.17387728]]\n",
      "1049853  Evaluations Remaining\n",
      "rewards= 47.099943229641724\n",
      "Timestep 2\tScore: 73.16\tmin: 73.16\tmax: 73.16actions= [[0.         0.69634872]]\n",
      "1049852  Evaluations Remaining\n",
      "rewards= 31.047348848429277\n",
      "Timestep 3\tScore: 104.21\tmin: 104.21\tmax: 104.21actions= [[0.11011115 0.38552409]]\n",
      "1049851  Evaluations Remaining\n",
      "rewards= 14.558314603203904\n",
      "Episode 29\tScore: 118.77\tAverage Score: 22.08.77\n",
      "actions= [[0.40447113 0.        ]]\n",
      "1049850  Evaluations Remaining\n",
      "rewards= 16.108932853964248\n",
      "actions= [[0.01074934 0.11243264]]\n",
      "1049849  Evaluations Remaining\n",
      "rewards= 33.51246300595045\n",
      "Timestep 1\tScore: 49.62\tmin: 49.62\tmax: 49.62actions= [[0. 0.]]\n",
      "1049848  Evaluations Remaining\n",
      "rewards= -0.22258538358053315\n",
      "Timestep 2\tScore: 49.40\tmin: 49.40\tmax: 49.40actions= [[0.         0.03474707]]\n",
      "1049847  Evaluations Remaining\n",
      "rewards= 3.200173747312205\n",
      "Timestep 3\tScore: 52.60\tmin: 52.60\tmax: 52.60actions= [[0.34090415 0.33461428]]\n",
      "1049846  Evaluations Remaining\n",
      "rewards= -0.5339079606715997\n",
      "Episode 30\tScore: 52.07\tAverage Score: 31.827\n",
      "actions= [[0.03006788 0.62524211]]\n",
      "1049845  Evaluations Remaining\n",
      "rewards= 34.21289174926866\n",
      "actions= [[0.         0.19078778]]\n",
      "1049844  Evaluations Remaining\n",
      "rewards= 13.98491708113989\n",
      "Timestep 1\tScore: 48.20\tmin: 48.20\tmax: 48.20actions= [[0.         0.33023417]]\n",
      "1049843  Evaluations Remaining\n",
      "rewards= 12.378820174885538\n",
      "Timestep 2\tScore: 60.58\tmin: 60.58\tmax: 60.58actions= [[0.72627057 0.65162693]]\n",
      "1049842  Evaluations Remaining\n",
      "rewards= 7.2497291796168835\n",
      "Timestep 3\tScore: 67.83\tmin: 67.83\tmax: 67.83actions= [[0.0487033  0.31460381]]\n",
      "1049841  Evaluations Remaining\n",
      "rewards= 33.81706675454876\n",
      "Episode 31\tScore: 101.64\tAverage Score: 52.31.64\n",
      "actions= [[0.0179881  0.09048947]]\n",
      "1049840  Evaluations Remaining\n",
      "rewards= 25.094016395002214\n",
      "actions= [[1. 1.]]\n",
      "1049839  Evaluations Remaining\n",
      "rewards= -22.09064927769711\n",
      "Timestep 1\tScore: 3.00\tmin: 3.00\tmax: 3.00actions= [[0.14062697 0.49744672]]\n",
      "1049838  Evaluations Remaining\n",
      "rewards= 0.07191404633119625\n",
      "Timestep 2\tScore: 3.08\tmin: 3.08\tmax: 3.08actions= [[0.0902168  0.26511103]]\n",
      "1049837  Evaluations Remaining\n",
      "rewards= 28.946701101180963\n",
      "Timestep 3\tScore: 32.02\tmin: 32.02\tmax: 32.02actions= [[0.         0.73198675]]\n",
      "1049836  Evaluations Remaining\n",
      "rewards= 29.548441402005903\n",
      "Episode 32\tScore: 61.57\tAverage Score: 89.027\n",
      "actions= [[0.0007634  0.15435192]]\n",
      "1049835  Evaluations Remaining\n",
      "rewards= 56.21766502144531\n",
      "actions= [[0.10592489 0.35365486]]\n",
      "1049834  Evaluations Remaining\n",
      "rewards= 2.500392105033279\n",
      "Timestep 1\tScore: 58.72\tmin: 58.72\tmax: 58.72actions= [[0. 0.]]\n",
      "1049833  Evaluations Remaining\n",
      "rewards= -0.10784734930512041\n",
      "Timestep 2\tScore: 58.61\tmin: 58.61\tmax: 58.61actions= [[0.21234812 0.49269071]]\n",
      "1049832  Evaluations Remaining\n",
      "rewards= 13.550553461816996\n",
      "Timestep 3\tScore: 72.16\tmin: 72.16\tmax: 72.16actions= [[1.         0.66086679]]\n",
      "1049831  Evaluations Remaining\n",
      "rewards= 19.536594001304515\n",
      "Episode 33\tScore: 91.70\tAverage Score: 85.150\n",
      "actions= [[0. 0.]]\n",
      "1049830  Evaluations Remaining\n",
      "rewards= 2.773774840521853\n",
      "actions= [[0.13676262 0.39925224]]\n",
      "1049829  Evaluations Remaining\n",
      "rewards= 5.383307136669176\n",
      "Timestep 1\tScore: 8.16\tmin: 8.16\tmax: 8.16actions= [[0.13578416 0.42332578]]\n",
      "1049828  Evaluations Remaining\n",
      "rewards= 2.7940194315113955\n",
      "Timestep 2\tScore: 10.95\tmin: 10.95\tmax: 10.95actions= [[0.         0.56229789]]\n",
      "1049827  Evaluations Remaining\n",
      "rewards= 9.29771729392645\n",
      "Timestep 3\tScore: 20.25\tmin: 20.25\tmax: 20.25actions= [[0. 0.]]\n",
      "1049826  Evaluations Remaining\n",
      "rewards= 0.25290680506314445\n",
      "Episode 34\tScore: 20.50\tAverage Score: 65.500\n",
      "actions= [[0.         0.24592012]]\n",
      "1049825  Evaluations Remaining\n",
      "rewards= 20.226208513832763\n",
      "actions= [[0.17390764 0.31947643]]\n",
      "1049824  Evaluations Remaining\n",
      "rewards= -7.887121373706568\n",
      "Timestep 1\tScore: 12.34\tmin: 12.34\tmax: 12.34actions= [[0.19594468 0.37340471]]\n",
      "1049823  Evaluations Remaining\n",
      "rewards= -4.068106546255231\n",
      "Timestep 2\tScore: 8.27\tmin: 8.27\tmax: 8.27actions= [[0.25782478 0.33872882]]\n",
      "1049822  Evaluations Remaining\n",
      "rewards= -27.374979110502302\n",
      "Timestep 3\tScore: -19.10\tmin: -19.10\tmax: -19.10actions= [[0.1760876  0.51301068]]\n",
      "1049821  Evaluations Remaining\n",
      "rewards= 2.676138118603269\n",
      "Episode 35\tScore: -16.43\tAverage Score: 51.80.43\n",
      "actions= [[0.         0.26623851]]\n",
      "1049820  Evaluations Remaining\n",
      "rewards= 13.70298480345918\n",
      "actions= [[0.11395907 0.63005092]]\n",
      "1049819  Evaluations Remaining\n",
      "rewards= 11.36770376986351\n",
      "Timestep 1\tScore: 25.07\tmin: 25.07\tmax: 25.07actions= [[0.12155665 0.64913076]]\n",
      "1049818  Evaluations Remaining\n",
      "rewards= 5.486981139456619\n",
      "Timestep 2\tScore: 30.56\tmin: 30.56\tmax: 30.56actions= [[0.25737226 0.        ]]\n",
      "1049817  Evaluations Remaining\n",
      "rewards= 0.7920228191272973\n",
      "Timestep 3\tScore: 31.35\tmin: 31.35\tmax: 31.35actions= [[0.23741074 0.74686611]]\n",
      "1049816  Evaluations Remaining\n",
      "rewards= 16.623347597475977\n",
      "Episode 36\tScore: 47.97\tAverage Score: 41.067\n",
      "actions= [[0.         0.33868903]]\n",
      "1049815  Evaluations Remaining\n",
      "rewards= 13.987874514492916\n",
      "actions= [[0.11698905 0.60022736]]\n",
      "1049814  Evaluations Remaining\n",
      "rewards= 6.756213381474279\n",
      "Timestep 1\tScore: 20.74\tmin: 20.74\tmax: 20.74actions= [[0.1311122  0.62827736]]\n",
      "1049813  Evaluations Remaining\n",
      "rewards= 3.0498884392166503\n",
      "Timestep 2\tScore: 23.79\tmin: 23.79\tmax: 23.79actions= [[0.         0.38269431]]\n",
      "1049812  Evaluations Remaining\n",
      "rewards= 47.25794039829565\n",
      "Timestep 3\tScore: 71.05\tmin: 71.05\tmax: 71.05actions= [[0.3162795  0.73813015]]\n",
      "1049811  Evaluations Remaining\n",
      "rewards= 48.351291111656586\n",
      "Episode 37\tScore: 119.40\tAverage Score: 52.63.40\n",
      "actions= [[0.00752731 0.38168553]]\n",
      "1049810  Evaluations Remaining\n",
      "rewards= 17.301538099435138\n",
      "actions= [[0.24081187 0.62150592]]\n",
      "1049809  Evaluations Remaining\n",
      "rewards= 11.544647310460025\n",
      "Timestep 1\tScore: 28.85\tmin: 28.85\tmax: 28.85actions= [[1.         0.64174107]]\n",
      "1049808  Evaluations Remaining\n",
      "rewards= 25.213530371039003\n",
      "Timestep 2\tScore: 54.06\tmin: 54.06\tmax: 54.06actions= [[1. 0.]]\n",
      "1049807  Evaluations Remaining\n",
      "rewards= -0.26768609715466374\n",
      "Timestep 3\tScore: 53.79\tmin: 53.79\tmax: 53.79actions= [[0.47930673 0.75392056]]\n",
      "1049806  Evaluations Remaining\n",
      "rewards= 97.35979768052017\n",
      "Episode 38\tScore: 151.15\tAverage Score: 64.52.15\n",
      "actions= [[0.13654734 0.49251571]]\n",
      "1049805  Evaluations Remaining\n",
      "rewards= 13.583047286633665\n",
      "actions= [[0.39034209 0.72652525]]\n",
      "1049804  Evaluations Remaining\n",
      "rewards= 21.406905498118483\n",
      "Timestep 1\tScore: 34.99\tmin: 34.99\tmax: 34.99actions= [[0.45648408 0.86497444]]\n",
      "1049803  Evaluations Remaining\n",
      "rewards= -44.66353974587823\n",
      "Timestep 2\tScore: -9.67\tmin: -9.67\tmax: -9.67actions= [[0.57740349 0.95577723]]\n",
      "1049802  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= -93.95233467712153\n",
      "Timestep 3\tScore: -103.63\tmin: -103.63\tmax: -103.63actions= [[0.53033555 1.        ]]\n",
      "1049801  Evaluations Remaining\n",
      "rewards= -9.829811149996742\n",
      "Episode 39\tScore: -113.46\tAverage Score: 37.7313.46\n",
      "actions= [[0.20191719 0.52460277]]\n",
      "1049800  Evaluations Remaining\n",
      "rewards= 17.36558504563844\n",
      "actions= [[0.45069093 0.7430706 ]]\n",
      "1049799  Evaluations Remaining\n",
      "rewards= 10.519800683975353\n",
      "Timestep 1\tScore: 27.89\tmin: 27.89\tmax: 27.89actions= [[0.43523559 0.90319824]]\n",
      "1049798  Evaluations Remaining\n",
      "rewards= -30.375393504179\n",
      "Timestep 2\tScore: -2.49\tmin: -2.49\tmax: -2.49actions= [[0.46557105 0.94277263]]\n",
      "1049797  Evaluations Remaining\n",
      "rewards= -48.47085351549478\n",
      "Timestep 3\tScore: -50.96\tmin: -50.96\tmax: -50.96actions= [[0. 0.]]\n",
      "1049796  Evaluations Remaining\n",
      "rewards= -0.07386521678239655\n",
      "Episode 40\tScore: -51.03\tAverage Score: 30.81.03\n",
      "actions= [[0.32323012 0.63235462]]\n",
      "1049795  Evaluations Remaining\n",
      "rewards= 4.681758984294512\n",
      "actions= [[0.52969402 0.7407952 ]]\n",
      "1049794  Evaluations Remaining\n",
      "rewards= -23.875989445859386\n",
      "Timestep 1\tScore: -19.19\tmin: -19.19\tmax: -19.19actions= [[0.48131995 0.        ]]\n",
      "1049793  Evaluations Remaining\n",
      "rewards= 0.9171567368927551\n",
      "Timestep 2\tScore: -18.28\tmin: -18.28\tmax: -18.28actions= [[0. 1.]]\n",
      "1049792  Evaluations Remaining\n",
      "rewards= 105.75525016490612\n",
      "Timestep 3\tScore: 87.48\tmin: 87.48\tmax: 87.48actions= [[0.75617826 0.98464501]]\n",
      "1049791  Evaluations Remaining\n",
      "rewards= 51.75558040872666\n",
      "Episode 41\tScore: 139.23\tAverage Score: 49.06.23\n",
      "actions= [[0.44829217 0.69773078]]\n",
      "1049790  Evaluations Remaining\n",
      "rewards= -0.009840261887942002\n",
      "actions= [[0.1538236  0.97148423]]\n",
      "1049789  Evaluations Remaining\n",
      "rewards= 4.1625064143688295\n",
      "Timestep 1\tScore: 4.15\tmin: 4.15\tmax: 4.15actions= [[0.71111619 0.85091031]]\n",
      "1049788  Evaluations Remaining\n",
      "rewards= 34.868595077819016\n",
      "Timestep 2\tScore: 39.02\tmin: 39.02\tmax: 39.02actions= [[0.80360609 0.87871689]]\n",
      "1049787  Evaluations Remaining\n",
      "rewards= -54.36223054840828\n",
      "Timestep 3\tScore: -15.34\tmin: -15.34\tmax: -15.34actions= [[0.96625686 1.        ]]\n",
      "1049786  Evaluations Remaining\n",
      "rewards= -21.33320984394908\n",
      "Episode 42\tScore: -36.67\tAverage Score: 17.84.67\n",
      "actions= [[0.56024122 0.71641666]]\n",
      "1049785  Evaluations Remaining\n",
      "rewards= 18.299564816293568\n",
      "actions= [[0.83505976 0.93021357]]\n",
      "1049784  Evaluations Remaining\n",
      "rewards= -26.52962931204154\n",
      "Timestep 1\tScore: -8.23\tmin: -8.23\tmax: -8.23actions= [[0. 0.]]\n",
      "1049783  Evaluations Remaining\n",
      "rewards= -0.029095986803937546\n",
      "Timestep 2\tScore: -8.26\tmin: -8.26\tmax: -8.26actions= [[0.88911504 0.98692679]]\n",
      "1049782  Evaluations Remaining\n",
      "rewards= 11.95261800935401\n",
      "Timestep 3\tScore: 3.69\tmin: 3.69\tmax: 3.69actions= [[0.96131504 1.        ]]\n",
      "1049781  Evaluations Remaining\n",
      "rewards= -0.08441489153475645\n",
      "Episode 43\tScore: 3.61\tAverage Score: -11.66\n",
      "actions= [[0.52418327 0.78864092]]\n",
      "1049780  Evaluations Remaining\n",
      "rewards= 31.842067493729296\n",
      "actions= [[0.76603276 1.        ]]\n",
      "1049779  Evaluations Remaining\n",
      "rewards= -58.13802305414091\n",
      "Timestep 1\tScore: -26.30\tmin: -26.30\tmax: -26.30actions= [[0.2300295 0.       ]]\n",
      "1049778  Evaluations Remaining\n",
      "rewards= 0.1443338330944135\n",
      "Timestep 2\tScore: -26.15\tmin: -26.15\tmax: -26.15actions= [[0. 1.]]\n",
      "1049777  Evaluations Remaining\n",
      "rewards= 102.92054378000415\n",
      "Timestep 3\tScore: 76.77\tmin: 76.77\tmax: 76.77actions= [[0.        0.0934104]]\n",
      "1049776  Evaluations Remaining\n",
      "rewards= 0.10140019433091174\n",
      "Episode 44\tScore: 76.87\tAverage Score: 26.407\n",
      "actions= [[0.         0.32039287]]\n",
      "1049775  Evaluations Remaining\n",
      "rewards= 13.131659401988664\n",
      "actions= [[0.82496274 1.        ]]\n",
      "1049774  Evaluations Remaining\n",
      "rewards= -7.152780607842381\n",
      "Timestep 1\tScore: 5.98\tmin: 5.98\tmax: 5.98actions= [[0.97333217 1.        ]]\n",
      "1049773  Evaluations Remaining\n",
      "rewards= -0.09084390525209107\n",
      "Timestep 2\tScore: 5.89\tmin: 5.89\tmax: 5.89actions= [[1. 1.]]\n",
      "1049772  Evaluations Remaining\n",
      "rewards= 0.1496191361332304\n",
      "Timestep 3\tScore: 6.04\tmin: 6.04\tmax: 6.04actions= [[1. 1.]]\n",
      "1049771  Evaluations Remaining\n",
      "rewards= 0.012276283033277213\n",
      "Episode 45\tScore: 6.05\tAverage Score: 37.82\n",
      "actions= [[0.         0.09015928]]\n",
      "1049770  Evaluations Remaining\n",
      "rewards= 23.119533112742563\n",
      "actions= [[1. 1.]]\n",
      "1049769  Evaluations Remaining\n",
      "rewards= -15.335789702104117\n",
      "Timestep 1\tScore: 7.78\tmin: 7.78\tmax: 7.78actions= [[0.13488738 0.49498996]]\n",
      "1049768  Evaluations Remaining\n",
      "rewards= -0.15450666947669456\n",
      "Timestep 2\tScore: 7.63\tmin: 7.63\tmax: 7.63actions= [[1. 1.]]\n",
      "1049767  Evaluations Remaining\n",
      "rewards= 30.43560064208003\n",
      "Timestep 3\tScore: 38.06\tmin: 38.06\tmax: 38.06actions= [[1. 1.]]\n",
      "1049766  Evaluations Remaining\n",
      "rewards= -0.218880521160556\n",
      "Episode 46\tScore: 37.85\tAverage Score: 17.545\n",
      "actions= [[0.55426589 1.        ]]\n",
      "1049765  Evaluations Remaining\n",
      "rewards= 20.592977648613346\n",
      "actions= [[1. 1.]]\n",
      "1049764  Evaluations Remaining\n",
      "rewards= 17.256146754532708\n",
      "Timestep 1\tScore: 37.85\tmin: 37.85\tmax: 37.85actions= [[1. 1.]]\n",
      "1049763  Evaluations Remaining\n",
      "rewards= -0.2123232012786742\n",
      "Timestep 2\tScore: 37.64\tmin: 37.64\tmax: 37.64actions= [[0.         0.75368467]]\n",
      "1049762  Evaluations Remaining\n",
      "rewards= -0.14710534566831868\n",
      "Timestep 3\tScore: 37.49\tmin: 37.49\tmax: 37.49actions= [[0.54390263 0.        ]]\n",
      "1049761  Evaluations Remaining\n",
      "rewards= 27.2991441767211\n",
      "Episode 47\tScore: 64.79\tAverage Score: 37.839\n",
      "actions= [[0.80780518 1.        ]]\n",
      "1049760  Evaluations Remaining\n",
      "rewards= 5.814490275607786\n",
      "actions= [[1. 0.]]\n",
      "1049759  Evaluations Remaining\n",
      "rewards= 0.21387451095140353\n",
      "Timestep 1\tScore: 6.03\tmin: 6.03\tmax: 6.03actions= [[1. 0.]]\n",
      "1049758  Evaluations Remaining\n",
      "rewards= -0.07906601876780783\n",
      "Timestep 2\tScore: 5.95\tmin: 5.95\tmax: 5.95actions= [[0.         0.63604182]]\n",
      "1049757  Evaluations Remaining\n",
      "rewards= 44.17642266494843\n",
      "Timestep 3\tScore: 50.13\tmin: 50.13\tmax: 50.13actions= [[1. 1.]]\n",
      "1049756  Evaluations Remaining\n",
      "rewards= 48.74222965853824\n",
      "Episode 48\tScore: 98.87\tAverage Score: 56.887\n",
      "actions= [[1.         0.95888597]]\n",
      "1049755  Evaluations Remaining\n",
      "rewards= 3.123477021916331\n",
      "actions= [[0.23144939 0.        ]]\n",
      "1049754  Evaluations Remaining\n",
      "rewards= -0.13723962632240605\n",
      "Timestep 1\tScore: 2.99\tmin: 2.99\tmax: 2.99actions= [[1. 0.]]\n",
      "1049753  Evaluations Remaining\n",
      "rewards= 53.18863728865396\n",
      "Timestep 2\tScore: 56.17\tmin: 56.17\tmax: 56.17actions= [[1. 1.]]\n",
      "1049752  Evaluations Remaining\n",
      "rewards= 99.61769714232916\n",
      "Timestep 3\tScore: 155.79\tmin: 155.79\tmax: 155.79actions= [[1. 1.]]\n",
      "1049751  Evaluations Remaining\n",
      "rewards= -0.27044640184848623\n",
      "Episode 49\tScore: 155.52\tAverage Score: 72.61.52\n",
      "actions= [[0.27435239 1.        ]]\n",
      "1049750  Evaluations Remaining\n",
      "rewards= 77.99586706092161\n",
      "actions= [[1. 1.]]\n",
      "1049749  Evaluations Remaining\n",
      "rewards= 48.55646553250039\n",
      "Timestep 1\tScore: 126.55\tmin: 126.55\tmax: 126.55actions= [[1. 1.]]\n",
      "1049748  Evaluations Remaining\n",
      "rewards= -0.23201546554708985\n",
      "Timestep 2\tScore: 126.32\tmin: 126.32\tmax: 126.32actions= [[1. 1.]]\n",
      "1049747  Evaluations Remaining\n",
      "rewards= 0.18755287167653645\n",
      "Timestep 3\tScore: 126.51\tmin: 126.51\tmax: 126.51actions= [[0.69712932 0.        ]]\n",
      "1049746  Evaluations Remaining\n",
      "rewards= -0.14211035203157873\n",
      "Episode 50\tScore: 126.37\tAverage Score: 96.68.37\n",
      "actions= [[0.92361909 0.98781574]]\n",
      "1049745  Evaluations Remaining\n",
      "rewards= 19.66336907600897\n",
      "actions= [[0.96252072 1.        ]]\n",
      "1049744  Evaluations Remaining\n",
      "rewards= 0.0824727488335415\n",
      "Timestep 1\tScore: 19.75\tmin: 19.75\tmax: 19.75actions= [[1. 1.]]\n",
      "1049743  Evaluations Remaining\n",
      "rewards= 0.04378471408979667\n",
      "Timestep 2\tScore: 19.79\tmin: 19.79\tmax: 19.79actions= [[1. 1.]]\n",
      "1049742  Evaluations Remaining\n",
      "rewards= -0.04688998407576728\n",
      "Timestep 3\tScore: 19.74\tmin: 19.74\tmax: 19.74actions= [[1. 0.]]\n",
      "1049741  Evaluations Remaining\n",
      "rewards= 0.14941631728323213\n",
      "Episode 51\tScore: 19.89\tAverage Score: 93.099\n",
      "actions= [[0.91662365 1.        ]]\n",
      "1049740  Evaluations Remaining\n",
      "rewards= 28.008387946901166\n",
      "actions= [[1. 1.]]\n",
      "1049739  Evaluations Remaining\n",
      "rewards= -0.3798418514732598\n",
      "Timestep 1\tScore: 27.63\tmin: 27.63\tmax: 27.63actions= [[1. 1.]]\n",
      "1049738  Evaluations Remaining\n",
      "rewards= -0.26212609002967735\n",
      "Timestep 2\tScore: 27.37\tmin: 27.37\tmax: 27.37actions= [[1. 1.]]\n",
      "1049737  Evaluations Remaining\n",
      "rewards= -0.16139537722808273\n",
      "Timestep 3\tScore: 27.21\tmin: 27.21\tmax: 27.21actions= [[1. 1.]]\n",
      "1049736  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= -0.16580505633327292\n",
      "Episode 52\tScore: 27.04\tAverage Score: 85.544\n",
      "actions= [[0.59765246 0.        ]]\n",
      "1049735  Evaluations Remaining\n",
      "rewards= 39.40572961559969\n",
      "actions= [[1. 1.]]\n",
      "1049734  Evaluations Remaining\n",
      "rewards= 38.59856370054566\n",
      "Timestep 1\tScore: 78.00\tmin: 78.00\tmax: 78.00actions= [[1. 1.]]\n",
      "1049733  Evaluations Remaining\n",
      "rewards= 0.10191292868036461\n",
      "Timestep 2\tScore: 78.11\tmin: 78.11\tmax: 78.11actions= [[0. 0.]]\n",
      "1049732  Evaluations Remaining\n",
      "rewards= -0.042371403237094984\n",
      "Timestep 3\tScore: 78.06\tmin: 78.06\tmax: 78.06actions= [[1. 1.]]\n",
      "1049731  Evaluations Remaining\n",
      "rewards= 11.945749779409729\n",
      "Episode 53\tScore: 90.01\tAverage Score: 83.771\n",
      "actions= [[0.96432632 1.        ]]\n",
      "1049730  Evaluations Remaining\n",
      "rewards= 28.23370998819321\n",
      "actions= [[0.20154074 0.        ]]\n",
      "1049729  Evaluations Remaining\n",
      "rewards= 0.13499736335065782\n",
      "Timestep 1\tScore: 28.37\tmin: 28.37\tmax: 28.37actions= [[0. 1.]]\n",
      "1049728  Evaluations Remaining\n",
      "rewards= 89.30903271796988\n",
      "Timestep 2\tScore: 117.68\tmin: 117.68\tmax: 117.68actions= [[1.         0.31145727]]\n",
      "1049727  Evaluations Remaining\n",
      "rewards= 93.50414915285094\n",
      "Timestep 3\tScore: 211.18\tmin: 211.18\tmax: 211.18actions= [[0.         0.20123733]]\n",
      "1049726  Evaluations Remaining\n",
      "rewards= 54.22026757922358\n",
      "Episode 54\tScore: 265.40\tAverage Score: 105.7440\n",
      "actions= [[0.31193209 0.10798064]]\n",
      "1049725  Evaluations Remaining\n",
      "rewards= -77.61067710636458\n",
      "actions= [[1. 1.]]\n",
      "1049724  Evaluations Remaining\n",
      "rewards= 7.391904835016595\n",
      "Timestep 1\tScore: -70.22\tmin: -70.22\tmax: -70.22actions= [[1. 1.]]\n",
      "1049723  Evaluations Remaining\n",
      "rewards= -0.2349303700964689\n",
      "Timestep 2\tScore: -70.45\tmin: -70.45\tmax: -70.45actions= [[1. 1.]]\n",
      "1049722  Evaluations Remaining\n",
      "rewards= 0.05275946073206006\n",
      "Timestep 3\tScore: -70.40\tmin: -70.40\tmax: -70.40actions= [[0.         0.12930617]]\n",
      "1049721  Evaluations Remaining\n",
      "rewards= -0.2184000606552554\n",
      "Episode 55\tScore: -70.62\tAverage Score: 66.34.62\n",
      "actions= [[0.57318369 0.        ]]\n",
      "1049720  Evaluations Remaining\n",
      "rewards= 32.35453500567392\n",
      "actions= [[0. 1.]]\n",
      "1049719  Evaluations Remaining\n",
      "rewards= 96.10809990565396\n",
      "Timestep 1\tScore: 128.46\tmin: 128.46\tmax: 128.46actions= [[1. 1.]]\n",
      "1049718  Evaluations Remaining\n",
      "rewards= 98.69567286347426\n",
      "Timestep 2\tScore: 227.16\tmin: 227.16\tmax: 227.16actions= [[1. 1.]]\n",
      "1049717  Evaluations Remaining\n",
      "rewards= 0.050820646370388634\n",
      "Timestep 3\tScore: 227.21\tmin: 227.21\tmax: 227.21actions= [[1. 1.]]\n",
      "1049716  Evaluations Remaining\n",
      "rewards= -0.13516860535880193\n",
      "Episode 56\tScore: 227.07\tAverage Score: 107.7807\n",
      "actions= [[0.97049153 1.        ]]\n",
      "1049715  Evaluations Remaining\n",
      "rewards= 25.5847307732679\n",
      "actions= [[1. 0.]]\n",
      "1049714  Evaluations Remaining\n",
      "rewards= 0.13245892650026603\n",
      "Timestep 1\tScore: 25.72\tmin: 25.72\tmax: 25.72actions= [[1. 1.]]\n",
      "1049713  Evaluations Remaining\n",
      "rewards= 99.71695228134624\n",
      "Timestep 2\tScore: 125.43\tmin: 125.43\tmax: 125.43actions= [[1. 1.]]\n",
      "1049712  Evaluations Remaining\n",
      "rewards= 0.14083727152210557\n",
      "Timestep 3\tScore: 125.57\tmin: 125.57\tmax: 125.57actions= [[1. 1.]]\n",
      "1049711  Evaluations Remaining\n",
      "rewards= -0.1671450778936152\n",
      "Episode 57\tScore: 125.41\tAverage Score: 127.4541\n",
      "actions= [[0. 0.]]\n",
      "1049710  Evaluations Remaining\n",
      "rewards= 2.87863794523418\n",
      "actions= [[1. 1.]]\n",
      "1049709  Evaluations Remaining\n",
      "rewards= 12.560963293307221\n",
      "Timestep 1\tScore: 15.44\tmin: 15.44\tmax: 15.44actions= [[1. 1.]]\n",
      "1049708  Evaluations Remaining\n",
      "rewards= -0.1083144912450189\n",
      "Timestep 2\tScore: 15.33\tmin: 15.33\tmax: 15.33actions= [[1. 1.]]\n",
      "1049707  Evaluations Remaining\n",
      "rewards= 0.10715582052928818\n",
      "Timestep 3\tScore: 15.44\tmin: 15.44\tmax: 15.44actions= [[1. 1.]]\n",
      "1049706  Evaluations Remaining\n",
      "rewards= -0.06053128045371814\n",
      "Episode 58\tScore: 15.38\tAverage Score: 112.53\n",
      "actions= [[1.        0.9933399]]\n",
      "1049705  Evaluations Remaining\n",
      "rewards= 13.316827278498922\n",
      "actions= [[1. 1.]]\n",
      "1049704  Evaluations Remaining\n",
      "rewards= 0.05838018615828622\n",
      "Timestep 1\tScore: 13.38\tmin: 13.38\tmax: 13.38actions= [[1. 1.]]\n",
      "1049703  Evaluations Remaining\n",
      "rewards= -0.19922115690267495\n",
      "Timestep 2\tScore: 13.18\tmin: 13.18\tmax: 13.18actions= [[1. 1.]]\n",
      "1049702  Evaluations Remaining\n",
      "rewards= 0.03433088626747027\n",
      "Timestep 3\tScore: 13.21\tmin: 13.21\tmax: 13.21actions= [[0.         0.31884792]]\n",
      "1049701  Evaluations Remaining\n",
      "rewards= 0.2704926945909647\n",
      "Episode 59\tScore: 13.48\tAverage Score: 62.148\n",
      "actions= [[1. 1.]]\n",
      "1049700  Evaluations Remaining\n",
      "rewards= 16.077037043382138\n",
      "actions= [[1. 1.]]\n",
      "1049699  Evaluations Remaining\n",
      "rewards= 0.20691604435660516\n",
      "Timestep 1\tScore: 16.28\tmin: 16.28\tmax: 16.28actions= [[1. 1.]]\n",
      "1049698  Evaluations Remaining\n",
      "rewards= -0.24937927088097078\n",
      "Timestep 2\tScore: 16.03\tmin: 16.03\tmax: 16.03actions= [[1. 1.]]\n",
      "1049697  Evaluations Remaining\n",
      "rewards= -0.23034239724350147\n",
      "Timestep 3\tScore: 15.80\tmin: 15.80\tmax: 15.80actions= [[1. 1.]]\n",
      "1049696  Evaluations Remaining\n",
      "rewards= 0.02440556118072701\n",
      "Episode 60\tScore: 15.83\tAverage Score: 79.433\n",
      "actions= [[1. 1.]]\n",
      "1049695  Evaluations Remaining\n",
      "rewards= 14.371680917277416\n",
      "actions= [[1. 1.]]\n",
      "1049694  Evaluations Remaining\n",
      "rewards= -0.1502134930629424\n",
      "Timestep 1\tScore: 14.22\tmin: 14.22\tmax: 14.22actions= [[1. 1.]]\n",
      "1049693  Evaluations Remaining\n",
      "rewards= -0.04538982742420439\n",
      "Timestep 2\tScore: 14.18\tmin: 14.18\tmax: 14.18actions= [[1. 1.]]\n",
      "1049692  Evaluations Remaining\n",
      "rewards= 0.025499210173628217\n",
      "Timestep 3\tScore: 14.20\tmin: 14.20\tmax: 14.20actions= [[1. 1.]]\n",
      "1049691  Evaluations Remaining\n",
      "rewards= -0.006094548285917156\n",
      "Episode 61\tScore: 14.20\tAverage Score: 36.860\n",
      "actions= [[1. 1.]]\n",
      "1049690  Evaluations Remaining\n",
      "rewards= 15.141271396780805\n",
      "actions= [[0.99189347 0.        ]]\n",
      "1049689  Evaluations Remaining\n",
      "rewards= 0.12641281643000868\n",
      "Timestep 1\tScore: 15.27\tmin: 15.27\tmax: 15.27actions= [[0.         0.34740865]]\n",
      "1049688  Evaluations Remaining\n",
      "rewards= 10.530577173753214\n",
      "Timestep 2\tScore: 25.80\tmin: 25.80\tmax: 25.80actions= [[1. 1.]]\n",
      "1049687  Evaluations Remaining\n",
      "rewards= -1.7141077379384135\n",
      "Timestep 3\tScore: 24.08\tmin: 24.08\tmax: 24.08actions= [[0.98611231 0.32329909]]\n",
      "1049686  Evaluations Remaining\n",
      "rewards= 0.07776731879724386\n",
      "Episode 62\tScore: 24.16\tAverage Score: 16.616\n",
      "actions= [[1. 1.]]\n",
      "1049685  Evaluations Remaining\n",
      "rewards= 14.356024862721771\n",
      "actions= [[1. 1.]]\n",
      "1049684  Evaluations Remaining\n",
      "rewards= 0.13423660148760952\n",
      "Timestep 1\tScore: 14.49\tmin: 14.49\tmax: 14.49actions= [[0. 0.]]\n",
      "1049683  Evaluations Remaining\n",
      "rewards= -0.18614709069908475\n",
      "Timestep 2\tScore: 14.30\tmin: 14.30\tmax: 14.30actions= [[1. 1.]]\n",
      "1049682  Evaluations Remaining\n",
      "rewards= 11.548938778552564\n",
      "Timestep 3\tScore: 25.85\tmin: 25.85\tmax: 25.85actions= [[0.         0.24931003]]\n",
      "1049681  Evaluations Remaining\n",
      "rewards= 0.06061033527130144\n",
      "Episode 63\tScore: 25.91\tAverage Score: 18.721\n",
      "actions= [[0.         0.70944179]]\n",
      "1049680  Evaluations Remaining\n",
      "rewards= 72.29837347587754\n",
      "actions= [[1. 0.]]\n",
      "1049679  Evaluations Remaining\n",
      "rewards= 96.26916427550465\n",
      "Timestep 1\tScore: 168.57\tmin: 168.57\tmax: 168.57actions= [[1. 1.]]\n",
      "1049678  Evaluations Remaining\n",
      "rewards= 108.98747175982274\n",
      "Timestep 2\tScore: 277.56\tmin: 277.56\tmax: 277.56actions= [[1. 1.]]\n",
      "1049677  Evaluations Remaining\n",
      "rewards= 0.23590729896326001\n",
      "Timestep 3\tScore: 277.79\tmin: 277.79\tmax: 277.79actions= [[1. 1.]]\n",
      "1049676  Evaluations Remaining\n",
      "rewards= 0.04031187849256801\n",
      "Episode 64\tScore: 277.83\tAverage Score: 71.59.83\n",
      "actions= [[1. 1.]]\n",
      "1049675  Evaluations Remaining\n",
      "rewards= 15.284953342889583\n",
      "actions= [[1. 1.]]\n",
      "1049674  Evaluations Remaining\n",
      "rewards= -0.02776882492995769\n",
      "Timestep 1\tScore: 15.26\tmin: 15.26\tmax: 15.26actions= [[1. 1.]]\n",
      "1049673  Evaluations Remaining\n",
      "rewards= -0.049521438070088575\n",
      "Timestep 2\tScore: 15.21\tmin: 15.21\tmax: 15.21actions= [[0.         0.42919777]]\n",
      "1049672  Evaluations Remaining\n",
      "rewards= 0.2132637799411139\n",
      "Timestep 3\tScore: 15.42\tmin: 15.42\tmax: 15.42actions= [[1. 1.]]\n",
      "1049671  Evaluations Remaining\n",
      "rewards= 28.22923724552063\n",
      "Episode 65\tScore: 43.65\tAverage Score: 77.155\n",
      "actions= [[1. 1.]]\n",
      "1049670  Evaluations Remaining\n",
      "rewards= 13.774972847113354\n",
      "actions= [[0.         0.09448507]]\n",
      "1049669  Evaluations Remaining\n",
      "rewards= -0.024129839629286387\n",
      "Timestep 1\tScore: 13.75\tmin: 13.75\tmax: 13.75actions= [[1. 1.]]\n",
      "1049668  Evaluations Remaining\n",
      "rewards= -17.340229963523612\n",
      "Timestep 2\tScore: -3.59\tmin: -3.59\tmax: -3.59actions= [[1. 1.]]\n",
      "1049667  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= -0.17087288674992074\n",
      "Timestep 3\tScore: -3.76\tmin: -3.76\tmax: -3.76actions= [[1. 1.]]\n",
      "1049666  Evaluations Remaining\n",
      "rewards= 0.24707831404375957\n",
      "Episode 66\tScore: -3.51\tAverage Score: 73.611\n",
      "actions= [[1. 1.]]\n",
      "1049665  Evaluations Remaining\n",
      "rewards= 13.549691117408386\n",
      "actions= [[0.69705603 0.        ]]\n",
      "1049664  Evaluations Remaining\n",
      "rewards= -0.18977152151798027\n",
      "Timestep 1\tScore: 13.36\tmin: 13.36\tmax: 13.36actions= [[0. 0.]]\n",
      "1049663  Evaluations Remaining\n",
      "rewards= 0.26560552985196484\n",
      "Timestep 2\tScore: 13.63\tmin: 13.63\tmax: 13.63actions= [[1. 1.]]\n",
      "1049662  Evaluations Remaining\n",
      "rewards= 11.59477169695667\n",
      "Timestep 3\tScore: 25.22\tmin: 25.22\tmax: 25.22actions= [[0. 0.]]\n",
      "1049661  Evaluations Remaining\n",
      "rewards= -0.14200078531617066\n",
      "Episode 67\tScore: 25.08\tAverage Score: 73.798\n",
      "actions= [[0.24080596 0.        ]]\n",
      "1049660  Evaluations Remaining\n",
      "rewards= 3.561120838931141\n",
      "actions= [[0. 0.]]\n",
      "1049659  Evaluations Remaining\n",
      "rewards= -0.18968377978844408\n",
      "Timestep 1\tScore: 3.37\tmin: 3.37\tmax: 3.37actions= [[1. 1.]]\n",
      "1049658  Evaluations Remaining\n",
      "rewards= 11.695725341070633\n",
      "Timestep 2\tScore: 15.07\tmin: 15.07\tmax: 15.07actions= [[0.         0.19044781]]\n",
      "1049657  Evaluations Remaining\n",
      "rewards= 0.13963368085083383\n",
      "Timestep 3\tScore: 15.21\tmin: 15.21\tmax: 15.21actions= [[0.62615523 0.        ]]\n",
      "1049656  Evaluations Remaining\n",
      "rewards= 39.03528520057779\n",
      "Episode 68\tScore: 54.24\tAverage Score: 79.464\n",
      "actions= [[1. 1.]]\n",
      "1049655  Evaluations Remaining\n",
      "rewards= 15.77771318414156\n",
      "actions= [[1. 1.]]\n",
      "1049654  Evaluations Remaining\n",
      "rewards= -0.07095748417924064\n",
      "Timestep 1\tScore: 15.71\tmin: 15.71\tmax: 15.71actions= [[0. 0.]]\n",
      "1049653  Evaluations Remaining\n",
      "rewards= -0.02344280824011946\n",
      "Timestep 2\tScore: 15.68\tmin: 15.68\tmax: 15.68actions= [[1.         0.94723813]]\n",
      "1049652  Evaluations Remaining\n",
      "rewards= -3.1118184679986687\n",
      "Timestep 3\tScore: 12.57\tmin: 12.57\tmax: 12.57actions= [[1. 1.]]\n",
      "1049651  Evaluations Remaining\n",
      "rewards= 6.903162032662202\n",
      "Episode 69\tScore: 19.47\tAverage Score: 27.797\n",
      "actions= [[1. 1.]]\n",
      "1049650  Evaluations Remaining\n",
      "rewards= 13.574520398178636\n",
      "actions= [[1. 1.]]\n",
      "1049649  Evaluations Remaining\n",
      "rewards= 0.09777765080988754\n",
      "Timestep 1\tScore: 13.67\tmin: 13.67\tmax: 13.67actions= [[1. 1.]]\n",
      "1049648  Evaluations Remaining\n",
      "rewards= -0.20536026216206116\n",
      "Timestep 2\tScore: 13.47\tmin: 13.47\tmax: 13.47actions= [[1. 1.]]\n",
      "1049647  Evaluations Remaining\n",
      "rewards= 0.13054403203636689\n",
      "Timestep 3\tScore: 13.60\tmin: 13.60\tmax: 13.60actions= [[1. 1.]]\n",
      "1049646  Evaluations Remaining\n",
      "rewards= -0.04701776516505962\n",
      "Episode 70\tScore: 13.55\tAverage Score: 21.775\n",
      "actions= [[1. 1.]]\n",
      "1049645  Evaluations Remaining\n",
      "rewards= 15.652468859335483\n",
      "actions= [[0.33278235 0.46525864]]\n",
      "1049644  Evaluations Remaining\n",
      "rewards= 0.13364599692119672\n",
      "Timestep 1\tScore: 15.79\tmin: 15.79\tmax: 15.79actions= [[1. 1.]]\n",
      "1049643  Evaluations Remaining\n",
      "rewards= 0.9746398203460265\n",
      "Timestep 2\tScore: 16.76\tmin: 16.76\tmax: 16.76actions= [[1. 1.]]\n",
      "1049642  Evaluations Remaining\n",
      "rewards= 0.1393855088336764\n",
      "Timestep 3\tScore: 16.90\tmin: 16.90\tmax: 16.90actions= [[1. 1.]]\n",
      "1049641  Evaluations Remaining\n",
      "rewards= -0.2538900159122526\n",
      "Episode 71\tScore: 16.65\tAverage Score: 25.805\n",
      "actions= [[0. 0.]]\n",
      "1049640  Evaluations Remaining\n",
      "rewards= 2.777469201921546\n",
      "actions= [[0. 0.]]\n",
      "1049639  Evaluations Remaining\n",
      "rewards= 0.25226000469099263\n",
      "Timestep 1\tScore: 3.03\tmin: 3.03\tmax: 3.03actions= [[1. 1.]]\n",
      "1049638  Evaluations Remaining\n",
      "rewards= 13.35829406067095\n",
      "Timestep 2\tScore: 16.39\tmin: 16.39\tmax: 16.39actions= [[0. 0.]]\n",
      "1049637  Evaluations Remaining\n",
      "rewards= 0.0023621458513982674\n",
      "Timestep 3\tScore: 16.39\tmin: 16.39\tmax: 16.39actions= [[1. 1.]]\n",
      "1049636  Evaluations Remaining\n",
      "rewards= 12.12666484742112\n",
      "Episode 72\tScore: 28.52\tAverage Score: 26.492\n",
      "actions= [[1. 1.]]\n",
      "1049635  Evaluations Remaining\n",
      "rewards= 15.542640275694408\n",
      "actions= [[1. 1.]]\n",
      "1049634  Evaluations Remaining\n",
      "rewards= 0.04535983932859633\n",
      "Timestep 1\tScore: 15.59\tmin: 15.59\tmax: 15.59actions= [[1. 1.]]\n",
      "1049633  Evaluations Remaining\n",
      "rewards= 0.20283134322707186\n",
      "Timestep 2\tScore: 15.79\tmin: 15.79\tmax: 15.79actions= [[1. 1.]]\n",
      "1049632  Evaluations Remaining\n",
      "rewards= 0.17616222026817718\n",
      "Timestep 3\tScore: 15.97\tmin: 15.97\tmax: 15.97actions= [[1. 1.]]\n",
      "1049631  Evaluations Remaining\n",
      "rewards= 0.23694947866262028\n",
      "Episode 73\tScore: 16.20\tAverage Score: 18.880\n",
      "actions= [[0. 0.]]\n",
      "1049630  Evaluations Remaining\n",
      "rewards= 2.641818870820192\n",
      "actions= [[1. 1.]]\n",
      "1049629  Evaluations Remaining\n",
      "rewards= 13.373111405406188\n",
      "Timestep 1\tScore: 16.01\tmin: 16.01\tmax: 16.01actions= [[1. 0.]]\n",
      "1049628  Evaluations Remaining\n",
      "rewards= -0.2320038563299116\n",
      "Timestep 2\tScore: 15.78\tmin: 15.78\tmax: 15.78actions= [[0.80667012 0.21236434]]\n",
      "1049627  Evaluations Remaining\n",
      "rewards= 35.00914916535705\n",
      "Timestep 3\tScore: 50.79\tmin: 50.79\tmax: 50.79actions= [[1. 1.]]\n",
      "1049626  Evaluations Remaining\n",
      "rewards= 7.7945392965353655\n",
      "Episode 74\tScore: 58.59\tAverage Score: 26.709\n",
      "actions= [[1. 1.]]\n",
      "1049625  Evaluations Remaining\n",
      "rewards= 16.407679757500297\n",
      "actions= [[0.         0.53253111]]\n",
      "1049624  Evaluations Remaining\n",
      "rewards= -0.19558660980420628\n",
      "Timestep 1\tScore: 16.21\tmin: 16.21\tmax: 16.21actions= [[1. 1.]]\n",
      "1049623  Evaluations Remaining\n",
      "rewards= 57.01504837671146\n",
      "Timestep 2\tScore: 73.23\tmin: 73.23\tmax: 73.23actions= [[1. 1.]]\n",
      "1049622  Evaluations Remaining\n",
      "rewards= 0.14864221825739454\n",
      "Timestep 3\tScore: 73.38\tmin: 73.38\tmax: 73.38actions= [[0. 0.]]\n",
      "1049621  Evaluations Remaining\n",
      "rewards= -0.1405099121322455\n",
      "Episode 75\tScore: 73.24\tAverage Score: 38.644\n",
      "actions= [[1. 1.]]\n",
      "1049620  Evaluations Remaining\n",
      "rewards= 14.630448644604702\n",
      "actions= [[1. 1.]]\n",
      "1049619  Evaluations Remaining\n",
      "rewards= 0.14858948557595042\n",
      "Timestep 1\tScore: 14.78\tmin: 14.78\tmax: 14.78actions= [[1. 1.]]\n",
      "1049618  Evaluations Remaining\n",
      "rewards= -0.10291782025074125\n",
      "Timestep 2\tScore: 14.68\tmin: 14.68\tmax: 14.68actions= [[1. 1.]]\n",
      "1049617  Evaluations Remaining\n",
      "rewards= -0.07250069530544989\n",
      "Timestep 3\tScore: 14.60\tmin: 14.60\tmax: 14.60actions= [[1. 1.]]\n",
      "1049616  Evaluations Remaining\n",
      "rewards= -0.007141452536806536\n",
      "Episode 76\tScore: 14.60\tAverage Score: 38.230\n",
      "actions= [[1. 1.]]\n",
      "1049615  Evaluations Remaining\n",
      "rewards= 14.964200758793265\n",
      "actions= [[0.48710143 0.        ]]\n",
      "1049614  Evaluations Remaining\n",
      "rewards= 0.2107879712337155\n",
      "Timestep 1\tScore: 15.17\tmin: 15.17\tmax: 15.17actions= [[1. 1.]]\n",
      "1049613  Evaluations Remaining\n",
      "rewards= 24.327950036035883\n",
      "Timestep 2\tScore: 39.50\tmin: 39.50\tmax: 39.50actions= [[1. 1.]]\n",
      "1049612  Evaluations Remaining\n",
      "rewards= 0.2253078026691684\n",
      "Timestep 3\tScore: 39.73\tmin: 39.73\tmax: 39.73actions= [[0.23109215 0.        ]]\n",
      "1049611  Evaluations Remaining\n",
      "rewards= -0.2003719642703392\n",
      "Episode 77\tScore: 39.53\tAverage Score: 40.433\n",
      "actions= [[1.         0.99877548]]\n",
      "1049610  Evaluations Remaining\n",
      "rewards= 13.776307459059451\n",
      "actions= [[1. 1.]]\n",
      "1049609  Evaluations Remaining\n",
      "rewards= -0.10874277866837412\n",
      "Timestep 1\tScore: 13.67\tmin: 13.67\tmax: 13.67actions= [[1. 1.]]\n",
      "1049608  Evaluations Remaining\n",
      "rewards= -0.08659818951876908\n",
      "Timestep 2\tScore: 13.58\tmin: 13.58\tmax: 13.58actions= [[1. 1.]]\n",
      "1049607  Evaluations Remaining\n",
      "rewards= 0.025736979472505528\n",
      "Timestep 3\tScore: 13.61\tmin: 13.61\tmax: 13.61actions= [[1. 1.]]\n",
      "1049606  Evaluations Remaining\n",
      "rewards= -0.11142652362917538\n",
      "Episode 78\tScore: 13.50\tAverage Score: 39.890\n",
      "actions= [[1. 1.]]\n",
      "1049605  Evaluations Remaining\n",
      "rewards= 13.663312856275576\n",
      "actions= [[1. 1.]]\n",
      "1049604  Evaluations Remaining\n",
      "rewards= 0.07352463204742365\n",
      "Timestep 1\tScore: 13.74\tmin: 13.74\tmax: 13.74actions= [[1. 1.]]\n",
      "1049603  Evaluations Remaining\n",
      "rewards= 0.0657598691470036\n",
      "Timestep 2\tScore: 13.80\tmin: 13.80\tmax: 13.80actions= [[1. 1.]]\n",
      "1049602  Evaluations Remaining\n",
      "rewards= -0.24956607711227896\n",
      "Timestep 3\tScore: 13.55\tmin: 13.55\tmax: 13.55actions= [[1. 0.]]\n",
      "1049601  Evaluations Remaining\n",
      "rewards= 0.088968041915368\n",
      "Episode 79\tScore: 13.64\tAverage Score: 30.904\n",
      "actions= [[0.99591219 1.        ]]\n",
      "1049600  Evaluations Remaining\n",
      "rewards= 17.24712504803453\n",
      "actions= [[1. 1.]]\n",
      "1049599  Evaluations Remaining\n",
      "rewards= -0.03396157745401185\n",
      "Timestep 1\tScore: 17.21\tmin: 17.21\tmax: 17.21actions= [[1. 1.]]\n",
      "1049598  Evaluations Remaining\n",
      "rewards= -0.20996503327926686\n",
      "Timestep 2\tScore: 17.00\tmin: 17.00\tmax: 17.00actions= [[0.64916922 0.        ]]\n",
      "1049597  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= -0.12244385387670587\n",
      "Timestep 3\tScore: 16.88\tmin: 16.88\tmax: 16.88actions= [[1. 1.]]\n",
      "1049596  Evaluations Remaining\n",
      "rewards= 65.26855731267788\n",
      "Episode 80\tScore: 82.15\tAverage Score: 32.685\n",
      "actions= [[0.        0.9622052]]\n",
      "1049595  Evaluations Remaining\n",
      "rewards= 94.47837698581846\n",
      "actions= [[1. 1.]]\n",
      "1049594  Evaluations Remaining\n",
      "rewards= 70.1110319176129\n",
      "Timestep 1\tScore: 164.59\tmin: 164.59\tmax: 164.59actions= [[1. 1.]]\n",
      "1049593  Evaluations Remaining\n",
      "rewards= 0.12048471957745921\n",
      "Timestep 2\tScore: 164.71\tmin: 164.71\tmax: 164.71actions= [[1. 1.]]\n",
      "1049592  Evaluations Remaining\n",
      "rewards= -0.1709195676304165\n",
      "Timestep 3\tScore: 164.54\tmin: 164.54\tmax: 164.54actions= [[0.37361256 0.16325652]]\n",
      "1049591  Evaluations Remaining\n",
      "rewards= 0.025453064988300245\n",
      "Episode 81\tScore: 164.56\tAverage Score: 62.68.56\n",
      "actions= [[0.54493673 0.        ]]\n",
      "1049590  Evaluations Remaining\n",
      "rewards= 30.219918303658375\n",
      "actions= [[1. 1.]]\n",
      "1049589  Evaluations Remaining\n",
      "rewards= 28.740008694988937\n",
      "Timestep 1\tScore: 58.96\tmin: 58.96\tmax: 58.96actions= [[1. 1.]]\n",
      "1049588  Evaluations Remaining\n",
      "rewards= -0.07931568235719855\n",
      "Timestep 2\tScore: 58.88\tmin: 58.88\tmax: 58.88actions= [[1. 1.]]\n",
      "1049587  Evaluations Remaining\n",
      "rewards= 0.15369860537086\n",
      "Timestep 3\tScore: 59.03\tmin: 59.03\tmax: 59.03actions= [[1. 1.]]\n",
      "1049586  Evaluations Remaining\n",
      "rewards= -0.14842076578036245\n",
      "Episode 82\tScore: 58.89\tAverage Score: 66.559\n",
      "actions= [[1. 1.]]\n",
      "1049585  Evaluations Remaining\n",
      "rewards= 15.211527779366662\n",
      "actions= [[1. 1.]]\n",
      "1049584  Evaluations Remaining\n",
      "rewards= 0.08706237028005637\n",
      "Timestep 1\tScore: 15.30\tmin: 15.30\tmax: 15.30actions= [[1. 1.]]\n",
      "1049583  Evaluations Remaining\n",
      "rewards= 0.02678510761705022\n",
      "Timestep 2\tScore: 15.33\tmin: 15.33\tmax: 15.33actions= [[1. 1.]]\n",
      "1049582  Evaluations Remaining\n",
      "rewards= 0.2707701264296145\n",
      "Timestep 3\tScore: 15.60\tmin: 15.60\tmax: 15.60actions= [[0. 0.]]\n",
      "1049581  Evaluations Remaining\n",
      "rewards= -0.24227603902741413\n",
      "Episode 83\tScore: 15.35\tAverage Score: 66.925\n",
      "actions= [[1. 1.]]\n",
      "1049580  Evaluations Remaining\n",
      "rewards= 13.763204671205724\n",
      "actions= [[1. 1.]]\n",
      "1049579  Evaluations Remaining\n",
      "rewards= -0.09837265642397286\n",
      "Timestep 1\tScore: 13.66\tmin: 13.66\tmax: 13.66actions= [[0. 0.]]\n",
      "1049578  Evaluations Remaining\n",
      "rewards= 0.08507335445841191\n",
      "Timestep 2\tScore: 13.75\tmin: 13.75\tmax: 13.75actions= [[1. 1.]]\n",
      "1049577  Evaluations Remaining\n",
      "rewards= 11.106221932111861\n",
      "Timestep 3\tScore: 24.86\tmin: 24.86\tmax: 24.86actions= [[1. 1.]]\n",
      "1049576  Evaluations Remaining\n",
      "rewards= 0.21356922375111864\n",
      "Episode 84\tScore: 25.07\tAverage Score: 69.207\n",
      "actions= [[1. 1.]]\n",
      "1049575  Evaluations Remaining\n",
      "rewards= 15.504330606300982\n",
      "actions= [[1. 1.]]\n",
      "1049574  Evaluations Remaining\n",
      "rewards= 0.13119487244064132\n",
      "Timestep 1\tScore: 15.64\tmin: 15.64\tmax: 15.64actions= [[1. 1.]]\n",
      "1049573  Evaluations Remaining\n",
      "rewards= 0.22265381626949088\n",
      "Timestep 2\tScore: 15.86\tmin: 15.86\tmax: 15.86actions= [[1. 1.]]\n",
      "1049572  Evaluations Remaining\n",
      "rewards= 0.16560886003841757\n",
      "Timestep 3\tScore: 16.02\tmin: 16.02\tmax: 16.02actions= [[1. 1.]]\n",
      "1049571  Evaluations Remaining\n",
      "rewards= 0.015257434139422266\n",
      "Episode 85\tScore: 16.04\tAverage Score: 55.984\n",
      "actions= [[1. 1.]]\n",
      "1049570  Evaluations Remaining\n",
      "rewards= 14.945582579870003\n",
      "actions= [[1. 1.]]\n",
      "1049569  Evaluations Remaining\n",
      "rewards= -0.029567201308464686\n",
      "Timestep 1\tScore: 14.92\tmin: 14.92\tmax: 14.92actions= [[1. 1.]]\n",
      "1049568  Evaluations Remaining\n",
      "rewards= 0.010079886294877216\n",
      "Timestep 2\tScore: 14.93\tmin: 14.93\tmax: 14.93actions= [[1. 1.]]\n",
      "1049567  Evaluations Remaining\n",
      "rewards= -0.01496827231054354\n",
      "Timestep 3\tScore: 14.91\tmin: 14.91\tmax: 14.91actions= [[1.         0.57066579]]\n",
      "1049566  Evaluations Remaining\n",
      "rewards= 0.24465813131796832\n",
      "Episode 86\tScore: 15.16\tAverage Score: 26.106\n",
      "actions= [[1. 1.]]\n",
      "1049565  Evaluations Remaining\n",
      "rewards= 15.041249828373124\n",
      "actions= [[1. 1.]]\n",
      "1049564  Evaluations Remaining\n",
      "rewards= -0.09728256583664985\n",
      "Timestep 1\tScore: 14.94\tmin: 14.94\tmax: 14.94actions= [[0.         0.71861113]]\n",
      "1049563  Evaluations Remaining\n",
      "rewards= -0.06525196714440273\n",
      "Timestep 2\tScore: 14.88\tmin: 14.88\tmax: 14.88actions= [[1. 1.]]\n",
      "1049562  Evaluations Remaining\n",
      "rewards= 35.568168644583395\n",
      "Timestep 3\tScore: 50.45\tmin: 50.45\tmax: 50.45actions= [[1. 1.]]\n",
      "1049561  Evaluations Remaining\n",
      "rewards= 0.08993033391534633\n",
      "Episode 87\tScore: 50.54\tAverage Score: 24.434\n",
      "actions= [[0. 0.]]\n",
      "1049560  Evaluations Remaining\n",
      "rewards= 2.8137824211034914\n",
      "actions= [[1. 1.]]\n",
      "1049559  Evaluations Remaining\n",
      "rewards= 11.63554277860046\n",
      "Timestep 1\tScore: 14.45\tmin: 14.45\tmax: 14.45actions= [[1. 1.]]\n",
      "1049558  Evaluations Remaining\n",
      "rewards= 0.25122980552303886\n",
      "Timestep 2\tScore: 14.70\tmin: 14.70\tmax: 14.70actions= [[0. 0.]]\n",
      "1049557  Evaluations Remaining\n",
      "rewards= 0.19866575480362014\n",
      "Timestep 3\tScore: 14.90\tmin: 14.90\tmax: 14.90actions= [[0.        0.0143638]]\n",
      "1049556  Evaluations Remaining\n",
      "rewards= 0.7674081183790631\n",
      "Episode 88\tScore: 15.67\tAverage Score: 24.497\n",
      "actions= [[1. 1.]]\n",
      "1049555  Evaluations Remaining\n",
      "rewards= 15.047699726155003\n",
      "actions= [[1. 1.]]\n",
      "1049554  Evaluations Remaining\n",
      "rewards= -0.24947138852766892\n",
      "Timestep 1\tScore: 14.80\tmin: 14.80\tmax: 14.80actions= [[1. 1.]]\n",
      "1049553  Evaluations Remaining\n",
      "rewards= 0.22316702002118394\n",
      "Timestep 2\tScore: 15.02\tmin: 15.02\tmax: 15.02actions= [[1. 1.]]\n",
      "1049552  Evaluations Remaining\n",
      "rewards= -0.24139253948047745\n",
      "Timestep 3\tScore: 14.78\tmin: 14.78\tmax: 14.78actions= [[1. 1.]]\n",
      "1049551  Evaluations Remaining\n",
      "rewards= 0.22073527584186792\n",
      "Episode 89\tScore: 15.00\tAverage Score: 22.480\n",
      "actions= [[1. 1.]]\n",
      "1049550  Evaluations Remaining\n",
      "rewards= 15.228635033066759\n",
      "actions= [[1. 1.]]\n",
      "1049549  Evaluations Remaining\n",
      "rewards= -0.25525339975368233\n",
      "Timestep 1\tScore: 14.97\tmin: 14.97\tmax: 14.97actions= [[1. 1.]]\n",
      "1049548  Evaluations Remaining\n",
      "rewards= -0.028217719323596402\n",
      "Timestep 2\tScore: 14.95\tmin: 14.95\tmax: 14.95actions= [[1. 1.]]\n",
      "1049547  Evaluations Remaining\n",
      "rewards= 0.019888306582355852\n",
      "Timestep 3\tScore: 14.97\tmin: 14.97\tmax: 14.97actions= [[1. 1.]]\n",
      "1049546  Evaluations Remaining\n",
      "rewards= 0.24143218555501456\n",
      "Episode 90\tScore: 15.21\tAverage Score: 22.311\n",
      "actions= [[1. 1.]]\n",
      "1049545  Evaluations Remaining\n",
      "rewards= 14.617880992431639\n",
      "actions= [[1. 1.]]\n",
      "1049544  Evaluations Remaining\n",
      "rewards= 0.25045167163959814\n",
      "Timestep 1\tScore: 14.87\tmin: 14.87\tmax: 14.87actions= [[1. 1.]]\n",
      "1049543  Evaluations Remaining\n",
      "rewards= -0.050663997055127474\n",
      "Timestep 2\tScore: 14.82\tmin: 14.82\tmax: 14.82actions= [[1. 1.]]\n",
      "1049542  Evaluations Remaining\n",
      "rewards= -0.1311543570919116\n",
      "Timestep 3\tScore: 14.69\tmin: 14.69\tmax: 14.69actions= [[0.97224285 0.        ]]\n",
      "1049541  Evaluations Remaining\n",
      "rewards= -0.08232195624365746\n",
      "Episode 91\tScore: 14.60\tAverage Score: 22.200\n",
      "actions= [[1. 1.]]\n",
      "1049540  Evaluations Remaining\n",
      "rewards= 14.501181067980598\n",
      "actions= [[1. 1.]]\n",
      "1049539  Evaluations Remaining\n",
      "rewards= -0.1823226135580085\n",
      "Timestep 1\tScore: 14.32\tmin: 14.32\tmax: 14.32actions= [[1. 1.]]\n",
      "1049538  Evaluations Remaining\n",
      "rewards= 0.07031338141926735\n",
      "Timestep 2\tScore: 14.39\tmin: 14.39\tmax: 14.39actions= [[1. 1.]]\n",
      "1049537  Evaluations Remaining\n",
      "rewards= 0.17090279193581415\n",
      "Timestep 3\tScore: 14.56\tmin: 14.56\tmax: 14.56actions= [[1. 1.]]\n",
      "1049536  Evaluations Remaining\n",
      "rewards= 0.09671913026715417\n",
      "Episode 92\tScore: 14.66\tAverage Score: 15.036\n",
      "actions= [[1.         0.99915385]]\n",
      "1049535  Evaluations Remaining\n",
      "rewards= 14.450327078059397\n",
      "actions= [[1. 1.]]\n",
      "1049534  Evaluations Remaining\n",
      "rewards= -0.15298807488751986\n",
      "Timestep 1\tScore: 14.30\tmin: 14.30\tmax: 14.30actions= [[1. 1.]]\n",
      "1049533  Evaluations Remaining\n",
      "rewards= -0.06011644029124019\n",
      "Timestep 2\tScore: 14.24\tmin: 14.24\tmax: 14.24actions= [[1. 1.]]\n",
      "1049532  Evaluations Remaining\n",
      "rewards= 0.07230741589434553\n",
      "Timestep 3\tScore: 14.31\tmin: 14.31\tmax: 14.31actions= [[1. 1.]]\n",
      "1049531  Evaluations Remaining\n",
      "rewards= -0.1555523173812925\n",
      "Episode 93\tScore: 14.15\tAverage Score: 14.725\n",
      "actions= [[1. 1.]]\n",
      "1049530  Evaluations Remaining\n",
      "rewards= 15.12781486416675\n",
      "actions= [[1. 1.]]\n",
      "1049529  Evaluations Remaining\n",
      "rewards= 0.03348497524195215\n",
      "Timestep 1\tScore: 15.16\tmin: 15.16\tmax: 15.16actions= [[1. 1.]]\n",
      "1049528  Evaluations Remaining\n",
      "rewards= 0.04048821879427367\n",
      "Timestep 2\tScore: 15.20\tmin: 15.20\tmax: 15.20actions= [[1. 1.]]\n",
      "1049527  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 0.08049729257736349\n",
      "Timestep 3\tScore: 15.28\tmin: 15.28\tmax: 15.28actions= [[0. 1.]]\n",
      "1049526  Evaluations Remaining\n",
      "rewards= 0.18503346232373774\n",
      "Episode 94\tScore: 15.47\tAverage Score: 14.827\n",
      "actions= [[1. 1.]]\n",
      "1049525  Evaluations Remaining\n",
      "rewards= 16.26207636633452\n",
      "actions= [[1. 1.]]\n",
      "1049524  Evaluations Remaining\n",
      "rewards= 0.16961935699577246\n",
      "Timestep 1\tScore: 16.43\tmin: 16.43\tmax: 16.43actions= [[0.         0.75669106]]\n",
      "1049523  Evaluations Remaining\n",
      "rewards= 0.13772136727451167\n",
      "Timestep 2\tScore: 16.57\tmin: 16.57\tmax: 16.57actions= [[1. 1.]]\n",
      "1049522  Evaluations Remaining\n",
      "rewards= 23.41858716892036\n",
      "Timestep 3\tScore: 39.99\tmin: 39.99\tmax: 39.99actions= [[1. 1.]]\n",
      "1049521  Evaluations Remaining\n",
      "rewards= -0.17536686629135811\n",
      "Episode 95\tScore: 39.81\tAverage Score: 19.741\n",
      "actions= [[1. 1.]]\n",
      "1049520  Evaluations Remaining\n",
      "rewards= 14.8367346668932\n",
      "actions= [[1. 1.]]\n",
      "1049519  Evaluations Remaining\n",
      "rewards= 0.02237224286613637\n",
      "Timestep 1\tScore: 14.86\tmin: 14.86\tmax: 14.86actions= [[1. 1.]]\n",
      "1049518  Evaluations Remaining\n",
      "rewards= 0.1699164890632403\n",
      "Timestep 2\tScore: 15.03\tmin: 15.03\tmax: 15.03actions= [[1. 1.]]\n",
      "1049517  Evaluations Remaining\n",
      "rewards= 0.16086518770264924\n",
      "Timestep 3\tScore: 15.19\tmin: 15.19\tmax: 15.19actions= [[1. 1.]]\n",
      "1049516  Evaluations Remaining\n",
      "rewards= 0.10153591083105695\n",
      "Episode 96\tScore: 15.29\tAverage Score: 19.889\n",
      "actions= [[1. 1.]]\n",
      "1049515  Evaluations Remaining\n",
      "rewards= 16.01917259660321\n",
      "actions= [[0.         0.06940401]]\n",
      "1049514  Evaluations Remaining\n",
      "rewards= -0.2308737667346925\n",
      "Timestep 1\tScore: 15.79\tmin: 15.79\tmax: 15.79actions= [[1. 0.]]\n",
      "1049513  Evaluations Remaining\n",
      "rewards= 101.31870472387591\n",
      "Timestep 2\tScore: 117.11\tmin: 117.11\tmax: 117.11actions= [[0.36401788 0.        ]]\n",
      "1049512  Evaluations Remaining\n",
      "rewards= 0.06471408200582296\n",
      "Timestep 3\tScore: 117.17\tmin: 117.17\tmax: 117.17actions= [[1. 1.]]\n",
      "1049511  Evaluations Remaining\n",
      "rewards= 13.105150675879576\n",
      "Episode 97\tScore: 130.28\tAverage Score: 43.00.28\n",
      "actions= [[1.         0.23847078]]\n",
      "1049510  Evaluations Remaining\n",
      "rewards= 21.291922478258165\n",
      "actions= [[1. 1.]]\n",
      "1049509  Evaluations Remaining\n",
      "rewards= 95.79955429055812\n",
      "Timestep 1\tScore: 117.09\tmin: 117.09\tmax: 117.09actions= [[1. 1.]]\n",
      "1049508  Evaluations Remaining\n",
      "rewards= -0.046753753900768746\n",
      "Timestep 2\tScore: 117.04\tmin: 117.04\tmax: 117.04actions= [[1. 1.]]\n",
      "1049507  Evaluations Remaining\n",
      "rewards= 0.08273718913459627\n",
      "Timestep 3\tScore: 117.13\tmin: 117.13\tmax: 117.13actions= [[1. 1.]]\n",
      "1049506  Evaluations Remaining\n",
      "rewards= -0.16475479378507663\n",
      "Episode 98\tScore: 116.96\tAverage Score: 63.56.96\n",
      "actions= [[1. 1.]]\n",
      "1049505  Evaluations Remaining\n",
      "rewards= 14.94325481315274\n",
      "actions= [[1. 1.]]\n",
      "1049504  Evaluations Remaining\n",
      "rewards= 0.06049580533669996\n",
      "Timestep 1\tScore: 15.00\tmin: 15.00\tmax: 15.00actions= [[1. 1.]]\n",
      "1049503  Evaluations Remaining\n",
      "rewards= -0.1681541592245246\n",
      "Timestep 2\tScore: 14.84\tmin: 14.84\tmax: 14.84actions= [[1. 1.]]\n",
      "1049502  Evaluations Remaining\n",
      "rewards= -0.042187984801756784\n",
      "Timestep 3\tScore: 14.79\tmin: 14.79\tmax: 14.79actions= [[1. 1.]]\n",
      "1049501  Evaluations Remaining\n",
      "rewards= -0.12491724136259208\n",
      "Episode 99\tScore: 14.67\tAverage Score: 63.407\n",
      "actions= [[1. 1.]]\n",
      "1049500  Evaluations Remaining\n",
      "rewards= 13.493345065211152\n",
      "actions= [[0.16504418 1.        ]]\n",
      "1049499  Evaluations Remaining\n",
      "rewards= 0.21732921831588392\n",
      "Timestep 1\tScore: 13.71\tmin: 13.71\tmax: 13.71actions= [[1. 1.]]\n",
      "1049498  Evaluations Remaining\n",
      "rewards= 66.6093307875117\n",
      "Timestep 2\tScore: 80.32\tmin: 80.32\tmax: 80.32actions= [[1. 1.]]\n",
      "1049497  Evaluations Remaining\n",
      "rewards= -0.040173020544092886\n",
      "Timestep 3\tScore: 80.28\tmin: 80.28\tmax: 80.28actions= [[1. 1.]]\n",
      "1049496  Evaluations Remaining\n",
      "rewards= 0.11911116455456439\n",
      "Episode 100\tScore: 80.40\tAverage Score: 71.52\n",
      "Episode 100\tAverage Score: 71.52\n",
      "actions= [[1. 1.]]\n",
      "1049495  Evaluations Remaining\n",
      "rewards= 14.718416744626229\n",
      "actions= [[0.45702815 0.14361415]]\n",
      "1049494  Evaluations Remaining\n",
      "rewards= 0.15580468616359777\n",
      "Timestep 1\tScore: 14.87\tmin: 14.87\tmax: 14.87actions= [[1. 1.]]\n",
      "1049493  Evaluations Remaining\n",
      "rewards= 22.214263891802236\n",
      "Timestep 2\tScore: 37.09\tmin: 37.09\tmax: 37.09actions= [[1. 1.]]\n",
      "1049492  Evaluations Remaining\n",
      "rewards= -0.26846022311810813\n",
      "Timestep 3\tScore: 36.82\tmin: 36.82\tmax: 36.82actions= [[1. 1.]]\n",
      "1049491  Evaluations Remaining\n",
      "rewards= -0.21235106841677487\n",
      "Episode 101\tScore: 36.61\tAverage Score: 75.78\n",
      "actions= [[1. 1.]]\n",
      "1049490  Evaluations Remaining\n",
      "rewards= 14.920066383417963\n",
      "actions= [[0.38881096 0.        ]]\n",
      "1049489  Evaluations Remaining\n",
      "rewards= -0.1621614081712517\n",
      "Timestep 1\tScore: 14.76\tmin: 14.76\tmax: 14.76actions= [[1. 1.]]\n",
      "1049488  Evaluations Remaining\n",
      "rewards= 13.488677698679478\n",
      "Timestep 2\tScore: 28.25\tmin: 28.25\tmax: 28.25actions= [[1. 1.]]\n",
      "1049487  Evaluations Remaining\n",
      "rewards= 0.18767593053831133\n",
      "Timestep 3\tScore: 28.43\tmin: 28.43\tmax: 28.43actions= [[0.95767561 0.        ]]\n",
      "1049486  Evaluations Remaining\n",
      "rewards= -0.06841010149114757\n",
      "Episode 102\tScore: 28.37\tAverage Score: 55.40\n",
      "actions= [[1. 1.]]\n",
      "1049485  Evaluations Remaining\n",
      "rewards= 14.609152886812543\n",
      "actions= [[1. 1.]]\n",
      "1049484  Evaluations Remaining\n",
      "rewards= -0.08047648302310106\n",
      "Timestep 1\tScore: 14.53\tmin: 14.53\tmax: 14.53actions= [[1. 1.]]\n",
      "1049483  Evaluations Remaining\n",
      "rewards= -0.1346138294469914\n",
      "Timestep 2\tScore: 14.39\tmin: 14.39\tmax: 14.39actions= [[1. 1.]]\n",
      "1049482  Evaluations Remaining\n",
      "rewards= 0.169393800183832\n",
      "Timestep 3\tScore: 14.56\tmin: 14.56\tmax: 14.56actions= [[1. 1.]]\n",
      "1049481  Evaluations Remaining\n",
      "rewards= -0.23164115139736463\n",
      "Episode 103\tScore: 14.33\tAverage Score: 34.87\n",
      "actions= [[1. 1.]]\n",
      "1049480  Evaluations Remaining\n",
      "rewards= 14.781370869492418\n",
      "actions= [[1. 1.]]\n",
      "1049479  Evaluations Remaining\n",
      "rewards= -0.003995385529002693\n",
      "Timestep 1\tScore: 14.78\tmin: 14.78\tmax: 14.78actions= [[0.09441835 0.        ]]\n",
      "1049478  Evaluations Remaining\n",
      "rewards= -0.03090160784169438\n",
      "Timestep 2\tScore: 14.75\tmin: 14.75\tmax: 14.75actions= [[1. 1.]]\n",
      "1049477  Evaluations Remaining\n",
      "rewards= 20.9774711667885\n",
      "Timestep 3\tScore: 35.72\tmin: 35.72\tmax: 35.72actions= [[1. 1.]]\n",
      "1049476  Evaluations Remaining\n",
      "rewards= 0.2542632208266755\n",
      "Episode 104\tScore: 35.98\tAverage Score: 39.14\n",
      "actions= [[1. 1.]]\n",
      "1049475  Evaluations Remaining\n",
      "rewards= 14.995956456310811\n",
      "actions= [[1. 1.]]\n",
      "1049474  Evaluations Remaining\n",
      "rewards= -0.15169745093317566\n",
      "Timestep 1\tScore: 14.84\tmin: 14.84\tmax: 14.84actions= [[1. 1.]]\n",
      "1049473  Evaluations Remaining\n",
      "rewards= -0.19253058191675532\n",
      "Timestep 2\tScore: 14.65\tmin: 14.65\tmax: 14.65actions= [[0.87108858 0.        ]]\n",
      "1049472  Evaluations Remaining\n",
      "rewards= -0.18137683312672737\n",
      "Timestep 3\tScore: 14.47\tmin: 14.47\tmax: 14.47actions= [[0.43349167 0.        ]]\n",
      "1049471  Evaluations Remaining\n",
      "rewards= 0.13941889932358587\n",
      "Episode 105\tScore: 14.61\tAverage Score: 25.98\n",
      "actions= [[1. 1.]]\n",
      "1049470  Evaluations Remaining\n",
      "rewards= 16.20473263561762\n",
      "actions= [[1. 1.]]\n",
      "1049469  Evaluations Remaining\n",
      "rewards= -0.11635753450359498\n",
      "Timestep 1\tScore: 16.09\tmin: 16.09\tmax: 16.09actions= [[0.52749855 0.        ]]\n",
      "1049468  Evaluations Remaining\n",
      "rewards= -0.011679383146837807\n",
      "Timestep 2\tScore: 16.08\tmin: 16.08\tmax: 16.08actions= [[0. 0.]]\n",
      "1049467  Evaluations Remaining\n",
      "rewards= -0.20902287974590328\n",
      "Timestep 3\tScore: 15.87\tmin: 15.87\tmax: 15.87actions= [[1. 1.]]\n",
      "1049466  Evaluations Remaining\n",
      "rewards= 10.851000124784136\n",
      "Episode 106\tScore: 26.72\tAverage Score: 24.00\n",
      "actions= [[1. 0.]]\n",
      "1049465  Evaluations Remaining\n",
      "rewards= 99.22081091419503\n",
      "actions= [[1. 1.]]\n",
      "1049464  Evaluations Remaining\n",
      "rewards= 103.08122166730897\n",
      "Timestep 1\tScore: 202.30\tmin: 202.30\tmax: 202.30actions= [[1. 1.]]\n",
      "1049463  Evaluations Remaining\n",
      "rewards= -0.20265288208487853\n",
      "Timestep 2\tScore: 202.10\tmin: 202.10\tmax: 202.10actions= [[1. 1.]]\n",
      "1049462  Evaluations Remaining\n",
      "rewards= -0.2501560684196211\n",
      "Timestep 3\tScore: 201.85\tmin: 201.85\tmax: 201.85actions= [[0.24615208 0.99218041]]\n",
      "1049461  Evaluations Remaining\n",
      "rewards= 0.12448255441752165\n",
      "Episode 107\tScore: 201.97\tAverage Score: 58.7297\n",
      "actions= [[1. 1.]]\n",
      "1049460  Evaluations Remaining\n",
      "rewards= 15.994829299856704\n",
      "actions= [[1. 1.]]\n",
      "1049459  Evaluations Remaining\n",
      "rewards= 0.22871884640790752\n",
      "Timestep 1\tScore: 16.22\tmin: 16.22\tmax: 16.22actions= [[1. 1.]]\n",
      "1049458  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 0.21011747660026403\n",
      "Timestep 2\tScore: 16.43\tmin: 16.43\tmax: 16.43actions= [[1. 1.]]\n",
      "1049457  Evaluations Remaining\n",
      "rewards= 0.12327306092922097\n",
      "Timestep 3\tScore: 16.56\tmin: 16.56\tmax: 16.56actions= [[1. 1.]]\n",
      "1049456  Evaluations Remaining\n",
      "rewards= -0.013279585689577988\n",
      "Episode 108\tScore: 16.54\tAverage Score: 59.16\n",
      "actions= [[1. 1.]]\n",
      "1049455  Evaluations Remaining\n",
      "rewards= 15.35763010890605\n",
      "actions= [[1. 0.]]\n",
      "1049454  Evaluations Remaining\n",
      "rewards= 0.26859491408603864\n",
      "Timestep 1\tScore: 15.63\tmin: 15.63\tmax: 15.63actions= [[1. 1.]]\n",
      "1049453  Evaluations Remaining\n",
      "rewards= 100.15792814998532\n",
      "Timestep 2\tScore: 115.78\tmin: 115.78\tmax: 115.78actions= [[1. 1.]]\n",
      "1049452  Evaluations Remaining\n",
      "rewards= -0.14534125342397308\n",
      "Timestep 3\tScore: 115.64\tmin: 115.64\tmax: 115.64actions= [[0.         0.49864069]]\n",
      "1049451  Evaluations Remaining\n",
      "rewards= -0.07639520353529061\n",
      "Episode 109\tScore: 115.56\tAverage Score: 75.0856\n",
      "actions= [[1. 1.]]\n",
      "1049450  Evaluations Remaining\n",
      "rewards= 15.223863008951263\n",
      "actions= [[1. 1.]]\n",
      "1049449  Evaluations Remaining\n",
      "rewards= -0.040809079065458054\n",
      "Timestep 1\tScore: 15.18\tmin: 15.18\tmax: 15.18actions= [[1. 1.]]\n",
      "1049448  Evaluations Remaining\n",
      "rewards= -0.15746604115058327\n",
      "Timestep 2\tScore: 15.03\tmin: 15.03\tmax: 15.03actions= [[0. 0.]]\n",
      "1049447  Evaluations Remaining\n",
      "rewards= 0.25866519460779136\n",
      "Timestep 3\tScore: 15.28\tmin: 15.28\tmax: 15.28actions= [[0. 0.]]\n",
      "1049446  Evaluations Remaining\n",
      "rewards= 0.07135364301217795\n",
      "Episode 110\tScore: 15.36\tAverage Score: 75.23\n",
      "actions= [[1. 1.]]\n",
      "1049445  Evaluations Remaining\n",
      "rewards= 14.131728832167413\n",
      "actions= [[1. 1.]]\n",
      "1049444  Evaluations Remaining\n",
      "rewards= -0.2362314808053516\n",
      "Timestep 1\tScore: 13.90\tmin: 13.90\tmax: 13.90actions= [[1. 1.]]\n",
      "1049443  Evaluations Remaining\n",
      "rewards= 0.06285783074689277\n",
      "Timestep 2\tScore: 13.96\tmin: 13.96\tmax: 13.96actions= [[1. 1.]]\n",
      "1049442  Evaluations Remaining\n",
      "rewards= 0.14237904897029763\n",
      "Timestep 3\tScore: 14.10\tmin: 14.10\tmax: 14.10actions= [[0.         0.14093261]]\n",
      "1049441  Evaluations Remaining\n",
      "rewards= 0.24545411722906563\n",
      "Episode 111\tScore: 14.35\tAverage Score: 72.76\n",
      "actions= [[1. 1.]]\n",
      "1049440  Evaluations Remaining\n",
      "rewards= 14.12033469082975\n",
      "actions= [[1. 1.]]\n",
      "1049439  Evaluations Remaining\n",
      "rewards= -0.1365106963316416\n",
      "Timestep 1\tScore: 13.98\tmin: 13.98\tmax: 13.98actions= [[1. 1.]]\n",
      "1049438  Evaluations Remaining\n",
      "rewards= -0.05369521677455369\n",
      "Timestep 2\tScore: 13.93\tmin: 13.93\tmax: 13.93actions= [[1. 1.]]\n",
      "1049437  Evaluations Remaining\n",
      "rewards= 0.12343026981497207\n",
      "Timestep 3\tScore: 14.05\tmin: 14.05\tmax: 14.05actions= [[1. 1.]]\n",
      "1049436  Evaluations Remaining\n",
      "rewards= -0.0019564153991349365\n",
      "Episode 112\tScore: 14.05\tAverage Score: 35.17\n",
      "actions= [[1. 1.]]\n",
      "1049435  Evaluations Remaining\n",
      "rewards= 15.699992675533181\n",
      "actions= [[1. 1.]]\n",
      "1049434  Evaluations Remaining\n",
      "rewards= 0.02073142360568525\n",
      "Timestep 1\tScore: 15.72\tmin: 15.72\tmax: 15.72actions= [[1.         0.00837349]]\n",
      "1049433  Evaluations Remaining\n",
      "rewards= -0.0027113558252569447\n",
      "Timestep 2\tScore: 15.72\tmin: 15.72\tmax: 15.72actions= [[1. 1.]]\n",
      "1049432  Evaluations Remaining\n",
      "rewards= 95.3274610830443\n",
      "Timestep 3\tScore: 111.05\tmin: 111.05\tmax: 111.05actions= [[1. 1.]]\n",
      "1049431  Evaluations Remaining\n",
      "rewards= 0.07878338574683674\n",
      "Episode 113\tScore: 111.12\tAverage Score: 54.0912\n",
      "actions= [[1. 1.]]\n",
      "1049430  Evaluations Remaining\n",
      "rewards= 14.658284356653557\n",
      "actions= [[0.         0.41519717]]\n",
      "1049429  Evaluations Remaining\n",
      "rewards= -0.10293270904858476\n",
      "Timestep 1\tScore: 14.56\tmin: 14.56\tmax: 14.56actions= [[1. 1.]]\n",
      "1049428  Evaluations Remaining\n",
      "rewards= 27.557095246861323\n",
      "Timestep 2\tScore: 42.11\tmin: 42.11\tmax: 42.11actions= [[1. 1.]]\n",
      "1049427  Evaluations Remaining\n",
      "rewards= -0.0074838666316834335\n",
      "Timestep 3\tScore: 42.10\tmin: 42.10\tmax: 42.10actions= [[0. 0.]]\n",
      "1049426  Evaluations Remaining\n",
      "rewards= -0.1671463896391554\n",
      "Episode 114\tScore: 41.94\tAverage Score: 39.36\n",
      "actions= [[1. 1.]]\n",
      "1049425  Evaluations Remaining\n",
      "rewards= 13.821107791376484\n",
      "actions= [[1. 1.]]\n",
      "1049424  Evaluations Remaining\n",
      "rewards= -0.08944122031747659\n",
      "Timestep 1\tScore: 13.73\tmin: 13.73\tmax: 13.73actions= [[0. 0.]]\n",
      "1049423  Evaluations Remaining\n",
      "rewards= 0.1712526813298978\n",
      "Timestep 2\tScore: 13.90\tmin: 13.90\tmax: 13.90actions= [[1. 1.]]\n",
      "1049422  Evaluations Remaining\n",
      "rewards= 13.027977770414862\n",
      "Timestep 3\tScore: 26.93\tmin: 26.93\tmax: 26.93actions= [[1. 1.]]\n",
      "1049421  Evaluations Remaining\n",
      "rewards= 0.0338247468381927\n",
      "Episode 115\tScore: 26.96\tAverage Score: 41.68\n",
      "actions= [[1. 1.]]\n",
      "1049420  Evaluations Remaining\n",
      "rewards= 15.697428752309728\n",
      "actions= [[0.49182911 0.        ]]\n",
      "1049419  Evaluations Remaining\n",
      "rewards= 0.006888321108503792\n",
      "Timestep 1\tScore: 15.70\tmin: 15.70\tmax: 15.70actions= [[0.         0.72418593]]\n",
      "1049418  Evaluations Remaining\n",
      "rewards= 72.90597742177769\n",
      "Timestep 2\tScore: 88.61\tmin: 88.61\tmax: 88.61actions= [[0.75447228 0.        ]]\n",
      "1049417  Evaluations Remaining\n",
      "rewards= 49.82789622615537\n",
      "Timestep 3\tScore: 138.44\tmin: 138.44\tmax: 138.44actions= [[0. 0.]]\n",
      "1049416  Evaluations Remaining\n",
      "rewards= 0.051538531765977336\n",
      "Episode 116\tScore: 138.49\tAverage Score: 66.5149\n",
      "actions= [[0. 0.]]\n",
      "1049415  Evaluations Remaining\n",
      "rewards= 2.624255510113086\n",
      "actions= [[1. 1.]]\n",
      "1049414  Evaluations Remaining\n",
      "rewards= 13.67120474746805\n",
      "Timestep 1\tScore: 16.30\tmin: 16.30\tmax: 16.30actions= [[1. 1.]]\n",
      "1049413  Evaluations Remaining\n",
      "rewards= 0.052058187524787414\n",
      "Timestep 2\tScore: 16.35\tmin: 16.35\tmax: 16.35actions= [[1. 1.]]\n",
      "1049412  Evaluations Remaining\n",
      "rewards= 0.1499522624966665\n",
      "Timestep 3\tScore: 16.50\tmin: 16.50\tmax: 16.50actions= [[1. 1.]]\n",
      "1049411  Evaluations Remaining\n",
      "rewards= -0.133982818657989\n",
      "Episode 117\tScore: 16.36\tAverage Score: 66.98\n",
      "actions= [[1. 1.]]\n",
      "1049410  Evaluations Remaining\n",
      "rewards= 16.228660997254202\n",
      "actions= [[0.53844511 0.87779455]]\n",
      "1049409  Evaluations Remaining\n",
      "rewards= -0.00026871984083332023\n",
      "Timestep 1\tScore: 16.23\tmin: 16.23\tmax: 16.23actions= [[1. 1.]]\n",
      "1049408  Evaluations Remaining\n",
      "rewards= 1.26795163146853\n",
      "Timestep 2\tScore: 17.50\tmin: 17.50\tmax: 17.50actions= [[0.         0.23931894]]\n",
      "1049407  Evaluations Remaining\n",
      "rewards= 0.25160832264891697\n",
      "Timestep 3\tScore: 17.75\tmin: 17.75\tmax: 17.75actions= [[1. 0.]]\n",
      "1049406  Evaluations Remaining\n",
      "rewards= 90.35696462707445\n",
      "Episode 118\tScore: 108.10\tAverage Score: 66.3710\n",
      "actions= [[1. 1.]]\n",
      "1049405  Evaluations Remaining\n",
      "rewards= 15.98849765832767\n",
      "actions= [[1. 1.]]\n",
      "1049404  Evaluations Remaining\n",
      "rewards= -0.11930591494840259\n",
      "Timestep 1\tScore: 15.87\tmin: 15.87\tmax: 15.87actions= [[1. 1.]]\n",
      "1049403  Evaluations Remaining\n",
      "rewards= 0.11647509879966034\n",
      "Timestep 2\tScore: 15.99\tmin: 15.99\tmax: 15.99actions= [[1. 0.]]\n",
      "1049402  Evaluations Remaining\n",
      "rewards= 0.20129343357851948\n",
      "Timestep 3\tScore: 16.19\tmin: 16.19\tmax: 16.19actions= [[1. 1.]]\n",
      "1049401  Evaluations Remaining\n",
      "rewards= 106.1069564846571\n",
      "Episode 119\tScore: 122.29\tAverage Score: 82.4429\n",
      "actions= [[1. 1.]]\n",
      "1049400  Evaluations Remaining\n",
      "rewards= 15.566664504096488\n",
      "actions= [[0.12798732 0.        ]]\n",
      "1049399  Evaluations Remaining\n",
      "rewards= 0.2284268571261201\n",
      "Timestep 1\tScore: 15.80\tmin: 15.80\tmax: 15.80actions= [[1. 1.]]\n",
      "1049398  Evaluations Remaining\n",
      "rewards= 11.154696543017979\n",
      "Timestep 2\tScore: 26.95\tmin: 26.95\tmax: 26.95actions= [[1. 1.]]\n",
      "1049397  Evaluations Remaining\n",
      "rewards= -0.07686762036495809\n",
      "Timestep 3\tScore: 26.87\tmin: 26.87\tmax: 26.87actions= [[1. 1.]]\n",
      "1049396  Evaluations Remaining\n",
      "rewards= -0.2503929222893895\n",
      "Episode 120\tScore: 26.62\tAverage Score: 82.37\n",
      "actions= [[1. 1.]]\n",
      "1049395  Evaluations Remaining\n",
      "rewards= 15.092846121488265\n",
      "actions= [[1. 1.]]\n",
      "1049394  Evaluations Remaining\n",
      "rewards= -0.14505636321680093\n",
      "Timestep 1\tScore: 14.95\tmin: 14.95\tmax: 14.95actions= [[1. 1.]]\n",
      "1049393  Evaluations Remaining\n",
      "rewards= -0.13207235847729537\n",
      "Timestep 2\tScore: 14.82\tmin: 14.82\tmax: 14.82actions= [[0. 0.]]\n",
      "1049392  Evaluations Remaining\n",
      "rewards= -0.07390968361545491\n",
      "Timestep 3\tScore: 14.74\tmin: 14.74\tmax: 14.74actions= [[1. 1.]]\n",
      "1049391  Evaluations Remaining\n",
      "rewards= 11.242464981640007\n",
      "Episode 121\tScore: 25.98\tAverage Score: 59.87\n",
      "actions= [[1. 1.]]\n",
      "1049390  Evaluations Remaining\n",
      "rewards= 16.325749234490395\n",
      "actions= [[1. 1.]]\n",
      "1049389  Evaluations Remaining\n",
      "rewards= 0.09835628056730306\n",
      "Timestep 1\tScore: 16.42\tmin: 16.42\tmax: 16.42actions= [[1. 1.]]\n",
      "1049388  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 0.013509422469069499\n",
      "Timestep 2\tScore: 16.44\tmin: 16.44\tmax: 16.44actions= [[1. 1.]]\n",
      "1049387  Evaluations Remaining\n",
      "rewards= 0.2466942260756979\n",
      "Timestep 3\tScore: 16.68\tmin: 16.68\tmax: 16.68actions= [[1. 1.]]\n",
      "1049386  Evaluations Remaining\n",
      "rewards= 0.006916020577653725\n",
      "Episode 122\tScore: 16.69\tAverage Score: 59.94\n",
      "actions= [[1. 1.]]\n",
      "1049385  Evaluations Remaining\n",
      "rewards= 16.331653141753716\n",
      "actions= [[0.         0.63410726]]\n",
      "1049384  Evaluations Remaining\n",
      "rewards= 0.16104091894901984\n",
      "Timestep 1\tScore: 16.49\tmin: 16.49\tmax: 16.49actions= [[1. 1.]]\n",
      "1049383  Evaluations Remaining\n",
      "rewards= 54.06985634020597\n",
      "Timestep 2\tScore: 70.56\tmin: 70.56\tmax: 70.56actions= [[0.         0.94034352]]\n",
      "1049382  Evaluations Remaining\n",
      "rewards= 0.002316032292135173\n",
      "Timestep 3\tScore: 70.56\tmin: 70.56\tmax: 70.56actions= [[0.         0.38790601]]\n",
      "1049381  Evaluations Remaining\n",
      "rewards= 1.6587168963764456\n",
      "Episode 123\tScore: 72.22\tAverage Score: 52.76\n",
      "actions= [[1. 1.]]\n",
      "1049380  Evaluations Remaining\n",
      "rewards= 14.285634615938738\n",
      "actions= [[1. 1.]]\n",
      "1049379  Evaluations Remaining\n",
      "rewards= -0.14845997709631575\n",
      "Timestep 1\tScore: 14.14\tmin: 14.14\tmax: 14.14actions= [[1. 1.]]\n",
      "1049378  Evaluations Remaining\n",
      "rewards= 0.2147151513638912\n",
      "Timestep 2\tScore: 14.35\tmin: 14.35\tmax: 14.35actions= [[1. 1.]]\n",
      "1049377  Evaluations Remaining\n",
      "rewards= 0.1428095621885217\n",
      "Timestep 3\tScore: 14.49\tmin: 14.49\tmax: 14.49actions= [[1. 1.]]\n",
      "1049376  Evaluations Remaining\n",
      "rewards= 0.04368502328501078\n",
      "Episode 124\tScore: 14.54\tAverage Score: 31.21\n",
      "actions= [[1. 1.]]\n",
      "1049375  Evaluations Remaining\n",
      "rewards= 16.31169356118328\n",
      "actions= [[1. 1.]]\n",
      "1049374  Evaluations Remaining\n",
      "rewards= -0.12610502852237504\n",
      "Timestep 1\tScore: 16.19\tmin: 16.19\tmax: 16.19actions= [[0.         0.32835927]]\n",
      "1049373  Evaluations Remaining\n",
      "rewards= -0.1644372843185531\n",
      "Timestep 2\tScore: 16.02\tmin: 16.02\tmax: 16.02actions= [[1. 1.]]\n",
      "1049372  Evaluations Remaining\n",
      "rewards= -10.733445416015384\n",
      "Timestep 3\tScore: 5.29\tmin: 5.29\tmax: 5.29actions= [[1. 1.]]\n",
      "1049371  Evaluations Remaining\n",
      "rewards= 0.14184972967269038\n",
      "Episode 125\tScore: 5.43\tAverage Score: 26.97\n",
      "actions= [[1. 1.]]\n",
      "1049370  Evaluations Remaining\n",
      "rewards= 14.4619071838403\n",
      "actions= [[1. 1.]]\n",
      "1049369  Evaluations Remaining\n",
      "rewards= -0.040045324134661886\n",
      "Timestep 1\tScore: 14.42\tmin: 14.42\tmax: 14.42actions= [[1. 1.]]\n",
      "1049368  Evaluations Remaining\n",
      "rewards= 0.26133340541758177\n",
      "Timestep 2\tScore: 14.68\tmin: 14.68\tmax: 14.68actions= [[1. 1.]]\n",
      "1049367  Evaluations Remaining\n",
      "rewards= -0.23464755090634837\n",
      "Timestep 3\tScore: 14.45\tmin: 14.45\tmax: 14.45actions= [[1. 1.]]\n",
      "1049366  Evaluations Remaining\n",
      "rewards= 0.03597334933124863\n",
      "Episode 126\tScore: 14.48\tAverage Score: 24.67\n",
      "actions= [[1. 1.]]\n",
      "1049365  Evaluations Remaining\n",
      "rewards= 14.22186249609692\n",
      "actions= [[1. 1.]]\n",
      "1049364  Evaluations Remaining\n",
      "rewards= -0.050298390567592666\n",
      "Timestep 1\tScore: 14.17\tmin: 14.17\tmax: 14.17actions= [[0.         0.23327909]]\n",
      "1049363  Evaluations Remaining\n",
      "rewards= 0.12047013698562292\n",
      "Timestep 2\tScore: 14.29\tmin: 14.29\tmax: 14.29actions= [[1. 1.]]\n",
      "1049362  Evaluations Remaining\n",
      "rewards= -68.89352283391133\n",
      "Timestep 3\tScore: -54.60\tmin: -54.60\tmax: -54.60actions= [[1. 1.]]\n",
      "1049361  Evaluations Remaining\n",
      "rewards= -0.2507582528976351\n",
      "Episode 127\tScore: -54.85\tAverage Score: 10.3685\n",
      "actions= [[1. 1.]]\n",
      "1049360  Evaluations Remaining\n",
      "rewards= 14.806103448993056\n",
      "actions= [[1. 1.]]\n",
      "1049359  Evaluations Remaining\n",
      "rewards= -0.1280761965411359\n",
      "Timestep 1\tScore: 14.68\tmin: 14.68\tmax: 14.68actions= [[1. 1.]]\n",
      "1049358  Evaluations Remaining\n",
      "rewards= 0.16188274676853576\n",
      "Timestep 2\tScore: 14.84\tmin: 14.84\tmax: 14.84actions= [[1. 1.]]\n",
      "1049357  Evaluations Remaining\n",
      "rewards= 0.13022244268102412\n",
      "Timestep 3\tScore: 14.97\tmin: 14.97\tmax: 14.97actions= [[1. 1.]]\n",
      "1049356  Evaluations Remaining\n",
      "rewards= -0.2067637708747707\n",
      "Episode 128\tScore: 14.76\tAverage Score: -1.13\n",
      "actions= [[1. 1.]]\n",
      "1049355  Evaluations Remaining\n",
      "rewards= 14.225761990063026\n",
      "actions= [[1. 1.]]\n",
      "1049354  Evaluations Remaining\n",
      "rewards= 0.057078637852437275\n",
      "Timestep 1\tScore: 14.28\tmin: 14.28\tmax: 14.28actions= [[1. 1.]]\n",
      "1049353  Evaluations Remaining\n",
      "rewards= 0.09855614585524597\n",
      "Timestep 2\tScore: 14.38\tmin: 14.38\tmax: 14.38actions= [[0.69763556 0.34826493]]\n",
      "1049352  Evaluations Remaining\n",
      "rewards= 0.008011480014415095\n",
      "Timestep 3\tScore: 14.39\tmin: 14.39\tmax: 14.39actions= [[1. 1.]]\n",
      "1049351  Evaluations Remaining\n",
      "rewards= -7.405190957722882\n",
      "Episode 129\tScore: 6.98\tAverage Score: -2.64\n",
      "actions= [[1. 1.]]\n",
      "1049350  Evaluations Remaining\n",
      "rewards= 13.982002577516262\n",
      "actions= [[1. 1.]]\n",
      "1049349  Evaluations Remaining\n",
      "rewards= 0.24430930029572728\n",
      "Timestep 1\tScore: 14.23\tmin: 14.23\tmax: 14.23actions= [[1. 1.]]\n",
      "1049348  Evaluations Remaining\n",
      "rewards= -0.17195870664876844\n",
      "Timestep 2\tScore: 14.05\tmin: 14.05\tmax: 14.05actions= [[1.         0.81696939]]\n",
      "1049347  Evaluations Remaining\n",
      "rewards= 0.24646622695163023\n",
      "Timestep 3\tScore: 14.30\tmin: 14.30\tmax: 14.30actions= [[0. 0.]]\n",
      "1049346  Evaluations Remaining\n",
      "rewards= -0.008646950329360248\n",
      "Episode 130\tScore: 14.29\tAverage Score: -0.87\n",
      "actions= [[1. 1.]]\n",
      "1049345  Evaluations Remaining\n",
      "rewards= 14.385802238412971\n",
      "actions= [[1. 1.]]\n",
      "1049344  Evaluations Remaining\n",
      "rewards= -0.13805760917147536\n",
      "Timestep 1\tScore: 14.25\tmin: 14.25\tmax: 14.25actions= [[1. 1.]]\n",
      "1049343  Evaluations Remaining\n",
      "rewards= 0.039832785101771684\n",
      "Timestep 2\tScore: 14.29\tmin: 14.29\tmax: 14.29actions= [[1.         0.45269422]]\n",
      "1049342  Evaluations Remaining\n",
      "rewards= 0.07920163896246057\n",
      "Timestep 3\tScore: 14.37\tmin: 14.37\tmax: 14.37actions= [[1. 1.]]\n",
      "1049341  Evaluations Remaining\n",
      "rewards= 26.36150715239516\n",
      "Episode 131\tScore: 40.73\tAverage Score: 4.383\n",
      "actions= [[1. 1.]]\n",
      "1049340  Evaluations Remaining\n",
      "rewards= 15.572345814098624\n",
      "actions= [[1. 1.]]\n",
      "1049339  Evaluations Remaining\n",
      "rewards= 0.018517089228236028\n",
      "Timestep 1\tScore: 15.59\tmin: 15.59\tmax: 15.59actions= [[1. 1.]]\n",
      "1049338  Evaluations Remaining\n",
      "rewards= -0.2188690716671573\n",
      "Timestep 2\tScore: 15.37\tmin: 15.37\tmax: 15.37actions= [[1. 1.]]\n",
      "1049337  Evaluations Remaining\n",
      "rewards= -0.03942337349869529\n",
      "Timestep 3\tScore: 15.33\tmin: 15.33\tmax: 15.33actions= [[0. 0.]]\n",
      "1049336  Evaluations Remaining\n",
      "rewards= -0.22066381220531994\n",
      "Episode 132\tScore: 15.11\tAverage Score: 18.38\n",
      "actions= [[1. 1.]]\n",
      "1049335  Evaluations Remaining\n",
      "rewards= 14.263250662994926\n",
      "actions= [[0. 0.]]\n",
      "1049334  Evaluations Remaining\n",
      "rewards= -0.07150746533089736\n",
      "Timestep 1\tScore: 14.19\tmin: 14.19\tmax: 14.19actions= [[0.94310083 0.6313521 ]]\n",
      "1049333  Evaluations Remaining\n",
      "rewards= 2.5282574836820344\n",
      "Timestep 2\tScore: 16.72\tmin: 16.72\tmax: 16.72actions= [[0. 0.]]\n",
      "1049332  Evaluations Remaining\n",
      "rewards= 0.03159875965745007\n",
      "Timestep 3\tScore: 16.75\tmin: 16.75\tmax: 16.75actions= [[1. 1.]]\n",
      "1049331  Evaluations Remaining\n",
      "rewards= 10.795949071899795\n",
      "Episode 133\tScore: 27.55\tAverage Score: 20.93\n",
      "actions= [[1. 1.]]\n",
      "1049330  Evaluations Remaining\n",
      "rewards= 13.639214086859374\n",
      "actions= [[1. 1.]]\n",
      "1049329  Evaluations Remaining\n",
      "rewards= 0.1256789815813848\n",
      "Timestep 1\tScore: 13.76\tmin: 13.76\tmax: 13.76actions= [[0.06433732 0.74565245]]\n",
      "1049328  Evaluations Remaining\n",
      "rewards= 0.09938208416405958\n",
      "Timestep 2\tScore: 13.86\tmin: 13.86\tmax: 13.86actions= [[0.13522523 1.        ]]\n",
      "1049327  Evaluations Remaining\n",
      "rewards= 1.3997871169283838\n",
      "Timestep 3\tScore: 15.26\tmin: 15.26\tmax: 15.26actions= [[1. 1.]]\n",
      "1049326  Evaluations Remaining\n",
      "rewards= 64.80200046028637\n",
      "Episode 134\tScore: 80.07\tAverage Score: 35.55\n",
      "actions= [[1. 1.]]\n",
      "1049325  Evaluations Remaining\n",
      "rewards= 16.254368084927126\n",
      "actions= [[1. 1.]]\n",
      "1049324  Evaluations Remaining\n",
      "rewards= 0.0073565571356923876\n",
      "Timestep 1\tScore: 16.26\tmin: 16.26\tmax: 16.26actions= [[1. 1.]]\n",
      "1049323  Evaluations Remaining\n",
      "rewards= -0.12246186896969613\n",
      "Timestep 2\tScore: 16.14\tmin: 16.14\tmax: 16.14actions= [[1. 1.]]\n",
      "1049322  Evaluations Remaining\n",
      "rewards= 0.20209172869649938\n",
      "Timestep 3\tScore: 16.34\tmin: 16.34\tmax: 16.34actions= [[1. 1.]]\n",
      "1049321  Evaluations Remaining\n",
      "rewards= -0.2626992743992842\n",
      "Episode 135\tScore: 16.08\tAverage Score: 35.91\n",
      "actions= [[1. 1.]]\n",
      "1049320  Evaluations Remaining\n",
      "rewards= 15.475159518840528\n",
      "actions= [[1. 1.]]\n",
      "1049319  Evaluations Remaining\n",
      "rewards= -0.06293157835773222\n",
      "Timestep 1\tScore: 15.41\tmin: 15.41\tmax: 15.41actions= [[1. 1.]]\n",
      "1049318  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= -0.1152858949594684\n",
      "Timestep 2\tScore: 15.30\tmin: 15.30\tmax: 15.30actions= [[1. 1.]]\n",
      "1049317  Evaluations Remaining\n",
      "rewards= 0.06731195154900949\n",
      "Timestep 3\tScore: 15.36\tmin: 15.36\tmax: 15.36actions= [[1. 1.]]\n",
      "1049316  Evaluations Remaining\n",
      "rewards= -0.05144633261556519\n",
      "Episode 136\tScore: 15.31\tAverage Score: 30.82\n",
      "actions= [[0.00855514 0.        ]]\n",
      "1049315  Evaluations Remaining\n",
      "rewards= 2.8729072020873136\n",
      "actions= [[1. 1.]]\n",
      "1049314  Evaluations Remaining\n",
      "rewards= 16.073517703523216\n",
      "Timestep 1\tScore: 18.95\tmin: 18.95\tmax: 18.95actions= [[1. 1.]]\n",
      "1049313  Evaluations Remaining\n",
      "rewards= 0.14605670718036157\n",
      "Timestep 2\tScore: 19.09\tmin: 19.09\tmax: 19.09actions= [[1.         0.65033272]]\n",
      "1049312  Evaluations Remaining\n",
      "rewards= -0.19821219277210567\n",
      "Timestep 3\tScore: 18.89\tmin: 18.89\tmax: 18.89actions= [[1. 1.]]\n",
      "1049311  Evaluations Remaining\n",
      "rewards= 10.803791264391583\n",
      "Episode 137\tScore: 29.70\tAverage Score: 33.74\n",
      "actions= [[1. 1.]]\n",
      "1049310  Evaluations Remaining\n",
      "rewards= 15.388052456652623\n",
      "actions= [[1. 1.]]\n",
      "1049309  Evaluations Remaining\n",
      "rewards= -0.03872984425919457\n",
      "Timestep 1\tScore: 15.35\tmin: 15.35\tmax: 15.35actions= [[1. 1.]]\n",
      "1049308  Evaluations Remaining\n",
      "rewards= -0.16650800274126887\n",
      "Timestep 2\tScore: 15.18\tmin: 15.18\tmax: 15.18actions= [[1. 1.]]\n",
      "1049307  Evaluations Remaining\n",
      "rewards= -0.22596657004535192\n",
      "Timestep 3\tScore: 14.96\tmin: 14.96\tmax: 14.96actions= [[1. 1.]]\n",
      "1049306  Evaluations Remaining\n",
      "rewards= 0.22470208014186444\n",
      "Episode 138\tScore: 15.18\tAverage Score: 31.27\n",
      "actions= [[1. 0.]]\n",
      "1049305  Evaluations Remaining\n",
      "rewards= 93.45874878092027\n",
      "actions= [[1. 1.]]\n",
      "1049304  Evaluations Remaining\n",
      "rewards= 96.92667343836447\n",
      "Timestep 1\tScore: 190.39\tmin: 190.39\tmax: 190.39actions= [[1. 1.]]\n",
      "1049303  Evaluations Remaining\n",
      "rewards= 0.13091630663786802\n",
      "Timestep 2\tScore: 190.52\tmin: 190.52\tmax: 190.52actions= [[1. 1.]]\n",
      "1049302  Evaluations Remaining\n",
      "rewards= 0.21550518189766077\n",
      "Timestep 3\tScore: 190.73\tmin: 190.73\tmax: 190.73actions= [[1. 1.]]\n",
      "1049301  Evaluations Remaining\n",
      "rewards= -0.0230184421680506\n",
      "Episode 139\tScore: 190.71\tAverage Score: 53.4071\n",
      "actions= [[1. 1.]]\n",
      "1049300  Evaluations Remaining\n",
      "rewards= 14.695112889958162\n",
      "actions= [[1. 1.]]\n",
      "1049299  Evaluations Remaining\n",
      "rewards= -0.003864887894823088\n",
      "Timestep 1\tScore: 14.69\tmin: 14.69\tmax: 14.69actions= [[1. 1.]]\n",
      "1049298  Evaluations Remaining\n",
      "rewards= -0.03475438936380648\n",
      "Timestep 2\tScore: 14.66\tmin: 14.66\tmax: 14.66actions= [[1. 1.]]\n",
      "1049297  Evaluations Remaining\n",
      "rewards= -0.20377392004373762\n",
      "Timestep 3\tScore: 14.45\tmin: 14.45\tmax: 14.45actions= [[1. 1.]]\n",
      "1049296  Evaluations Remaining\n",
      "rewards= 0.0016208288902288537\n",
      "Episode 140\tScore: 14.45\tAverage Score: 53.07\n",
      "actions= [[1. 1.]]\n",
      "1049295  Evaluations Remaining\n",
      "rewards= 16.41257344931779\n",
      "actions= [[1. 1.]]\n",
      "1049294  Evaluations Remaining\n",
      "rewards= -0.03822030127574294\n",
      "Timestep 1\tScore: 16.37\tmin: 16.37\tmax: 16.37actions= [[1. 1.]]\n",
      "1049293  Evaluations Remaining\n",
      "rewards= -0.12533090303596106\n",
      "Timestep 2\tScore: 16.25\tmin: 16.25\tmax: 16.25actions= [[1. 1.]]\n",
      "1049292  Evaluations Remaining\n",
      "rewards= -0.08425462975450637\n",
      "Timestep 3\tScore: 16.16\tmin: 16.16\tmax: 16.16actions= [[1. 1.]]\n",
      "1049291  Evaluations Remaining\n",
      "rewards= 0.17369380003852575\n",
      "Episode 141\tScore: 16.34\tAverage Score: 53.28\n",
      "actions= [[1. 1.]]\n",
      "1049290  Evaluations Remaining\n",
      "rewards= 14.025685789817752\n",
      "actions= [[1. 1.]]\n",
      "1049289  Evaluations Remaining\n",
      "rewards= 0.21596096840854306\n",
      "Timestep 1\tScore: 14.24\tmin: 14.24\tmax: 14.24actions= [[0.89292948 0.05337829]]\n",
      "1049288  Evaluations Remaining\n",
      "rewards= 0.050840919885714264\n",
      "Timestep 2\tScore: 14.29\tmin: 14.29\tmax: 14.29actions= [[1. 1.]]\n",
      "1049287  Evaluations Remaining\n",
      "rewards= 66.07750168075515\n",
      "Timestep 3\tScore: 80.37\tmin: 80.37\tmax: 80.37actions= [[1. 1.]]\n",
      "1049286  Evaluations Remaining\n",
      "rewards= 0.26988188671350954\n",
      "Episode 142\tScore: 80.64\tAverage Score: 63.46\n",
      "actions= [[1. 1.]]\n",
      "1049285  Evaluations Remaining\n",
      "rewards= 14.282806107992657\n",
      "actions= [[1. 1.]]\n",
      "1049284  Evaluations Remaining\n",
      "rewards= -0.03760925348959665\n",
      "Timestep 1\tScore: 14.25\tmin: 14.25\tmax: 14.25actions= [[1. 0.]]\n",
      "1049283  Evaluations Remaining\n",
      "rewards= -0.13600671214653515\n",
      "Timestep 2\tScore: 14.11\tmin: 14.11\tmax: 14.11actions= [[1. 1.]]\n",
      "1049282  Evaluations Remaining\n",
      "rewards= 97.97270643106782\n",
      "Timestep 3\tScore: 112.08\tmin: 112.08\tmax: 112.08actions= [[1. 1.]]\n",
      "1049281  Evaluations Remaining\n",
      "rewards= -0.016267202472686204\n",
      "Episode 143\tScore: 112.07\tAverage Score: 82.8407\n",
      "actions= [[1. 1.]]\n",
      "1049280  Evaluations Remaining\n",
      "rewards= 14.47428003714407\n",
      "actions= [[1. 0.]]\n",
      "1049279  Evaluations Remaining\n",
      "rewards= 0.22802110798619202\n",
      "Timestep 1\tScore: 14.70\tmin: 14.70\tmax: 14.70actions= [[1. 1.]]\n",
      "1049278  Evaluations Remaining\n",
      "rewards= 99.53563399749778\n",
      "Timestep 2\tScore: 114.24\tmin: 114.24\tmax: 114.24actions= [[1. 1.]]\n",
      "1049277  Evaluations Remaining\n",
      "rewards= 0.24914624014931253\n",
      "Timestep 3\tScore: 114.49\tmin: 114.49\tmax: 114.49actions= [[1. 1.]]\n",
      "1049276  Evaluations Remaining\n",
      "rewards= 0.13807302535575028\n",
      "Episode 144\tScore: 114.63\tAverage Score: 67.6263\n",
      "actions= [[1. 1.]]\n",
      "1049275  Evaluations Remaining\n",
      "rewards= 15.266048842092097\n",
      "actions= [[1. 1.]]\n",
      "1049274  Evaluations Remaining\n",
      "rewards= 0.1305438666570966\n",
      "Timestep 1\tScore: 15.40\tmin: 15.40\tmax: 15.40actions= [[1. 1.]]\n",
      "1049273  Evaluations Remaining\n",
      "rewards= 0.15689864975408652\n",
      "Timestep 2\tScore: 15.55\tmin: 15.55\tmax: 15.55actions= [[1. 1.]]\n",
      "1049272  Evaluations Remaining\n",
      "rewards= -0.04215560322603418\n",
      "Timestep 3\tScore: 15.51\tmin: 15.51\tmax: 15.51actions= [[1. 1.]]\n",
      "1049271  Evaluations Remaining\n",
      "rewards= 0.11702875529157808\n",
      "Episode 145\tScore: 15.63\tAverage Score: 67.86\n",
      "actions= [[1. 1.]]\n",
      "1049270  Evaluations Remaining\n",
      "rewards= 14.065795105418717\n",
      "actions= [[1. 1.]]\n",
      "1049269  Evaluations Remaining\n",
      "rewards= -0.0880005889476645\n",
      "Timestep 1\tScore: 13.98\tmin: 13.98\tmax: 13.98actions= [[1. 1.]]\n",
      "1049268  Evaluations Remaining\n",
      "rewards= 0.0655044270299272\n",
      "Timestep 2\tScore: 14.04\tmin: 14.04\tmax: 14.04actions= [[1. 1.]]\n",
      "1049267  Evaluations Remaining\n",
      "rewards= 0.2002544126053536\n",
      "Timestep 3\tScore: 14.24\tmin: 14.24\tmax: 14.24actions= [[1. 1.]]\n",
      "1049266  Evaluations Remaining\n",
      "rewards= -0.21254392573372938\n",
      "Episode 146\tScore: 14.03\tAverage Score: 67.40\n",
      "actions= [[1. 1.]]\n",
      "1049265  Evaluations Remaining\n",
      "rewards= 15.035593930251927\n",
      "actions= [[1. 1.]]\n",
      "1049264  Evaluations Remaining\n",
      "rewards= 0.04810684403297172\n",
      "Timestep 1\tScore: 15.08\tmin: 15.08\tmax: 15.08actions= [[1. 1.]]\n",
      "1049263  Evaluations Remaining\n",
      "rewards= 0.1333537748521052\n",
      "Timestep 2\tScore: 15.22\tmin: 15.22\tmax: 15.22actions= [[1. 1.]]\n",
      "1049262  Evaluations Remaining\n",
      "rewards= 0.24676677239085443\n",
      "Timestep 3\tScore: 15.46\tmin: 15.46\tmax: 15.46actions= [[1. 1.]]\n",
      "1049261  Evaluations Remaining\n",
      "rewards= 0.18411792804717342\n",
      "Episode 147\tScore: 15.65\tAverage Score: 54.40\n",
      "actions= [[1. 1.]]\n",
      "1049260  Evaluations Remaining\n",
      "rewards= 14.272006723682189\n",
      "actions= [[1. 1.]]\n",
      "1049259  Evaluations Remaining\n",
      "rewards= 0.012004641058329213\n",
      "Timestep 1\tScore: 14.28\tmin: 14.28\tmax: 14.28actions= [[1. 1.]]\n",
      "1049258  Evaluations Remaining\n",
      "rewards= 0.2288740527990285\n",
      "Timestep 2\tScore: 14.51\tmin: 14.51\tmax: 14.51actions= [[1. 1.]]\n",
      "1049257  Evaluations Remaining\n",
      "rewards= 0.16111396092550745\n",
      "Timestep 3\tScore: 14.67\tmin: 14.67\tmax: 14.67actions= [[1. 1.]]\n",
      "1049256  Evaluations Remaining\n",
      "rewards= -0.19913985629082287\n",
      "Episode 148\tScore: 14.47\tAverage Score: 34.88\n",
      "actions= [[1. 1.]]\n",
      "1049255  Evaluations Remaining\n",
      "rewards= 14.574427983452837\n",
      "actions= [[1. 1.]]\n",
      "1049254  Evaluations Remaining\n",
      "rewards= -0.17660881110601379\n",
      "Timestep 1\tScore: 14.40\tmin: 14.40\tmax: 14.40actions= [[1. 1.]]\n",
      "1049253  Evaluations Remaining\n",
      "rewards= -0.10755073898647538\n",
      "Timestep 2\tScore: 14.29\tmin: 14.29\tmax: 14.29actions= [[0.         0.07863182]]\n",
      "1049252  Evaluations Remaining\n",
      "rewards= 0.23044634392700747\n",
      "Timestep 3\tScore: 14.52\tmin: 14.52\tmax: 14.52actions= [[1. 1.]]\n",
      "1049251  Evaluations Remaining\n",
      "rewards= -11.910572385572806\n",
      "Episode 149\tScore: 2.61\tAverage Score: 12.48\n",
      "actions= [[1. 1.]]\n",
      "1049250  Evaluations Remaining\n",
      "rewards= 16.18060312363709\n",
      "actions= [[1. 1.]]\n",
      "1049249  Evaluations Remaining\n",
      "rewards= -0.09672944639538228\n",
      "Timestep 1\tScore: 16.08\tmin: 16.08\tmax: 16.08actions= [[1. 1.]]\n",
      "1049248  Evaluations Remaining\n",
      "rewards= -0.2367110232313947\n",
      "Timestep 2\tScore: 15.85\tmin: 15.85\tmax: 15.85actions= [[0.21898951 0.        ]]\n",
      "1049247  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= -0.1889201934794542\n",
      "Timestep 3\tScore: 15.66\tmin: 15.66\tmax: 15.66actions= [[1.         0.38993573]]\n",
      "1049246  Evaluations Remaining\n",
      "rewards= 14.812283042422013\n",
      "Episode 150\tScore: 30.47\tAverage Score: 15.45\n",
      "actions= [[1. 1.]]\n",
      "1049245  Evaluations Remaining\n",
      "rewards= 14.225754572894433\n",
      "actions= [[1. 1.]]\n",
      "1049244  Evaluations Remaining\n",
      "rewards= -0.015152984003736325\n",
      "Timestep 1\tScore: 14.21\tmin: 14.21\tmax: 14.21actions= [[1. 1.]]\n",
      "1049243  Evaluations Remaining\n",
      "rewards= 0.05175569010502157\n",
      "Timestep 2\tScore: 14.26\tmin: 14.26\tmax: 14.26actions= [[1. 1.]]\n",
      "1049242  Evaluations Remaining\n",
      "rewards= 0.1841795081335107\n",
      "Timestep 3\tScore: 14.45\tmin: 14.45\tmax: 14.45actions= [[0.33998144 0.890986  ]]\n",
      "1049241  Evaluations Remaining\n",
      "rewards= 0.02340860342905282\n",
      "Episode 151\tScore: 14.47\tAverage Score: 15.53\n",
      "actions= [[1.         0.96786692]]\n",
      "1049240  Evaluations Remaining\n",
      "rewards= 5.461672006673719\n",
      "actions= [[1. 1.]]\n",
      "1049239  Evaluations Remaining\n",
      "rewards= 3.078838469996365\n",
      "Timestep 1\tScore: 8.54\tmin: 8.54\tmax: 8.54actions= [[1. 1.]]\n",
      "1049238  Evaluations Remaining\n",
      "rewards= -0.06024114571721917\n",
      "Timestep 2\tScore: 8.48\tmin: 8.48\tmax: 8.48actions= [[0. 0.]]\n",
      "1049237  Evaluations Remaining\n",
      "rewards= -0.21630911217463877\n",
      "Timestep 3\tScore: 8.26\tmin: 8.26\tmax: 8.26actions= [[1. 1.]]\n",
      "1049236  Evaluations Remaining\n",
      "rewards= 11.719788327619106\n",
      "Episode 152\tScore: 19.98\tAverage Score: 16.40\n",
      "actions= [[1. 1.]]\n",
      "1049235  Evaluations Remaining\n",
      "rewards= 16.109391003732558\n",
      "actions= [[1. 1.]]\n",
      "1049234  Evaluations Remaining\n",
      "rewards= -0.15561423702110444\n",
      "Timestep 1\tScore: 15.95\tmin: 15.95\tmax: 15.95actions= [[1. 1.]]\n",
      "1049233  Evaluations Remaining\n",
      "rewards= 0.18190594144468708\n",
      "Timestep 2\tScore: 16.14\tmin: 16.14\tmax: 16.14actions= [[0.34126238 0.55387843]]\n",
      "1049232  Evaluations Remaining\n",
      "rewards= -0.1869989836256134\n",
      "Timestep 3\tScore: 15.95\tmin: 15.95\tmax: 15.95actions= [[1. 1.]]\n",
      "1049231  Evaluations Remaining\n",
      "rewards= 3.3344616673872776\n",
      "Episode 153\tScore: 19.28\tAverage Score: 17.36\n",
      "actions= [[0. 0.]]\n",
      "1049230  Evaluations Remaining\n",
      "rewards= 2.8746074664180203\n",
      "actions= [[1. 1.]]\n",
      "1049229  Evaluations Remaining\n",
      "rewards= 12.363482890386905\n",
      "Timestep 1\tScore: 15.24\tmin: 15.24\tmax: 15.24actions= [[1. 1.]]\n",
      "1049228  Evaluations Remaining\n",
      "rewards= 0.1131463685120977\n",
      "Timestep 2\tScore: 15.35\tmin: 15.35\tmax: 15.35actions= [[1. 1.]]\n",
      "1049227  Evaluations Remaining\n",
      "rewards= 0.23619748420297482\n",
      "Timestep 3\tScore: 15.59\tmin: 15.59\tmax: 15.59actions= [[1. 1.]]\n",
      "1049226  Evaluations Remaining\n",
      "rewards= -0.044143706009248884\n",
      "Episode 154\tScore: 15.54\tAverage Score: 19.95\n",
      "actions= [[1. 1.]]\n",
      "1049225  Evaluations Remaining\n",
      "rewards= 14.83918008507062\n",
      "actions= [[1. 1.]]\n",
      "1049224  Evaluations Remaining\n",
      "rewards= 0.06105821569944547\n",
      "Timestep 1\tScore: 14.90\tmin: 14.90\tmax: 14.90actions= [[1. 1.]]\n",
      "1049223  Evaluations Remaining\n",
      "rewards= -0.1904343112586977\n",
      "Timestep 2\tScore: 14.71\tmin: 14.71\tmax: 14.71actions= [[1. 1.]]\n",
      "1049222  Evaluations Remaining\n",
      "rewards= -0.02374286520593394\n",
      "Timestep 3\tScore: 14.69\tmin: 14.69\tmax: 14.69actions= [[1. 1.]]\n",
      "1049221  Evaluations Remaining\n",
      "rewards= -0.05126833199774472\n",
      "Episode 155\tScore: 14.63\tAverage Score: 16.78\n",
      "actions= [[1. 1.]]\n",
      "1049220  Evaluations Remaining\n",
      "rewards= 14.16964106456659\n",
      "actions= [[1. 1.]]\n",
      "1049219  Evaluations Remaining\n",
      "rewards= -0.024029394081205968\n",
      "Timestep 1\tScore: 14.15\tmin: 14.15\tmax: 14.15actions= [[1. 1.]]\n",
      "1049218  Evaluations Remaining\n",
      "rewards= -0.19026652145914147\n",
      "Timestep 2\tScore: 13.96\tmin: 13.96\tmax: 13.96actions= [[1. 1.]]\n",
      "1049217  Evaluations Remaining\n",
      "rewards= 0.019720012173046086\n",
      "Timestep 3\tScore: 13.98\tmin: 13.98\tmax: 13.98actions= [[1. 1.]]\n",
      "1049216  Evaluations Remaining\n",
      "rewards= -0.05886366704772339\n",
      "Episode 156\tScore: 13.92\tAverage Score: 16.67\n",
      "actions= [[1. 1.]]\n",
      "1049215  Evaluations Remaining\n",
      "rewards= 15.122129434415085\n",
      "actions= [[1. 1.]]\n",
      "1049214  Evaluations Remaining\n",
      "rewards= -0.15455350527369216\n",
      "Timestep 1\tScore: 14.97\tmin: 14.97\tmax: 14.97actions= [[1. 1.]]\n",
      "1049213  Evaluations Remaining\n",
      "rewards= -0.09193090584778618\n",
      "Timestep 2\tScore: 14.88\tmin: 14.88\tmax: 14.88actions= [[1. 1.]]\n",
      "1049212  Evaluations Remaining\n",
      "rewards= 0.19097645076706193\n",
      "Timestep 3\tScore: 15.07\tmin: 15.07\tmax: 15.07actions= [[1. 0.]]\n",
      "1049211  Evaluations Remaining\n",
      "rewards= 0.18557041462841184\n",
      "Episode 157\tScore: 15.25\tAverage Score: 15.73\n",
      "actions= [[1. 1.]]\n",
      "1049210  Evaluations Remaining\n",
      "rewards= 16.38013543986366\n",
      "actions= [[0.26733145 1.        ]]\n",
      "1049209  Evaluations Remaining\n",
      "rewards= -0.24112044013428413\n",
      "Timestep 1\tScore: 16.14\tmin: 16.14\tmax: 16.14actions= [[1. 1.]]\n",
      "1049208  Evaluations Remaining\n",
      "rewards= 55.4226817821253\n",
      "Timestep 2\tScore: 71.56\tmin: 71.56\tmax: 71.56actions= [[1. 1.]]\n",
      "1049207  Evaluations Remaining\n",
      "rewards= -0.11499846483496734\n",
      "Timestep 3\tScore: 71.45\tmin: 71.45\tmax: 71.45actions= [[1. 1.]]\n",
      "1049206  Evaluations Remaining\n",
      "rewards= 0.06385397958028438\n",
      "Episode 158\tScore: 71.51\tAverage Score: 26.17\n",
      "actions= [[0. 0.]]\n",
      "1049205  Evaluations Remaining\n",
      "rewards= 2.7969741981481384\n",
      "actions= [[1. 1.]]\n",
      "1049204  Evaluations Remaining\n",
      "rewards= 10.818770729978693\n",
      "Timestep 1\tScore: 13.62\tmin: 13.62\tmax: 13.62actions= [[1. 1.]]\n",
      "1049203  Evaluations Remaining\n",
      "rewards= 0.24005203614998383\n",
      "Timestep 2\tScore: 13.86\tmin: 13.86\tmax: 13.86actions= [[1. 1.]]\n",
      "1049202  Evaluations Remaining\n",
      "rewards= -0.060816067872927704\n",
      "Timestep 3\tScore: 13.79\tmin: 13.79\tmax: 13.79actions= [[1. 1.]]\n",
      "1049201  Evaluations Remaining\n",
      "rewards= 0.17886655609688962\n",
      "Episode 159\tScore: 13.97\tAverage Score: 25.86\n",
      "actions= [[1. 1.]]\n",
      "1049200  Evaluations Remaining\n",
      "rewards= 16.106636030029946\n",
      "actions= [[1. 1.]]\n",
      "1049199  Evaluations Remaining\n",
      "rewards= -0.18909051666506782\n",
      "Timestep 1\tScore: 15.92\tmin: 15.92\tmax: 15.92actions= [[1. 1.]]\n",
      "1049198  Evaluations Remaining\n",
      "rewards= -0.15480974581379137\n",
      "Timestep 2\tScore: 15.76\tmin: 15.76\tmax: 15.76actions= [[1. 1.]]\n",
      "1049197  Evaluations Remaining\n",
      "rewards= 0.23767467199175574\n",
      "Timestep 3\tScore: 16.00\tmin: 16.00\tmax: 16.00actions= [[1. 1.]]\n",
      "1049196  Evaluations Remaining\n",
      "rewards= 0.109150362822664\n",
      "Episode 160\tScore: 16.11\tAverage Score: 26.15\n",
      "actions= [[1. 1.]]\n",
      "1049195  Evaluations Remaining\n",
      "rewards= 16.393952222233946\n",
      "actions= [[1. 1.]]\n",
      "1049194  Evaluations Remaining\n",
      "rewards= -0.2484834460641201\n",
      "Timestep 1\tScore: 16.15\tmin: 16.15\tmax: 16.15actions= [[1. 1.]]\n",
      "1049193  Evaluations Remaining\n",
      "rewards= 0.20562178076961501\n",
      "Timestep 2\tScore: 16.35\tmin: 16.35\tmax: 16.35actions= [[0.48487313 1.        ]]\n",
      "1049192  Evaluations Remaining\n",
      "rewards= -0.12738257944793485\n",
      "Timestep 3\tScore: 16.22\tmin: 16.22\tmax: 16.22actions= [[0.92865865 0.        ]]\n",
      "1049191  Evaluations Remaining\n",
      "rewards= 21.904137898747994\n",
      "Episode 161\tScore: 38.13\tAverage Score: 30.99\n",
      "actions= [[1. 1.]]\n",
      "1049190  Evaluations Remaining\n",
      "rewards= 16.265811289831568\n",
      "actions= [[1. 1.]]\n",
      "1049189  Evaluations Remaining\n",
      "rewards= 0.15007097033842998\n",
      "Timestep 1\tScore: 16.42\tmin: 16.42\tmax: 16.42actions= [[1. 1.]]\n",
      "1049188  Evaluations Remaining\n",
      "rewards= -0.1125660671837232\n",
      "Timestep 2\tScore: 16.30\tmin: 16.30\tmax: 16.30actions= [[1. 1.]]\n",
      "1049187  Evaluations Remaining\n",
      "rewards= -0.2489862308091202\n",
      "Timestep 3\tScore: 16.05\tmin: 16.05\tmax: 16.05actions= [[1. 1.]]\n",
      "1049186  Evaluations Remaining\n",
      "rewards= -0.13080591917968443\n",
      "Episode 162\tScore: 15.92\tAverage Score: 31.13\n",
      "actions= [[1. 1.]]\n",
      "1049185  Evaluations Remaining\n",
      "rewards= 14.123930144559411\n",
      "actions= [[1. 1.]]\n",
      "1049184  Evaluations Remaining\n",
      "rewards= 0.2168108173078407\n",
      "Timestep 1\tScore: 14.34\tmin: 14.34\tmax: 14.34actions= [[1. 1.]]\n",
      "1049183  Evaluations Remaining\n",
      "rewards= -0.2505253545412107\n",
      "Timestep 2\tScore: 14.09\tmin: 14.09\tmax: 14.09actions= [[1. 1.]]\n",
      "1049182  Evaluations Remaining\n",
      "rewards= 0.18793966956703478\n",
      "Timestep 3\tScore: 14.28\tmin: 14.28\tmax: 14.28actions= [[1. 1.]]\n",
      "1049181  Evaluations Remaining\n",
      "rewards= -0.21362435282401515\n",
      "Episode 163\tScore: 14.06\tAverage Score: 19.64\n",
      "actions= [[1. 1.]]\n",
      "1049180  Evaluations Remaining\n",
      "rewards= 14.770528161481993\n",
      "actions= [[0.19042542 0.20939398]]\n",
      "1049179  Evaluations Remaining\n",
      "rewards= 0.17572163178759226\n",
      "Timestep 1\tScore: 14.95\tmin: 14.95\tmax: 14.95actions= [[1. 1.]]\n",
      "1049178  Evaluations Remaining\n",
      "rewards= -19.653213070018772\n",
      "Timestep 2\tScore: -4.71\tmin: -4.71\tmax: -4.71actions= [[0. 0.]]\n",
      "1049177  Evaluations Remaining\n",
      "rewards= -0.15655099538139794\n",
      "Timestep 3\tScore: -4.86\tmin: -4.86\tmax: -4.86actions= [[1. 1.]]\n",
      "1049176  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 13.117324839780375\n",
      "Episode 164\tScore: 8.25\tAverage Score: 18.50\n",
      "actions= [[1. 1.]]\n",
      "1049175  Evaluations Remaining\n",
      "rewards= 15.140754696486916\n",
      "actions= [[1. 1.]]\n",
      "1049174  Evaluations Remaining\n",
      "rewards= -0.2580951127479807\n",
      "Timestep 1\tScore: 14.88\tmin: 14.88\tmax: 14.88actions= [[1. 1.]]\n",
      "1049173  Evaluations Remaining\n",
      "rewards= 0.1516127263496303\n",
      "Timestep 2\tScore: 15.03\tmin: 15.03\tmax: 15.03actions= [[1. 1.]]\n",
      "1049172  Evaluations Remaining\n",
      "rewards= -0.22915347939699204\n",
      "Timestep 3\tScore: 14.81\tmin: 14.81\tmax: 14.81actions= [[1. 1.]]\n",
      "1049171  Evaluations Remaining\n",
      "rewards= -0.06267462328021622\n",
      "Episode 165\tScore: 14.74\tAverage Score: 18.22\n",
      "actions= [[1. 1.]]\n",
      "1049170  Evaluations Remaining\n",
      "rewards= 13.819594857565477\n",
      "actions= [[1. 1.]]\n",
      "1049169  Evaluations Remaining\n",
      "rewards= 0.22123962495161287\n",
      "Timestep 1\tScore: 14.04\tmin: 14.04\tmax: 14.04actions= [[0.         0.23775779]]\n",
      "1049168  Evaluations Remaining\n",
      "rewards= -0.08627131481025652\n",
      "Timestep 2\tScore: 13.95\tmin: 13.95\tmax: 13.95actions= [[1. 1.]]\n",
      "1049167  Evaluations Remaining\n",
      "rewards= -61.09941305080861\n",
      "Timestep 3\tScore: -47.14\tmin: -47.14\tmax: -47.14actions= [[1. 1.]]\n",
      "1049166  Evaluations Remaining\n",
      "rewards= 0.18371775324210748\n",
      "Episode 166\tScore: -46.96\tAverage Score: 1.20.96\n",
      "actions= [[1. 1.]]\n",
      "1049165  Evaluations Remaining\n",
      "rewards= 15.416784506636837\n",
      "actions= [[0. 0.]]\n",
      "1049164  Evaluations Remaining\n",
      "rewards= 0.12532645057738812\n",
      "Timestep 1\tScore: 15.54\tmin: 15.54\tmax: 15.54actions= [[1. 1.]]\n",
      "1049163  Evaluations Remaining\n",
      "rewards= 10.887310338236151\n",
      "Timestep 2\tScore: 26.43\tmin: 26.43\tmax: 26.43actions= [[1. 1.]]\n",
      "1049162  Evaluations Remaining\n",
      "rewards= 0.2516272383405789\n",
      "Timestep 3\tScore: 26.68\tmin: 26.68\tmax: 26.68actions= [[0.34685774 1.        ]]\n",
      "1049161  Evaluations Remaining\n",
      "rewards= -0.09928184453823263\n",
      "Episode 167\tScore: 26.58\tAverage Score: 3.348\n",
      "actions= [[1. 1.]]\n",
      "1049160  Evaluations Remaining\n",
      "rewards= 14.322510025989258\n",
      "actions= [[1. 1.]]\n",
      "1049159  Evaluations Remaining\n",
      "rewards= -0.00419163359096375\n",
      "Timestep 1\tScore: 14.32\tmin: 14.32\tmax: 14.32actions= [[1. 1.]]\n",
      "1049158  Evaluations Remaining\n",
      "rewards= 0.21002773297515498\n",
      "Timestep 2\tScore: 14.53\tmin: 14.53\tmax: 14.53actions= [[1. 1.]]\n",
      "1049157  Evaluations Remaining\n",
      "rewards= -0.2570663999951699\n",
      "Timestep 3\tScore: 14.27\tmin: 14.27\tmax: 14.27actions= [[1. 1.]]\n",
      "1049156  Evaluations Remaining\n",
      "rewards= -0.018381571702638766\n",
      "Episode 168\tScore: 14.25\tAverage Score: 3.375\n",
      "actions= [[1. 1.]]\n",
      "1049155  Evaluations Remaining\n",
      "rewards= 15.300829298774378\n",
      "actions= [[1. 1.]]\n",
      "1049154  Evaluations Remaining\n",
      "rewards= 0.2630470198504047\n",
      "Timestep 1\tScore: 15.56\tmin: 15.56\tmax: 15.56actions= [[1. 1.]]\n",
      "1049153  Evaluations Remaining\n",
      "rewards= 0.21110688816881318\n",
      "Timestep 2\tScore: 15.77\tmin: 15.77\tmax: 15.77actions= [[1. 1.]]\n",
      "1049152  Evaluations Remaining\n",
      "rewards= -0.2698892405304907\n",
      "Timestep 3\tScore: 15.51\tmin: 15.51\tmax: 15.51actions= [[1. 1.]]\n",
      "1049151  Evaluations Remaining\n",
      "rewards= 0.16030599729479933\n",
      "Episode 169\tScore: 15.67\tAverage Score: 4.867\n",
      "actions= [[1. 1.]]\n",
      "1049150  Evaluations Remaining\n",
      "rewards= 15.792065594053678\n",
      "actions= [[1. 1.]]\n",
      "1049149  Evaluations Remaining\n",
      "rewards= -0.04720728525839846\n",
      "Timestep 1\tScore: 15.74\tmin: 15.74\tmax: 15.74actions= [[1. 1.]]\n",
      "1049148  Evaluations Remaining\n",
      "rewards= -0.1086440272724114\n",
      "Timestep 2\tScore: 15.64\tmin: 15.64\tmax: 15.64actions= [[0.32126313 0.        ]]\n",
      "1049147  Evaluations Remaining\n",
      "rewards= 0.24238497215533927\n",
      "Timestep 3\tScore: 15.88\tmin: 15.88\tmax: 15.88actions= [[1. 1.]]\n",
      "1049146  Evaluations Remaining\n",
      "rewards= 8.657412753459282\n",
      "Episode 170\tScore: 24.54\tAverage Score: 6.814\n",
      "actions= [[1. 1.]]\n",
      "1049145  Evaluations Remaining\n",
      "rewards= 15.051157306328587\n",
      "actions= [[1. 1.]]\n",
      "1049144  Evaluations Remaining\n",
      "rewards= 0.09466832972640793\n",
      "Timestep 1\tScore: 15.15\tmin: 15.15\tmax: 15.15actions= [[1. 1.]]\n",
      "1049143  Evaluations Remaining\n",
      "rewards= -0.20833785472457444\n",
      "Timestep 2\tScore: 14.94\tmin: 14.94\tmax: 14.94actions= [[1. 1.]]\n",
      "1049142  Evaluations Remaining\n",
      "rewards= -0.11406925054794392\n",
      "Timestep 3\tScore: 14.82\tmin: 14.82\tmax: 14.82actions= [[1. 1.]]\n",
      "1049141  Evaluations Remaining\n",
      "rewards= -0.1322474106502285\n",
      "Episode 171\tScore: 14.69\tAverage Score: 19.15\n",
      "actions= [[1. 1.]]\n",
      "1049140  Evaluations Remaining\n",
      "rewards= 14.120458071739028\n",
      "actions= [[1. 1.]]\n",
      "1049139  Evaluations Remaining\n",
      "rewards= -0.2422552720647464\n",
      "Timestep 1\tScore: 13.88\tmin: 13.88\tmax: 13.88actions= [[1. 1.]]\n",
      "1049138  Evaluations Remaining\n",
      "rewards= 0.03251389077719935\n",
      "Timestep 2\tScore: 13.91\tmin: 13.91\tmax: 13.91actions= [[1. 1.]]\n",
      "1049137  Evaluations Remaining\n",
      "rewards= 0.007967370290067777\n",
      "Timestep 3\tScore: 13.92\tmin: 13.92\tmax: 13.92actions= [[1. 1.]]\n",
      "1049136  Evaluations Remaining\n",
      "rewards= -0.08403239776379401\n",
      "Episode 172\tScore: 13.83\tAverage Score: 16.60\n",
      "actions= [[1. 1.]]\n",
      "1049135  Evaluations Remaining\n",
      "rewards= 15.296500313495228\n",
      "actions= [[1. 1.]]\n",
      "1049134  Evaluations Remaining\n",
      "rewards= 0.017767995056876096\n",
      "Timestep 1\tScore: 15.31\tmin: 15.31\tmax: 15.31actions= [[1. 1.]]\n",
      "1049133  Evaluations Remaining\n",
      "rewards= 0.18321096140565096\n",
      "Timestep 2\tScore: 15.50\tmin: 15.50\tmax: 15.50actions= [[0.         0.33982343]]\n",
      "1049132  Evaluations Remaining\n",
      "rewards= -0.14651973848693967\n",
      "Timestep 3\tScore: 15.35\tmin: 15.35\tmax: 15.35actions= [[0.08238553 0.        ]]\n",
      "1049131  Evaluations Remaining\n",
      "rewards= -0.16850387641618436\n",
      "Episode 173\tScore: 15.18\tAverage Score: 16.78\n",
      "actions= [[1. 1.]]\n",
      "1049130  Evaluations Remaining\n",
      "rewards= 14.499851214561486\n",
      "actions= [[1. 1.]]\n",
      "1049129  Evaluations Remaining\n",
      "rewards= 0.24805719312376695\n",
      "Timestep 1\tScore: 14.75\tmin: 14.75\tmax: 14.75actions= [[1. 1.]]\n",
      "1049128  Evaluations Remaining\n",
      "rewards= 0.15532690706387609\n",
      "Timestep 2\tScore: 14.90\tmin: 14.90\tmax: 14.90actions= [[1. 1.]]\n",
      "1049127  Evaluations Remaining\n",
      "rewards= -0.21670721651273261\n",
      "Timestep 3\tScore: 14.69\tmin: 14.69\tmax: 14.69actions= [[1. 1.]]\n",
      "1049126  Evaluations Remaining\n",
      "rewards= 0.07984238116974973\n",
      "Episode 174\tScore: 14.77\tAverage Score: 16.60\n",
      "actions= [[1. 1.]]\n",
      "1049125  Evaluations Remaining\n",
      "rewards= 14.221531170023654\n",
      "actions= [[1. 1.]]\n",
      "1049124  Evaluations Remaining\n",
      "rewards= -0.06386692482389611\n",
      "Timestep 1\tScore: 14.16\tmin: 14.16\tmax: 14.16actions= [[1. 1.]]\n",
      "1049123  Evaluations Remaining\n",
      "rewards= 0.23277768422803247\n",
      "Timestep 2\tScore: 14.39\tmin: 14.39\tmax: 14.39actions= [[1. 1.]]\n",
      "1049122  Evaluations Remaining\n",
      "rewards= 0.180472163905272\n",
      "Timestep 3\tScore: 14.57\tmin: 14.57\tmax: 14.57actions= [[1. 1.]]\n",
      "1049121  Evaluations Remaining\n",
      "rewards= -0.04039072067367844\n",
      "Episode 175\tScore: 14.53\tAverage Score: 14.60\n",
      "actions= [[1. 1.]]\n",
      "1049120  Evaluations Remaining\n",
      "rewards= 15.303943664422702\n",
      "actions= [[1. 1.]]\n",
      "1049119  Evaluations Remaining\n",
      "rewards= 0.0606181413483835\n",
      "Timestep 1\tScore: 15.36\tmin: 15.36\tmax: 15.36actions= [[1. 1.]]\n",
      "1049118  Evaluations Remaining\n",
      "rewards= 0.2715509355521615\n",
      "Timestep 2\tScore: 15.64\tmin: 15.64\tmax: 15.64actions= [[1. 1.]]\n",
      "1049117  Evaluations Remaining\n",
      "rewards= 0.2717473121516911\n",
      "Timestep 3\tScore: 15.91\tmin: 15.91\tmax: 15.91actions= [[1. 1.]]\n",
      "1049116  Evaluations Remaining\n",
      "rewards= -0.012631293681767186\n",
      "Episode 176\tScore: 15.90\tAverage Score: 14.84\n",
      "actions= [[1. 1.]]\n",
      "1049115  Evaluations Remaining\n",
      "rewards= 13.984503803942694\n",
      "actions= [[1. 1.]]\n",
      "1049114  Evaluations Remaining\n",
      "rewards= -0.22021330539145767\n",
      "Timestep 1\tScore: 13.76\tmin: 13.76\tmax: 13.76actions= [[1. 1.]]\n",
      "1049113  Evaluations Remaining\n",
      "rewards= -0.0068830610710057805\n",
      "Timestep 2\tScore: 13.76\tmin: 13.76\tmax: 13.76actions= [[1. 1.]]\n",
      "1049112  Evaluations Remaining\n",
      "rewards= -0.12607098064432343\n",
      "Timestep 3\tScore: 13.63\tmin: 13.63\tmax: 13.63actions= [[1. 1.]]\n",
      "1049111  Evaluations Remaining\n",
      "rewards= -0.2641495362471784\n",
      "Episode 177\tScore: 13.37\tAverage Score: 14.75\n",
      "actions= [[1. 1.]]\n",
      "1049110  Evaluations Remaining\n",
      "rewards= 14.485090408967167\n",
      "actions= [[1. 1.]]\n",
      "1049109  Evaluations Remaining\n",
      "rewards= 0.2461875723297351\n",
      "Timestep 1\tScore: 14.73\tmin: 14.73\tmax: 14.73actions= [[1. 1.]]\n",
      "1049108  Evaluations Remaining\n",
      "rewards= 0.005945915380447975\n",
      "Timestep 2\tScore: 14.74\tmin: 14.74\tmax: 14.74actions= [[1. 1.]]\n",
      "1049107  Evaluations Remaining\n",
      "rewards= -0.22296980743946415\n",
      "Timestep 3\tScore: 14.51\tmin: 14.51\tmax: 14.51actions= [[1. 1.]]\n",
      "1049106  Evaluations Remaining\n",
      "rewards= 0.23597796291564466\n",
      "Episode 178\tScore: 14.75\tAverage Score: 14.66\n",
      "actions= [[1. 1.]]\n",
      "1049105  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 16.044058922888112\n",
      "actions= [[1. 1.]]\n",
      "1049104  Evaluations Remaining\n",
      "rewards= 0.07364590193971132\n",
      "Timestep 1\tScore: 16.12\tmin: 16.12\tmax: 16.12actions= [[1. 1.]]\n",
      "1049103  Evaluations Remaining\n",
      "rewards= -0.07818946857717624\n",
      "Timestep 2\tScore: 16.04\tmin: 16.04\tmax: 16.04actions= [[1. 1.]]\n",
      "1049102  Evaluations Remaining\n",
      "rewards= 0.029332188104775447\n",
      "Timestep 3\tScore: 16.07\tmin: 16.07\tmax: 16.07actions= [[1. 1.]]\n",
      "1049101  Evaluations Remaining\n",
      "rewards= -0.045290830102001856\n",
      "Episode 179\tScore: 16.02\tAverage Score: 14.91\n",
      "actions= [[1. 1.]]\n",
      "1049100  Evaluations Remaining\n",
      "rewards= 16.05864122094755\n",
      "actions= [[1. 1.]]\n",
      "1049099  Evaluations Remaining\n",
      "rewards= 0.17755412941856719\n",
      "Timestep 1\tScore: 16.24\tmin: 16.24\tmax: 16.24actions= [[1. 1.]]\n",
      "1049098  Evaluations Remaining\n",
      "rewards= 0.16720745972280415\n",
      "Timestep 2\tScore: 16.40\tmin: 16.40\tmax: 16.40actions= [[1. 1.]]\n",
      "1049097  Evaluations Remaining\n",
      "rewards= -0.2162525375036468\n",
      "Timestep 3\tScore: 16.19\tmin: 16.19\tmax: 16.19actions= [[1. 1.]]\n",
      "1049096  Evaluations Remaining\n",
      "rewards= 0.23324795796787345\n",
      "Episode 180\tScore: 16.42\tAverage Score: 15.29\n",
      "actions= [[1. 1.]]\n",
      "1049095  Evaluations Remaining\n",
      "rewards= 14.340236962063265\n",
      "actions= [[1. 1.]]\n",
      "1049094  Evaluations Remaining\n",
      "rewards= -0.06403067045057753\n",
      "Timestep 1\tScore: 14.28\tmin: 14.28\tmax: 14.28actions= [[1. 1.]]\n",
      "1049093  Evaluations Remaining\n",
      "rewards= -0.1365552983020888\n",
      "Timestep 2\tScore: 14.14\tmin: 14.14\tmax: 14.14actions= [[1. 1.]]\n",
      "1049092  Evaluations Remaining\n",
      "rewards= 0.10355256794999823\n",
      "Timestep 3\tScore: 14.24\tmin: 14.24\tmax: 14.24actions= [[1. 1.]]\n",
      "1049091  Evaluations Remaining\n",
      "rewards= 0.11941008919648688\n",
      "Episode 181\tScore: 14.36\tAverage Score: 14.98\n",
      "actions= [[1. 1.]]\n",
      "1049090  Evaluations Remaining\n",
      "rewards= 15.10779288369481\n",
      "actions= [[1. 1.]]\n",
      "1049089  Evaluations Remaining\n",
      "rewards= 0.03733583240459515\n",
      "Timestep 1\tScore: 15.15\tmin: 15.15\tmax: 15.15actions= [[1. 1.]]\n",
      "1049088  Evaluations Remaining\n",
      "rewards= 0.08168097675262631\n",
      "Timestep 2\tScore: 15.23\tmin: 15.23\tmax: 15.23actions= [[1. 1.]]\n",
      "1049087  Evaluations Remaining\n",
      "rewards= -0.12411887034932834\n",
      "Timestep 3\tScore: 15.10\tmin: 15.10\tmax: 15.10actions= [[1. 1.]]\n",
      "1049086  Evaluations Remaining\n",
      "rewards= 0.24035615808195443\n",
      "Episode 182\tScore: 15.34\tAverage Score: 15.38\n",
      "actions= [[1. 1.]]\n",
      "1049085  Evaluations Remaining\n",
      "rewards= 14.725789919921835\n",
      "actions= [[1. 1.]]\n",
      "1049084  Evaluations Remaining\n",
      "rewards= -0.269974609433433\n",
      "Timestep 1\tScore: 14.46\tmin: 14.46\tmax: 14.46actions= [[1. 1.]]\n",
      "1049083  Evaluations Remaining\n",
      "rewards= 0.1915149246242991\n",
      "Timestep 2\tScore: 14.65\tmin: 14.65\tmax: 14.65actions= [[1. 1.]]\n",
      "1049082  Evaluations Remaining\n",
      "rewards= 0.10659874988895712\n",
      "Timestep 3\tScore: 14.75\tmin: 14.75\tmax: 14.75actions= [[1. 1.]]\n",
      "1049081  Evaluations Remaining\n",
      "rewards= -0.03159765723662877\n",
      "Episode 183\tScore: 14.72\tAverage Score: 15.37\n",
      "actions= [[1. 1.]]\n",
      "1049080  Evaluations Remaining\n",
      "rewards= 15.419125614154034\n",
      "actions= [[1. 1.]]\n",
      "1049079  Evaluations Remaining\n",
      "rewards= -0.1032197884038002\n",
      "Timestep 1\tScore: 15.32\tmin: 15.32\tmax: 15.32actions= [[1. 1.]]\n",
      "1049078  Evaluations Remaining\n",
      "rewards= 0.269460361273278\n",
      "Timestep 2\tScore: 15.59\tmin: 15.59\tmax: 15.59actions= [[1. 1.]]\n",
      "1049077  Evaluations Remaining\n",
      "rewards= -0.07596381589793522\n",
      "Timestep 3\tScore: 15.51\tmin: 15.51\tmax: 15.51actions= [[1. 1.]]\n",
      "1049076  Evaluations Remaining\n",
      "rewards= 0.0681590234566869\n",
      "Episode 184\tScore: 15.58\tAverage Score: 15.29\n",
      "actions= [[1. 1.]]\n",
      "1049075  Evaluations Remaining\n",
      "rewards= 14.479606699102716\n",
      "actions= [[1. 1.]]\n",
      "1049074  Evaluations Remaining\n",
      "rewards= 0.00204441990690718\n",
      "Timestep 1\tScore: 14.48\tmin: 14.48\tmax: 14.48actions= [[1. 1.]]\n",
      "1049073  Evaluations Remaining\n",
      "rewards= 0.1084368484327336\n",
      "Timestep 2\tScore: 14.59\tmin: 14.59\tmax: 14.59actions= [[1. 1.]]\n",
      "1049072  Evaluations Remaining\n",
      "rewards= -0.14829904404412364\n",
      "Timestep 3\tScore: 14.44\tmin: 14.44\tmax: 14.44actions= [[1. 1.]]\n",
      "1049071  Evaluations Remaining\n",
      "rewards= -0.20376011482713707\n",
      "Episode 185\tScore: 14.24\tAverage Score: 14.85\n",
      "actions= [[1. 1.]]\n",
      "1049070  Evaluations Remaining\n",
      "rewards= 15.518449416139765\n",
      "actions= [[1. 1.]]\n",
      "1049069  Evaluations Remaining\n",
      "rewards= -0.19861398577917688\n",
      "Timestep 1\tScore: 15.32\tmin: 15.32\tmax: 15.32actions= [[1. 1.]]\n",
      "1049068  Evaluations Remaining\n",
      "rewards= -0.26844582778565407\n",
      "Timestep 2\tScore: 15.05\tmin: 15.05\tmax: 15.05actions= [[1. 1.]]\n",
      "1049067  Evaluations Remaining\n",
      "rewards= 0.22986864163461762\n",
      "Timestep 3\tScore: 15.28\tmin: 15.28\tmax: 15.28actions= [[1. 1.]]\n",
      "1049066  Evaluations Remaining\n",
      "rewards= 0.09403103167045401\n",
      "Episode 186\tScore: 15.38\tAverage Score: 15.05\n",
      "actions= [[1. 1.]]\n",
      "1049065  Evaluations Remaining\n",
      "rewards= 15.779514405173996\n",
      "actions= [[1. 1.]]\n",
      "1049064  Evaluations Remaining\n",
      "rewards= 0.14115184411326176\n",
      "Timestep 1\tScore: 15.92\tmin: 15.92\tmax: 15.92actions= [[1. 1.]]\n",
      "1049063  Evaluations Remaining\n",
      "rewards= 0.18865536187554444\n",
      "Timestep 2\tScore: 16.11\tmin: 16.11\tmax: 16.11actions= [[1. 1.]]\n",
      "1049062  Evaluations Remaining\n",
      "rewards= 0.20216814656571325\n",
      "Timestep 3\tScore: 16.31\tmin: 16.31\tmax: 16.31actions= [[1. 1.]]\n",
      "1049061  Evaluations Remaining\n",
      "rewards= 0.23994672831403951\n",
      "Episode 187\tScore: 16.55\tAverage Score: 15.29\n",
      "actions= [[1. 1.]]\n",
      "1049060  Evaluations Remaining\n",
      "rewards= 13.764612817244675\n",
      "actions= [[1. 1.]]\n",
      "1049059  Evaluations Remaining\n",
      "rewards= -0.05298479756646346\n",
      "Timestep 1\tScore: 13.71\tmin: 13.71\tmax: 13.71actions= [[0. 0.]]\n",
      "1049058  Evaluations Remaining\n",
      "rewards= -0.04193178924325469\n",
      "Timestep 2\tScore: 13.67\tmin: 13.67\tmax: 13.67actions= [[1. 1.]]\n",
      "1049057  Evaluations Remaining\n",
      "rewards= 11.34487743642043\n",
      "Timestep 3\tScore: 25.01\tmin: 25.01\tmax: 25.01actions= [[1. 1.]]\n",
      "1049056  Evaluations Remaining\n",
      "rewards= -0.10756668567752747\n",
      "Episode 188\tScore: 24.91\tAverage Score: 17.33\n",
      "actions= [[1. 1.]]\n",
      "1049055  Evaluations Remaining\n",
      "rewards= 15.926007927964582\n",
      "actions= [[1. 0.]]\n",
      "1049054  Evaluations Remaining\n",
      "rewards= -0.07320515665112826\n",
      "Timestep 1\tScore: 15.85\tmin: 15.85\tmax: 15.85actions= [[0. 0.]]\n",
      "1049053  Evaluations Remaining\n",
      "rewards= 0.1973139312376695\n",
      "Timestep 2\tScore: 16.05\tmin: 16.05\tmax: 16.05actions= [[1. 1.]]\n",
      "1049052  Evaluations Remaining\n",
      "rewards= 12.806938458098546\n",
      "Timestep 3\tScore: 28.86\tmin: 28.86\tmax: 28.86actions= [[1. 1.]]\n",
      "1049051  Evaluations Remaining\n",
      "rewards= -0.19725696445729746\n",
      "Episode 189\tScore: 28.66\tAverage Score: 19.95\n",
      "actions= [[1. 1.]]\n",
      "1049050  Evaluations Remaining\n",
      "rewards= 13.852888678246513\n",
      "actions= [[1. 1.]]\n",
      "1049049  Evaluations Remaining\n",
      "rewards= 0.2678645877231669\n",
      "Timestep 1\tScore: 14.12\tmin: 14.12\tmax: 14.12actions= [[1. 1.]]\n",
      "1049048  Evaluations Remaining\n",
      "rewards= 0.24678614547964983\n",
      "Timestep 2\tScore: 14.37\tmin: 14.37\tmax: 14.37actions= [[1. 1.]]\n",
      "1049047  Evaluations Remaining\n",
      "rewards= 0.07940086911024924\n",
      "Timestep 3\tScore: 14.45\tmin: 14.45\tmax: 14.45actions= [[1. 1.]]\n",
      "1049046  Evaluations Remaining\n",
      "rewards= -0.0021921383830831864\n",
      "Episode 190\tScore: 14.44\tAverage Score: 19.99\n",
      "actions= [[1. 1.]]\n",
      "1049045  Evaluations Remaining\n",
      "rewards= 15.029357419019194\n",
      "actions= [[1. 1.]]\n",
      "1049044  Evaluations Remaining\n",
      "rewards= -0.14962014625840503\n",
      "Timestep 1\tScore: 14.88\tmin: 14.88\tmax: 14.88actions= [[1. 1.]]\n",
      "1049043  Evaluations Remaining\n",
      "rewards= -0.20811923984448288\n",
      "Timestep 2\tScore: 14.67\tmin: 14.67\tmax: 14.67actions= [[1. 1.]]\n",
      "1049042  Evaluations Remaining\n",
      "rewards= -0.017882413647347217\n",
      "Timestep 3\tScore: 14.65\tmin: 14.65\tmax: 14.65actions= [[1. 1.]]\n",
      "1049041  Evaluations Remaining\n",
      "rewards= 0.05640712918263269\n",
      "Episode 191\tScore: 14.71\tAverage Score: 19.85\n",
      "actions= [[1. 1.]]\n",
      "1049040  Evaluations Remaining\n",
      "rewards= 15.143911948114734\n",
      "actions= [[1. 1.]]\n",
      "1049039  Evaluations Remaining\n",
      "rewards= -0.24744919223250283\n",
      "Timestep 1\tScore: 14.90\tmin: 14.90\tmax: 14.90actions= [[1. 1.]]\n",
      "1049038  Evaluations Remaining\n",
      "rewards= 0.2048285720216776\n",
      "Timestep 2\tScore: 15.10\tmin: 15.10\tmax: 15.10actions= [[1. 1.]]\n",
      "1049037  Evaluations Remaining\n",
      "rewards= -0.0459755340945418\n",
      "Timestep 3\tScore: 15.06\tmin: 15.06\tmax: 15.06actions= [[1. 1.]]\n",
      "1049036  Evaluations Remaining\n",
      "rewards= -0.23746304886685454\n",
      "Episode 192\tScore: 14.82\tAverage Score: 19.51\n",
      "actions= [[1. 1.]]\n",
      "1049035  Evaluations Remaining\n",
      "rewards= 15.493940360199792\n",
      "actions= [[0. 1.]]\n",
      "1049034  Evaluations Remaining\n",
      "rewards= -0.04527140920580308\n",
      "Timestep 1\tScore: 15.45\tmin: 15.45\tmax: 15.45actions= [[1. 1.]]\n",
      "1049033  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 88.24390670980512\n",
      "Timestep 2\tScore: 103.69\tmin: 103.69\tmax: 103.69actions= [[1. 1.]]\n",
      "1049032  Evaluations Remaining\n",
      "rewards= 0.26882819307213657\n",
      "Timestep 3\tScore: 103.96\tmin: 103.96\tmax: 103.96actions= [[1. 1.]]\n",
      "1049031  Evaluations Remaining\n",
      "rewards= 0.2667113298257351\n",
      "Episode 193\tScore: 104.23\tAverage Score: 35.3723\n",
      "actions= [[1. 1.]]\n",
      "1049030  Evaluations Remaining\n",
      "rewards= 15.786939255551252\n",
      "actions= [[1. 1.]]\n",
      "1049029  Evaluations Remaining\n",
      "rewards= -0.07067627749609917\n",
      "Timestep 1\tScore: 15.72\tmin: 15.72\tmax: 15.72actions= [[1. 1.]]\n",
      "1049028  Evaluations Remaining\n",
      "rewards= -0.208585207478317\n",
      "Timestep 2\tScore: 15.51\tmin: 15.51\tmax: 15.51actions= [[1. 1.]]\n",
      "1049027  Evaluations Remaining\n",
      "rewards= -0.1747612553246487\n",
      "Timestep 3\tScore: 15.33\tmin: 15.33\tmax: 15.33actions= [[1. 1.]]\n",
      "1049026  Evaluations Remaining\n",
      "rewards= -0.1574112424590588\n",
      "Episode 194\tScore: 15.18\tAverage Score: 32.68\n",
      "actions= [[1. 1.]]\n",
      "1049025  Evaluations Remaining\n",
      "rewards= 13.59047845380127\n",
      "actions= [[1. 1.]]\n",
      "1049024  Evaluations Remaining\n",
      "rewards= 0.002242835647767727\n",
      "Timestep 1\tScore: 13.59\tmin: 13.59\tmax: 13.59actions= [[1. 1.]]\n",
      "1049023  Evaluations Remaining\n",
      "rewards= 0.15959528076455065\n",
      "Timestep 2\tScore: 13.75\tmin: 13.75\tmax: 13.75actions= [[1. 1.]]\n",
      "1049022  Evaluations Remaining\n",
      "rewards= 0.25370679303805765\n",
      "Timestep 3\tScore: 14.01\tmin: 14.01\tmax: 14.01actions= [[1. 1.]]\n",
      "1049021  Evaluations Remaining\n",
      "rewards= 0.20262697896329884\n",
      "Episode 195\tScore: 14.21\tAverage Score: 32.63\n",
      "actions= [[1. 1.]]\n",
      "1049020  Evaluations Remaining\n",
      "rewards= 13.78405003664021\n",
      "actions= [[1. 1.]]\n",
      "1049019  Evaluations Remaining\n",
      "rewards= -0.06612030024646876\n",
      "Timestep 1\tScore: 13.72\tmin: 13.72\tmax: 13.72actions= [[1. 1.]]\n",
      "1049018  Evaluations Remaining\n",
      "rewards= -0.23819268658324733\n",
      "Timestep 2\tScore: 13.48\tmin: 13.48\tmax: 13.48actions= [[1. 1.]]\n",
      "1049017  Evaluations Remaining\n",
      "rewards= -0.2703631479444204\n",
      "Timestep 3\tScore: 13.21\tmin: 13.21\tmax: 13.21actions= [[1. 1.]]\n",
      "1049016  Evaluations Remaining\n",
      "rewards= -0.1247054882754588\n",
      "Episode 196\tScore: 13.08\tAverage Score: 32.30\n",
      "actions= [[1. 1.]]\n",
      "1049015  Evaluations Remaining\n",
      "rewards= 16.266169315749085\n",
      "actions= [[0. 0.]]\n",
      "1049014  Evaluations Remaining\n",
      "rewards= 0.19478725477696868\n",
      "Timestep 1\tScore: 16.46\tmin: 16.46\tmax: 16.46actions= [[1. 1.]]\n",
      "1049013  Evaluations Remaining\n",
      "rewards= 11.045712757395588\n",
      "Timestep 2\tScore: 27.51\tmin: 27.51\tmax: 27.51actions= [[1. 1.]]\n",
      "1049012  Evaluations Remaining\n",
      "rewards= 0.2229611846832089\n",
      "Timestep 3\tScore: 27.73\tmin: 27.73\tmax: 27.73actions= [[1. 1.]]\n",
      "1049011  Evaluations Remaining\n",
      "rewards= -0.007699804056612525\n",
      "Episode 197\tScore: 27.72\tAverage Score: 34.88\n",
      "actions= [[1. 1.]]\n",
      "1049010  Evaluations Remaining\n",
      "rewards= 14.619942464920102\n",
      "actions= [[1. 1.]]\n",
      "1049009  Evaluations Remaining\n",
      "rewards= -0.2139477563123675\n",
      "Timestep 1\tScore: 14.41\tmin: 14.41\tmax: 14.41actions= [[1. 1.]]\n",
      "1049008  Evaluations Remaining\n",
      "rewards= -0.18884184802054316\n",
      "Timestep 2\tScore: 14.22\tmin: 14.22\tmax: 14.22actions= [[1. 1.]]\n",
      "1049007  Evaluations Remaining\n",
      "rewards= 0.260713976977224\n",
      "Timestep 3\tScore: 14.48\tmin: 14.48\tmax: 14.48actions= [[0.20540661 0.2856799 ]]\n",
      "1049006  Evaluations Remaining\n",
      "rewards= -0.22373417920445293\n",
      "Episode 198\tScore: 14.25\tAverage Score: 16.89\n",
      "actions= [[1. 1.]]\n",
      "1049005  Evaluations Remaining\n",
      "rewards= 16.17919869007584\n",
      "actions= [[1. 1.]]\n",
      "1049004  Evaluations Remaining\n",
      "rewards= -0.21616743170473152\n",
      "Timestep 1\tScore: 15.96\tmin: 15.96\tmax: 15.96actions= [[1. 1.]]\n",
      "1049003  Evaluations Remaining\n",
      "rewards= 0.09601116666878529\n",
      "Timestep 2\tScore: 16.06\tmin: 16.06\tmax: 16.06actions= [[1. 1.]]\n",
      "1049002  Evaluations Remaining\n",
      "rewards= 0.21838397881560567\n",
      "Timestep 3\tScore: 16.28\tmin: 16.28\tmax: 16.28actions= [[1. 1.]]\n",
      "1049001  Evaluations Remaining\n",
      "rewards= 0.13765877793930903\n",
      "Episode 199\tScore: 16.42\tAverage Score: 17.14\n",
      "actions= [[1. 1.]]\n",
      "1049000  Evaluations Remaining\n",
      "rewards= 13.53859412002512\n",
      "actions= [[1. 1.]]\n",
      "1048999  Evaluations Remaining\n",
      "rewards= -0.1660960629376631\n",
      "Timestep 1\tScore: 13.37\tmin: 13.37\tmax: 13.37actions= [[1. 1.]]\n",
      "1048998  Evaluations Remaining\n",
      "rewards= -0.2518431376816488\n",
      "Timestep 2\tScore: 13.12\tmin: 13.12\tmax: 13.12actions= [[1. 1.]]\n",
      "1048997  Evaluations Remaining\n",
      "rewards= 0.15269499834820666\n",
      "Timestep 3\tScore: 13.27\tmin: 13.27\tmax: 13.27actions= [[1. 1.]]\n",
      "1048996  Evaluations Remaining\n",
      "rewards= 0.050595430521877205\n",
      "Episode 200\tScore: 13.32\tAverage Score: 16.96\n",
      "Episode 200\tAverage Score: 16.96\n",
      "actions= [[1. 1.]]\n",
      "1048995  Evaluations Remaining\n",
      "rewards= 14.749016710356303\n",
      "actions= [[1. 1.]]\n",
      "1048994  Evaluations Remaining\n",
      "rewards= 0.2161380579408112\n",
      "Timestep 1\tScore: 14.97\tmin: 14.97\tmax: 14.97actions= [[1. 1.]]\n",
      "1048993  Evaluations Remaining\n",
      "rewards= 0.1735752209238033\n",
      "Timestep 2\tScore: 15.14\tmin: 15.14\tmax: 15.14actions= [[1. 1.]]\n",
      "1048992  Evaluations Remaining\n",
      "rewards= 0.06179116463345924\n",
      "Timestep 3\tScore: 15.20\tmin: 15.20\tmax: 15.20actions= [[1. 1.]]\n",
      "1048991  Evaluations Remaining\n",
      "rewards= -0.26956195259390237\n",
      "Episode 201\tScore: 14.93\tAverage Score: 17.33\n",
      "actions= [[1. 1.]]\n",
      "1048990  Evaluations Remaining\n",
      "rewards= 15.163804056254667\n",
      "actions= [[1. 1.]]\n",
      "1048989  Evaluations Remaining\n",
      "rewards= -0.033625063741122396\n",
      "Timestep 1\tScore: 15.13\tmin: 15.13\tmax: 15.13actions= [[1. 1.]]\n",
      "1048988  Evaluations Remaining\n",
      "rewards= -0.15785911366843308\n",
      "Timestep 2\tScore: 14.97\tmin: 14.97\tmax: 14.97actions= [[1. 1.]]\n",
      "1048987  Evaluations Remaining\n",
      "rewards= -0.17930446912213727\n",
      "Timestep 3\tScore: 14.79\tmin: 14.79\tmax: 14.79actions= [[1. 1.]]\n",
      "1048986  Evaluations Remaining\n",
      "rewards= 0.0979343600018483\n",
      "Episode 202\tScore: 14.89\tAverage Score: 14.76\n",
      "actions= [[1. 1.]]\n",
      "1048985  Evaluations Remaining\n",
      "rewards= 14.10277485635608\n",
      "actions= [[1. 1.]]\n",
      "1048984  Evaluations Remaining\n",
      "rewards= -0.06922074214869367\n",
      "Timestep 1\tScore: 14.03\tmin: 14.03\tmax: 14.03actions= [[1. 1.]]\n",
      "1048983  Evaluations Remaining\n",
      "rewards= -0.09312495336819238\n",
      "Timestep 2\tScore: 13.94\tmin: 13.94\tmax: 13.94actions= [[0. 0.]]\n",
      "1048982  Evaluations Remaining\n",
      "rewards= 0.09433744273918787\n",
      "Timestep 3\tScore: 14.03\tmin: 14.03\tmax: 14.03actions= [[1. 1.]]\n",
      "1048981  Evaluations Remaining\n",
      "rewards= 11.18109723358888\n",
      "Episode 203\tScore: 25.22\tAverage Score: 16.96\n",
      "actions= [[1. 1.]]\n",
      "1048980  Evaluations Remaining\n",
      "rewards= 15.244219610324327\n",
      "actions= [[1. 1.]]\n",
      "1048979  Evaluations Remaining\n",
      "rewards= -0.1619308389059113\n",
      "Timestep 1\tScore: 15.08\tmin: 15.08\tmax: 15.08actions= [[1. 1.]]\n",
      "1048978  Evaluations Remaining\n",
      "rewards= -0.19105495083260227\n",
      "Timestep 2\tScore: 14.89\tmin: 14.89\tmax: 14.89actions= [[0.6846464  0.58193015]]\n",
      "1048977  Evaluations Remaining\n",
      "rewards= 0.16894822877885884\n",
      "Timestep 3\tScore: 15.06\tmin: 15.06\tmax: 15.06actions= [[1. 1.]]\n",
      "1048976  Evaluations Remaining\n",
      "rewards= 45.44373996895259\n",
      "Episode 204\tScore: 60.50\tAverage Score: 25.77\n",
      "actions= [[1. 1.]]\n",
      "1048975  Evaluations Remaining\n",
      "rewards= 13.552751329649546\n",
      "actions= [[1. 1.]]\n",
      "1048974  Evaluations Remaining\n",
      "rewards= 0.25243952588224916\n",
      "Timestep 1\tScore: 13.81\tmin: 13.81\tmax: 13.81actions= [[1. 1.]]\n",
      "1048973  Evaluations Remaining\n",
      "rewards= -0.12273459378765272\n",
      "Timestep 2\tScore: 13.68\tmin: 13.68\tmax: 13.68actions= [[1. 1.]]\n",
      "1048972  Evaluations Remaining\n",
      "rewards= 0.03905927314656177\n",
      "Timestep 3\tScore: 13.72\tmin: 13.72\tmax: 13.72actions= [[1. 1.]]\n",
      "1048971  Evaluations Remaining\n",
      "rewards= -0.2577200701790767\n",
      "Episode 205\tScore: 13.46\tAverage Score: 25.80\n",
      "actions= [[1. 1.]]\n",
      "1048970  Evaluations Remaining\n",
      "rewards= 13.975709958163492\n",
      "actions= [[1. 1.]]\n",
      "1048969  Evaluations Remaining\n",
      "rewards= 0.08632896967478443\n",
      "Timestep 1\tScore: 14.06\tmin: 14.06\tmax: 14.06actions= [[1. 1.]]\n",
      "1048968  Evaluations Remaining\n",
      "rewards= 0.20120170681527672\n",
      "Timestep 2\tScore: 14.26\tmin: 14.26\tmax: 14.26actions= [[1. 1.]]\n",
      "1048967  Evaluations Remaining\n",
      "rewards= 0.16890273313009896\n",
      "Timestep 3\tScore: 14.43\tmin: 14.43\tmax: 14.43actions= [[1. 1.]]\n",
      "1048966  Evaluations Remaining\n",
      "rewards= -0.14524924123963423\n",
      "Episode 206\tScore: 14.29\tAverage Score: 25.67\n",
      "actions= [[1. 1.]]\n",
      "1048965  Evaluations Remaining\n",
      "rewards= 13.710524961618487\n",
      "actions= [[1. 1.]]\n",
      "1048964  Evaluations Remaining\n",
      "rewards= -0.045006953882333445\n",
      "Timestep 1\tScore: 13.67\tmin: 13.67\tmax: 13.67actions= [[1. 1.]]\n",
      "1048963  Evaluations Remaining\n",
      "rewards= -0.08100496028876503\n",
      "Timestep 2\tScore: 13.58\tmin: 13.58\tmax: 13.58actions= [[1. 1.]]\n",
      "1048962  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= -0.1345965310440902\n",
      "Timestep 3\tScore: 13.45\tmin: 13.45\tmax: 13.45actions= [[1. 1.]]\n",
      "1048961  Evaluations Remaining\n",
      "rewards= 0.2072067095807153\n",
      "Episode 207\tScore: 13.66\tAverage Score: 25.43\n",
      "actions= [[1. 1.]]\n",
      "1048960  Evaluations Remaining\n",
      "rewards= 13.581523373265146\n",
      "actions= [[0.         0.91446523]]\n",
      "1048959  Evaluations Remaining\n",
      "rewards= -0.0025607953085042823\n",
      "Timestep 1\tScore: 13.58\tmin: 13.58\tmax: 13.58actions= [[1. 1.]]\n",
      "1048958  Evaluations Remaining\n",
      "rewards= 38.26626848088298\n",
      "Timestep 2\tScore: 51.85\tmin: 51.85\tmax: 51.85actions= [[1. 1.]]\n",
      "1048957  Evaluations Remaining\n",
      "rewards= -0.24460758068043686\n",
      "Timestep 3\tScore: 51.60\tmin: 51.60\tmax: 51.60actions= [[1. 1.]]\n",
      "1048956  Evaluations Remaining\n",
      "rewards= -0.2363094308245537\n",
      "Episode 208\tScore: 51.36\tAverage Score: 30.66\n",
      "actions= [[1. 1.]]\n",
      "1048955  Evaluations Remaining\n",
      "rewards= 14.136508192400989\n",
      "actions= [[1. 1.]]\n",
      "1048954  Evaluations Remaining\n",
      "rewards= -0.1839562254296987\n",
      "Timestep 1\tScore: 13.95\tmin: 13.95\tmax: 13.95actions= [[1. 1.]]\n",
      "1048953  Evaluations Remaining\n",
      "rewards= -0.23280567407260522\n",
      "Timestep 2\tScore: 13.72\tmin: 13.72\tmax: 13.72actions= [[1. 1.]]\n",
      "1048952  Evaluations Remaining\n",
      "rewards= -0.1314560612094482\n",
      "Timestep 3\tScore: 13.59\tmin: 13.59\tmax: 13.59actions= [[1. 1.]]\n",
      "1048951  Evaluations Remaining\n",
      "rewards= 0.20838958254127027\n",
      "Episode 209\tScore: 13.80\tAverage Score: 21.31\n",
      "actions= [[1. 1.]]\n",
      "1048950  Evaluations Remaining\n",
      "rewards= 13.659255235488821\n",
      "actions= [[1. 1.]]\n",
      "1048949  Evaluations Remaining\n",
      "rewards= -0.26780598875518447\n",
      "Timestep 1\tScore: 13.39\tmin: 13.39\tmax: 13.39actions= [[1. 1.]]\n",
      "1048948  Evaluations Remaining\n",
      "rewards= 0.00292330320774159\n",
      "Timestep 2\tScore: 13.39\tmin: 13.39\tmax: 13.39actions= [[1. 1.]]\n",
      "1048947  Evaluations Remaining\n",
      "rewards= -0.05003359443563449\n",
      "Timestep 3\tScore: 13.34\tmin: 13.34\tmax: 13.34actions= [[0.         0.50707174]]\n",
      "1048946  Evaluations Remaining\n",
      "rewards= -0.0643703209321318\n",
      "Episode 210\tScore: 13.28\tAverage Score: 21.28\n",
      "actions= [[1. 1.]]\n",
      "1048945  Evaluations Remaining\n",
      "rewards= 15.355038994566675\n",
      "actions= [[1. 1.]]\n",
      "1048944  Evaluations Remaining\n",
      "rewards= 0.10256920794469648\n",
      "Timestep 1\tScore: 15.46\tmin: 15.46\tmax: 15.46actions= [[1. 1.]]\n",
      "1048943  Evaluations Remaining\n",
      "rewards= -0.19487955271841928\n",
      "Timestep 2\tScore: 15.26\tmin: 15.26\tmax: 15.26actions= [[1. 1.]]\n",
      "1048942  Evaluations Remaining\n",
      "rewards= -0.1895132334057963\n",
      "Timestep 3\tScore: 15.07\tmin: 15.07\tmax: 15.07actions= [[0.44523572 0.76212466]]\n",
      "1048941  Evaluations Remaining\n",
      "rewards= 0.04158425496484952\n",
      "Episode 211\tScore: 15.11\tAverage Score: 21.44\n",
      "actions= [[1. 1.]]\n",
      "1048940  Evaluations Remaining\n",
      "rewards= 15.5047644171815\n",
      "actions= [[1. 1.]]\n",
      "1048939  Evaluations Remaining\n",
      "rewards= -0.12411460727374068\n",
      "Timestep 1\tScore: 15.38\tmin: 15.38\tmax: 15.38actions= [[1. 1.]]\n",
      "1048938  Evaluations Remaining\n",
      "rewards= -0.07540158360876648\n",
      "Timestep 2\tScore: 15.31\tmin: 15.31\tmax: 15.31actions= [[1. 1.]]\n",
      "1048937  Evaluations Remaining\n",
      "rewards= 0.04123417814983599\n",
      "Timestep 3\tScore: 15.35\tmin: 15.35\tmax: 15.35actions= [[1. 1.]]\n",
      "1048936  Evaluations Remaining\n",
      "rewards= 0.25402585104865416\n",
      "Episode 212\tScore: 15.60\tAverage Score: 21.83\n",
      "actions= [[1. 1.]]\n",
      "1048935  Evaluations Remaining\n",
      "rewards= 13.987271351834481\n",
      "actions= [[1. 1.]]\n",
      "1048934  Evaluations Remaining\n",
      "rewards= 0.20150997760445355\n",
      "Timestep 1\tScore: 14.19\tmin: 14.19\tmax: 14.19actions= [[1. 1.]]\n",
      "1048933  Evaluations Remaining\n",
      "rewards= 0.1546191501001153\n",
      "Timestep 2\tScore: 14.34\tmin: 14.34\tmax: 14.34actions= [[1. 1.]]\n",
      "1048932  Evaluations Remaining\n",
      "rewards= 0.11839360008879485\n",
      "Timestep 3\tScore: 14.46\tmin: 14.46\tmax: 14.46actions= [[1. 1.]]\n",
      "1048931  Evaluations Remaining\n",
      "rewards= 0.14841786646300692\n",
      "Episode 213\tScore: 14.61\tAverage Score: 14.48\n",
      "actions= [[1. 1.]]\n",
      "1048930  Evaluations Remaining\n",
      "rewards= 13.637371596095928\n",
      "actions= [[1. 1.]]\n",
      "1048929  Evaluations Remaining\n",
      "rewards= 0.06250034257955894\n",
      "Timestep 1\tScore: 13.70\tmin: 13.70\tmax: 13.70actions= [[1. 1.]]\n",
      "1048928  Evaluations Remaining\n",
      "rewards= 0.1296083097662355\n",
      "Timestep 2\tScore: 13.83\tmin: 13.83\tmax: 13.83actions= [[1. 1.]]\n",
      "1048927  Evaluations Remaining\n",
      "rewards= -0.07656357777341904\n",
      "Timestep 3\tScore: 13.75\tmin: 13.75\tmax: 13.75actions= [[1. 1.]]\n",
      "1048926  Evaluations Remaining\n",
      "rewards= 0.23001172731975705\n",
      "Episode 214\tScore: 13.98\tAverage Score: 14.52\n",
      "actions= [[1. 1.]]\n",
      "1048925  Evaluations Remaining\n",
      "rewards= 16.379935533288915\n",
      "actions= [[1. 1.]]\n",
      "1048924  Evaluations Remaining\n",
      "rewards= -0.19786359708453283\n",
      "Timestep 1\tScore: 16.18\tmin: 16.18\tmax: 16.18actions= [[1. 1.]]\n",
      "1048923  Evaluations Remaining\n",
      "rewards= -0.2348425689617044\n",
      "Timestep 2\tScore: 15.95\tmin: 15.95\tmax: 15.95actions= [[0. 1.]]\n",
      "1048922  Evaluations Remaining\n",
      "rewards= -0.05463769350353953\n",
      "Timestep 3\tScore: 15.89\tmin: 15.89\tmax: 15.89actions= [[1. 1.]]\n",
      "1048921  Evaluations Remaining\n",
      "rewards= 99.53712551685157\n",
      "Episode 215\tScore: 115.43\tAverage Score: 34.9543\n",
      "actions= [[1. 1.]]\n",
      "1048920  Evaluations Remaining\n",
      "rewards= 14.919414295855578\n",
      "actions= [[1. 1.]]\n",
      "1048919  Evaluations Remaining\n",
      "rewards= -0.09969305042146814\n",
      "Timestep 1\tScore: 14.82\tmin: 14.82\tmax: 14.82actions= [[1. 1.]]\n",
      "1048918  Evaluations Remaining\n",
      "rewards= 0.116793718709991\n",
      "Timestep 2\tScore: 14.94\tmin: 14.94\tmax: 14.94actions= [[1. 1.]]\n",
      "1048917  Evaluations Remaining\n",
      "rewards= 0.26368723268695016\n",
      "Timestep 3\tScore: 15.20\tmin: 15.20\tmax: 15.20actions= [[1. 1.]]\n",
      "1048916  Evaluations Remaining\n",
      "rewards= -0.14046554406326228\n",
      "Episode 216\tScore: 15.06\tAverage Score: 34.94\n",
      "actions= [[1. 1.]]\n",
      "1048915  Evaluations Remaining\n",
      "rewards= 13.89801473966084\n",
      "actions= [[1. 1.]]\n",
      "1048914  Evaluations Remaining\n",
      "rewards= 0.21426264182479615\n",
      "Timestep 1\tScore: 14.11\tmin: 14.11\tmax: 14.11actions= [[1. 1.]]\n",
      "1048913  Evaluations Remaining\n",
      "rewards= 0.1633133785685903\n",
      "Timestep 2\tScore: 14.28\tmin: 14.28\tmax: 14.28actions= [[1. 1.]]\n",
      "1048912  Evaluations Remaining\n",
      "rewards= -0.10268966088667231\n",
      "Timestep 3\tScore: 14.17\tmin: 14.17\tmax: 14.17actions= [[1. 1.]]\n",
      "1048911  Evaluations Remaining\n",
      "rewards= 0.06305899682223703\n",
      "Episode 217\tScore: 14.24\tAverage Score: 34.66\n",
      "actions= [[1. 1.]]\n",
      "1048910  Evaluations Remaining\n",
      "rewards= 14.503756903024405\n",
      "actions= [[1. 1.]]\n",
      "1048909  Evaluations Remaining\n",
      "rewards= -0.1014599449655722\n",
      "Timestep 1\tScore: 14.40\tmin: 14.40\tmax: 14.40actions= [[1. 1.]]\n",
      "1048908  Evaluations Remaining\n",
      "rewards= -0.21273233193493502\n",
      "Timestep 2\tScore: 14.19\tmin: 14.19\tmax: 14.19actions= [[1. 1.]]\n",
      "1048907  Evaluations Remaining\n",
      "rewards= -0.1351956741034197\n",
      "Timestep 3\tScore: 14.05\tmin: 14.05\tmax: 14.05actions= [[1. 1.]]\n",
      "1048906  Evaluations Remaining\n",
      "rewards= -0.07615146302481124\n",
      "Episode 218\tScore: 13.98\tAverage Score: 34.54\n",
      "actions= [[1. 1.]]\n",
      "1048905  Evaluations Remaining\n",
      "rewards= 15.97137307216311\n",
      "actions= [[1. 1.]]\n",
      "1048904  Evaluations Remaining\n",
      "rewards= -0.22068721142484327\n",
      "Timestep 1\tScore: 15.75\tmin: 15.75\tmax: 15.75actions= [[1. 1.]]\n",
      "1048903  Evaluations Remaining\n",
      "rewards= -0.0457323354781205\n",
      "Timestep 2\tScore: 15.70\tmin: 15.70\tmax: 15.70actions= [[1. 1.]]\n",
      "1048902  Evaluations Remaining\n",
      "rewards= 0.10795998372463922\n",
      "Timestep 3\tScore: 15.81\tmin: 15.81\tmax: 15.81actions= [[1. 1.]]\n",
      "1048901  Evaluations Remaining\n",
      "rewards= -0.006280157354380478\n",
      "Episode 219\tScore: 15.81\tAverage Score: 34.90\n",
      "actions= [[1. 1.]]\n",
      "1048900  Evaluations Remaining\n",
      "rewards= 14.11208385136351\n",
      "actions= [[1. 1.]]\n",
      "1048899  Evaluations Remaining\n",
      "rewards= -0.11712352779847013\n",
      "Timestep 1\tScore: 13.99\tmin: 13.99\tmax: 13.99actions= [[1. 1.]]\n",
      "1048898  Evaluations Remaining\n",
      "rewards= -0.05538931180459494\n",
      "Timestep 2\tScore: 13.94\tmin: 13.94\tmax: 13.94actions= [[1. 1.]]\n",
      "1048897  Evaluations Remaining\n",
      "rewards= 0.057430364182390115\n",
      "Timestep 3\tScore: 14.00\tmin: 14.00\tmax: 14.00actions= [[1. 1.]]\n",
      "1048896  Evaluations Remaining\n",
      "rewards= 0.1880412241361511\n",
      "Episode 220\tScore: 14.19\tAverage Score: 14.65\n",
      "actions= [[1. 1.]]\n",
      "1048895  Evaluations Remaining\n",
      "rewards= 14.403396103254641\n",
      "actions= [[1. 1.]]\n",
      "1048894  Evaluations Remaining\n",
      "rewards= -0.1889363455298274\n",
      "Timestep 1\tScore: 14.21\tmin: 14.21\tmax: 14.21actions= [[1. 1.]]\n",
      "1048893  Evaluations Remaining\n",
      "rewards= -0.07375282500809144\n",
      "Timestep 2\tScore: 14.14\tmin: 14.14\tmax: 14.14actions= [[1. 1.]]\n",
      "1048892  Evaluations Remaining\n",
      "rewards= -0.16164721802636084\n",
      "Timestep 3\tScore: 13.98\tmin: 13.98\tmax: 13.98actions= [[1. 1.]]\n",
      "1048891  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 0.165927011887534\n",
      "Episode 221\tScore: 14.14\tAverage Score: 14.47\n",
      "actions= [[1. 1.]]\n",
      "1048890  Evaluations Remaining\n",
      "rewards= 13.828787895680545\n",
      "actions= [[1. 1.]]\n",
      "1048889  Evaluations Remaining\n",
      "rewards= -0.26558876395028275\n",
      "Timestep 1\tScore: 13.56\tmin: 13.56\tmax: 13.56actions= [[1. 1.]]\n",
      "1048888  Evaluations Remaining\n",
      "rewards= 0.25022258461684244\n",
      "Timestep 2\tScore: 13.81\tmin: 13.81\tmax: 13.81actions= [[0. 0.]]\n",
      "1048887  Evaluations Remaining\n",
      "rewards= -0.16730851299060223\n",
      "Timestep 3\tScore: 13.65\tmin: 13.65\tmax: 13.65actions= [[1. 1.]]\n",
      "1048886  Evaluations Remaining\n",
      "rewards= 10.822943511701522\n",
      "Episode 222\tScore: 24.47\tAverage Score: 16.52\n",
      "actions= [[1. 1.]]\n",
      "1048885  Evaluations Remaining\n",
      "rewards= 13.594149212726354\n",
      "actions= [[0.41179377 0.84800296]]\n",
      "1048884  Evaluations Remaining\n",
      "rewards= 0.010855968677063732\n",
      "Timestep 1\tScore: 13.61\tmin: 13.61\tmax: 13.61actions= [[1. 1.]]\n",
      "1048883  Evaluations Remaining\n",
      "rewards= 64.50784786325396\n",
      "Timestep 2\tScore: 78.11\tmin: 78.11\tmax: 78.11actions= [[1. 1.]]\n",
      "1048882  Evaluations Remaining\n",
      "rewards= -0.20043754269797853\n",
      "Timestep 3\tScore: 77.91\tmin: 77.91\tmax: 77.91actions= [[1. 1.]]\n",
      "1048881  Evaluations Remaining\n",
      "rewards= -0.054232938487813076\n",
      "Episode 223\tScore: 77.86\tAverage Score: 29.29\n",
      "actions= [[1. 1.]]\n",
      "1048880  Evaluations Remaining\n",
      "rewards= 15.754061381508711\n",
      "actions= [[1. 1.]]\n",
      "1048879  Evaluations Remaining\n",
      "rewards= -0.23751531793543457\n",
      "Timestep 1\tScore: 15.52\tmin: 15.52\tmax: 15.52actions= [[1. 1.]]\n",
      "1048878  Evaluations Remaining\n",
      "rewards= 0.06122062117586591\n",
      "Timestep 2\tScore: 15.58\tmin: 15.58\tmax: 15.58actions= [[1. 1.]]\n",
      "1048877  Evaluations Remaining\n",
      "rewards= -0.2291962826197982\n",
      "Timestep 3\tScore: 15.35\tmin: 15.35\tmax: 15.35actions= [[1. 1.]]\n",
      "1048876  Evaluations Remaining\n",
      "rewards= 0.11114674706514416\n",
      "Episode 224\tScore: 15.46\tAverage Score: 29.22\n",
      "actions= [[1. 1.]]\n",
      "1048875  Evaluations Remaining\n",
      "rewards= 13.702101309362682\n",
      "actions= [[1. 1.]]\n",
      "1048874  Evaluations Remaining\n",
      "rewards= -0.2468046141370599\n",
      "Timestep 1\tScore: 13.46\tmin: 13.46\tmax: 13.46actions= [[1. 1.]]\n",
      "1048873  Evaluations Remaining\n",
      "rewards= -0.1880521403054196\n",
      "Timestep 2\tScore: 13.27\tmin: 13.27\tmax: 13.27actions= [[1. 1.]]\n",
      "1048872  Evaluations Remaining\n",
      "rewards= -0.19608860564795494\n",
      "Timestep 3\tScore: 13.07\tmin: 13.07\tmax: 13.07actions= [[1. 1.]]\n",
      "1048871  Evaluations Remaining\n",
      "rewards= 0.010652868026948425\n",
      "Episode 225\tScore: 13.08\tAverage Score: 29.00\n",
      "actions= [[1. 1.]]\n",
      "1048870  Evaluations Remaining\n",
      "rewards= 15.801458346845616\n",
      "actions= [[1. 1.]]\n",
      "1048869  Evaluations Remaining\n",
      "rewards= -0.19794160464681543\n",
      "Timestep 1\tScore: 15.60\tmin: 15.60\tmax: 15.60actions= [[1. 1.]]\n",
      "1048868  Evaluations Remaining\n",
      "rewards= -0.18013334515946378\n",
      "Timestep 2\tScore: 15.42\tmin: 15.42\tmax: 15.42actions= [[1. 1.]]\n",
      "1048867  Evaluations Remaining\n",
      "rewards= -0.22029966211187668\n",
      "Timestep 3\tScore: 15.20\tmin: 15.20\tmax: 15.20actions= [[1. 1.]]\n",
      "1048866  Evaluations Remaining\n",
      "rewards= -0.2556941903447605\n",
      "Episode 226\tScore: 14.95\tAverage Score: 29.16\n",
      "actions= [[1. 1.]]\n",
      "1048865  Evaluations Remaining\n",
      "rewards= 15.989802834137455\n",
      "actions= [[1. 1.]]\n",
      "1048864  Evaluations Remaining\n",
      "rewards= 0.25498786738862744\n",
      "Timestep 1\tScore: 16.24\tmin: 16.24\tmax: 16.24actions= [[1. 1.]]\n",
      "1048863  Evaluations Remaining\n",
      "rewards= -0.08957032790478614\n",
      "Timestep 2\tScore: 16.16\tmin: 16.16\tmax: 16.16actions= [[1. 0.]]\n",
      "1048862  Evaluations Remaining\n",
      "rewards= -0.07394197985406059\n",
      "Timestep 3\tScore: 16.08\tmin: 16.08\tmax: 16.08actions= [[1. 1.]]\n",
      "1048861  Evaluations Remaining\n",
      "rewards= 96.4498658440623\n",
      "Episode 227\tScore: 112.53\tAverage Score: 46.7853\n",
      "actions= [[1. 1.]]\n",
      "1048860  Evaluations Remaining\n",
      "rewards= 14.584267149506672\n",
      "actions= [[1. 1.]]\n",
      "1048859  Evaluations Remaining\n",
      "rewards= -0.26837003829853323\n",
      "Timestep 1\tScore: 14.32\tmin: 14.32\tmax: 14.32actions= [[1. 1.]]\n",
      "1048858  Evaluations Remaining\n",
      "rewards= 0.07339405271846955\n",
      "Timestep 2\tScore: 14.39\tmin: 14.39\tmax: 14.39actions= [[1. 1.]]\n",
      "1048857  Evaluations Remaining\n",
      "rewards= 0.11244040147978174\n",
      "Timestep 3\tScore: 14.50\tmin: 14.50\tmax: 14.50actions= [[1. 1.]]\n",
      "1048856  Evaluations Remaining\n",
      "rewards= 0.17351301224881333\n",
      "Episode 228\tScore: 14.68\tAverage Score: 34.14\n",
      "actions= [[1. 1.]]\n",
      "1048855  Evaluations Remaining\n",
      "rewards= 15.005194427042024\n",
      "actions= [[1. 1.]]\n",
      "1048854  Evaluations Remaining\n",
      "rewards= 0.08381510435350847\n",
      "Timestep 1\tScore: 15.09\tmin: 15.09\tmax: 15.09actions= [[1. 1.]]\n",
      "1048853  Evaluations Remaining\n",
      "rewards= 0.1942779367976204\n",
      "Timestep 2\tScore: 15.28\tmin: 15.28\tmax: 15.28actions= [[1. 1.]]\n",
      "1048852  Evaluations Remaining\n",
      "rewards= 0.06304245505768202\n",
      "Timestep 3\tScore: 15.35\tmin: 15.35\tmax: 15.35actions= [[1. 1.]]\n",
      "1048851  Evaluations Remaining\n",
      "rewards= -0.2695489761691636\n",
      "Episode 229\tScore: 15.08\tAverage Score: 34.06\n",
      "actions= [[1. 1.]]\n",
      "1048850  Evaluations Remaining\n",
      "rewards= 14.24785035272321\n",
      "actions= [[1. 1.]]\n",
      "1048849  Evaluations Remaining\n",
      "rewards= 0.25405891818798576\n",
      "Timestep 1\tScore: 14.50\tmin: 14.50\tmax: 14.50actions= [[1. 1.]]\n",
      "1048848  Evaluations Remaining\n",
      "rewards= -0.14976852508698446\n",
      "Timestep 2\tScore: 14.35\tmin: 14.35\tmax: 14.35actions= [[1. 1.]]\n",
      "1048847  Evaluations Remaining\n",
      "rewards= -0.23540663559758146\n",
      "Timestep 3\tScore: 14.12\tmin: 14.12\tmax: 14.12actions= [[1. 1.]]\n",
      "1048846  Evaluations Remaining\n",
      "rewards= -0.03070381993900506\n",
      "Episode 230\tScore: 14.09\tAverage Score: 34.26\n",
      "actions= [[1. 1.]]\n",
      "1048845  Evaluations Remaining\n",
      "rewards= 16.08212930246209\n",
      "actions= [[0.         0.26101061]]\n",
      "1048844  Evaluations Remaining\n",
      "rewards= 0.255090917594488\n",
      "Timestep 1\tScore: 16.34\tmin: 16.34\tmax: 16.34actions= [[1. 1.]]\n",
      "1048843  Evaluations Remaining\n",
      "rewards= -49.453356288468605\n",
      "Timestep 2\tScore: -33.12\tmin: -33.12\tmax: -33.12actions= [[1. 1.]]\n",
      "1048842  Evaluations Remaining\n",
      "rewards= 0.2525960077792426\n",
      "Timestep 3\tScore: -32.86\tmin: -32.86\tmax: -32.86actions= [[1. 1.]]\n",
      "1048841  Evaluations Remaining\n",
      "rewards= -0.12924486865130813\n",
      "Episode 231\tScore: -32.99\tAverage Score: 24.6899\n",
      "actions= [[1. 1.]]\n",
      "1048840  Evaluations Remaining\n",
      "rewards= 13.581123954202646\n",
      "actions= [[1. 1.]]\n",
      "1048839  Evaluations Remaining\n",
      "rewards= 0.23891624953069535\n",
      "Timestep 1\tScore: 13.82\tmin: 13.82\tmax: 13.82actions= [[1. 1.]]\n",
      "1048838  Evaluations Remaining\n",
      "rewards= 0.21571763417817502\n",
      "Timestep 2\tScore: 14.04\tmin: 14.04\tmax: 14.04actions= [[1. 1.]]\n",
      "1048837  Evaluations Remaining\n",
      "rewards= 0.018567044717230807\n",
      "Timestep 3\tScore: 14.05\tmin: 14.05\tmax: 14.05actions= [[1. 1.]]\n",
      "1048836  Evaluations Remaining\n",
      "rewards= 0.2034666293198022\n",
      "Episode 232\tScore: 14.26\tAverage Score: 5.026\n",
      "actions= [[1. 1.]]\n",
      "1048835  Evaluations Remaining\n",
      "rewards= 14.067039313502374\n",
      "actions= [[1. 1.]]\n",
      "1048834  Evaluations Remaining\n",
      "rewards= -0.21483210926169383\n",
      "Timestep 1\tScore: 13.85\tmin: 13.85\tmax: 13.85actions= [[1. 1.]]\n",
      "1048833  Evaluations Remaining\n",
      "rewards= -0.2343124803119654\n",
      "Timestep 2\tScore: 13.62\tmin: 13.62\tmax: 13.62actions= [[0. 0.]]\n",
      "1048832  Evaluations Remaining\n",
      "rewards= 0.19414790622187272\n",
      "Timestep 3\tScore: 13.81\tmin: 13.81\tmax: 13.81actions= [[1. 1.]]\n",
      "1048831  Evaluations Remaining\n",
      "rewards= 12.971407807268305\n",
      "Episode 233\tScore: 26.78\tAverage Score: 7.448\n",
      "actions= [[1. 1.]]\n",
      "1048830  Evaluations Remaining\n",
      "rewards= 15.179063482317583\n",
      "actions= [[1. 1.]]\n",
      "1048829  Evaluations Remaining\n",
      "rewards= 0.25400001680812645\n",
      "Timestep 1\tScore: 15.43\tmin: 15.43\tmax: 15.43actions= [[1. 1.]]\n",
      "1048828  Evaluations Remaining\n",
      "rewards= 0.10027231064481823\n",
      "Timestep 2\tScore: 15.53\tmin: 15.53\tmax: 15.53actions= [[1. 1.]]\n",
      "1048827  Evaluations Remaining\n",
      "rewards= 0.21886102788432815\n",
      "Timestep 3\tScore: 15.75\tmin: 15.75\tmax: 15.75actions= [[1. 1.]]\n",
      "1048826  Evaluations Remaining\n",
      "rewards= 0.2528328339935757\n",
      "Episode 234\tScore: 16.01\tAverage Score: 7.631\n",
      "actions= [[1. 1.]]\n",
      "1048825  Evaluations Remaining\n",
      "rewards= 14.254031542823743\n",
      "actions= [[1. 1.]]\n",
      "1048824  Evaluations Remaining\n",
      "rewards= -0.22505561275330033\n",
      "Timestep 1\tScore: 14.03\tmin: 14.03\tmax: 14.03actions= [[1. 1.]]\n",
      "1048823  Evaluations Remaining\n",
      "rewards= -0.21955009413257676\n",
      "Timestep 2\tScore: 13.81\tmin: 13.81\tmax: 13.81actions= [[1. 1.]]\n",
      "1048822  Evaluations Remaining\n",
      "rewards= 0.11180980185655276\n",
      "Timestep 3\tScore: 13.92\tmin: 13.92\tmax: 13.92actions= [[1. 1.]]\n",
      "1048821  Evaluations Remaining\n",
      "rewards= -0.16890507035714597\n",
      "Episode 235\tScore: 13.75\tAverage Score: 7.565\n",
      "actions= [[1. 1.]]\n",
      "1048820  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 15.389723442609341\n",
      "actions= [[1. 1.]]\n",
      "1048819  Evaluations Remaining\n",
      "rewards= 0.2233758465817881\n",
      "Timestep 1\tScore: 15.61\tmin: 15.61\tmax: 15.61actions= [[1. 1.]]\n",
      "1048818  Evaluations Remaining\n",
      "rewards= -0.02763426477765485\n",
      "Timestep 2\tScore: 15.59\tmin: 15.59\tmax: 15.59actions= [[1. 1.]]\n",
      "1048817  Evaluations Remaining\n",
      "rewards= 0.039004369777412506\n",
      "Timestep 3\tScore: 15.62\tmin: 15.62\tmax: 15.62actions= [[1. 1.]]\n",
      "1048816  Evaluations Remaining\n",
      "rewards= 0.26782174935011005\n",
      "Episode 236\tScore: 15.89\tAverage Score: 17.34\n",
      "actions= [[1. 1.]]\n",
      "1048815  Evaluations Remaining\n",
      "rewards= 15.609563140332327\n",
      "actions= [[1. 1.]]\n",
      "1048814  Evaluations Remaining\n",
      "rewards= -0.02782262954107395\n",
      "Timestep 1\tScore: 15.58\tmin: 15.58\tmax: 15.58actions= [[1. 1.]]\n",
      "1048813  Evaluations Remaining\n",
      "rewards= -0.05015520772803539\n",
      "Timestep 2\tScore: 15.53\tmin: 15.53\tmax: 15.53actions= [[1. 1.]]\n",
      "1048812  Evaluations Remaining\n",
      "rewards= 0.2063007551332694\n",
      "Timestep 3\tScore: 15.74\tmin: 15.74\tmax: 15.74actions= [[1. 1.]]\n",
      "1048811  Evaluations Remaining\n",
      "rewards= -0.09944001476162923\n",
      "Episode 237\tScore: 15.64\tAverage Score: 17.61\n",
      "actions= [[1. 1.]]\n",
      "1048810  Evaluations Remaining\n",
      "rewards= 14.495969641301654\n",
      "actions= [[1. 1.]]\n",
      "1048809  Evaluations Remaining\n",
      "rewards= -0.044461074761153796\n",
      "Timestep 1\tScore: 14.45\tmin: 14.45\tmax: 14.45actions= [[1. 1.]]\n",
      "1048808  Evaluations Remaining\n",
      "rewards= 0.18830022450546968\n",
      "Timestep 2\tScore: 14.64\tmin: 14.64\tmax: 14.64actions= [[0.10383701 0.        ]]\n",
      "1048807  Evaluations Remaining\n",
      "rewards= -0.22575320615342997\n",
      "Timestep 3\tScore: 14.41\tmin: 14.41\tmax: 14.41actions= [[1. 1.]]\n",
      "1048806  Evaluations Remaining\n",
      "rewards= 16.820022521482205\n",
      "Episode 238\tScore: 31.23\tAverage Score: 18.50\n",
      "actions= [[1. 1.]]\n",
      "1048805  Evaluations Remaining\n",
      "rewards= 13.57388541117557\n",
      "actions= [[1. 1.]]\n",
      "1048804  Evaluations Remaining\n",
      "rewards= -0.19510764046265727\n",
      "Timestep 1\tScore: 13.38\tmin: 13.38\tmax: 13.38actions= [[0.51940944 0.        ]]\n",
      "1048803  Evaluations Remaining\n",
      "rewards= 0.2281738143771479\n",
      "Timestep 2\tScore: 13.61\tmin: 13.61\tmax: 13.61actions= [[1. 1.]]\n",
      "1048802  Evaluations Remaining\n",
      "rewards= 25.26335662288225\n",
      "Timestep 3\tScore: 38.87\tmin: 38.87\tmax: 38.87actions= [[1. 1.]]\n",
      "1048801  Evaluations Remaining\n",
      "rewards= -0.08302353510777483\n",
      "Episode 239\tScore: 38.79\tAverage Score: 23.06\n",
      "actions= [[1. 1.]]\n",
      "1048800  Evaluations Remaining\n",
      "rewards= 13.678378850338374\n",
      "actions= [[1. 1.]]\n",
      "1048799  Evaluations Remaining\n",
      "rewards= -0.1463657378835217\n",
      "Timestep 1\tScore: 13.53\tmin: 13.53\tmax: 13.53actions= [[1. 1.]]\n",
      "1048798  Evaluations Remaining\n",
      "rewards= -0.1718496851936715\n",
      "Timestep 2\tScore: 13.36\tmin: 13.36\tmax: 13.36actions= [[1. 1.]]\n",
      "1048797  Evaluations Remaining\n",
      "rewards= 0.25550605555533634\n",
      "Timestep 3\tScore: 13.62\tmin: 13.62\tmax: 13.62actions= [[1. 1.]]\n",
      "1048796  Evaluations Remaining\n",
      "rewards= 0.01423264677342706\n",
      "Episode 240\tScore: 13.63\tAverage Score: 23.04\n",
      "actions= [[1. 1.]]\n",
      "1048795  Evaluations Remaining\n",
      "rewards= 15.989116244750868\n",
      "actions= [[1. 1.]]\n",
      "1048794  Evaluations Remaining\n",
      "rewards= 0.16850195760553976\n",
      "Timestep 1\tScore: 16.16\tmin: 16.16\tmax: 16.16actions= [[1. 1.]]\n",
      "1048793  Evaluations Remaining\n",
      "rewards= -0.22374830783612376\n",
      "Timestep 2\tScore: 15.93\tmin: 15.93\tmax: 15.93actions= [[1. 1.]]\n",
      "1048792  Evaluations Remaining\n",
      "rewards= -0.2503957200475875\n",
      "Timestep 3\tScore: 15.68\tmin: 15.68\tmax: 15.68actions= [[1. 1.]]\n",
      "1048791  Evaluations Remaining\n",
      "rewards= 0.1850582940695471\n",
      "Episode 241\tScore: 15.87\tAverage Score: 23.03\n",
      "actions= [[1. 1.]]\n",
      "1048790  Evaluations Remaining\n",
      "rewards= 14.796258446923337\n",
      "actions= [[1. 1.]]\n",
      "1048789  Evaluations Remaining\n",
      "rewards= 0.20342754729295676\n",
      "Timestep 1\tScore: 15.00\tmin: 15.00\tmax: 15.00actions= [[1. 1.]]\n",
      "1048788  Evaluations Remaining\n",
      "rewards= -0.05107115556898645\n",
      "Timestep 2\tScore: 14.95\tmin: 14.95\tmax: 14.95actions= [[1. 1.]]\n",
      "1048787  Evaluations Remaining\n",
      "rewards= -0.13579628083665174\n",
      "Timestep 3\tScore: 14.81\tmin: 14.81\tmax: 14.81actions= [[0. 0.]]\n",
      "1048786  Evaluations Remaining\n",
      "rewards= -0.1903539243259491\n",
      "Episode 242\tScore: 14.62\tAverage Score: 22.83\n",
      "actions= [[1. 1.]]\n",
      "1048785  Evaluations Remaining\n",
      "rewards= 13.827602287220879\n",
      "actions= [[1. 1.]]\n",
      "1048784  Evaluations Remaining\n",
      "rewards= -0.07437404931481639\n",
      "Timestep 1\tScore: 13.75\tmin: 13.75\tmax: 13.75actions= [[1. 1.]]\n",
      "1048783  Evaluations Remaining\n",
      "rewards= -0.0927834826562175\n",
      "Timestep 2\tScore: 13.66\tmin: 13.66\tmax: 13.66actions= [[1. 1.]]\n",
      "1048782  Evaluations Remaining\n",
      "rewards= -0.12861048732533975\n",
      "Timestep 3\tScore: 13.53\tmin: 13.53\tmax: 13.53actions= [[1. 1.]]\n",
      "1048781  Evaluations Remaining\n",
      "rewards= 0.2471223837062988\n",
      "Episode 243\tScore: 13.78\tAverage Score: 19.34\n",
      "actions= [[1. 1.]]\n",
      "1048780  Evaluations Remaining\n",
      "rewards= 14.626891370225636\n",
      "actions= [[1. 1.]]\n",
      "1048779  Evaluations Remaining\n",
      "rewards= 0.08626485886739577\n",
      "Timestep 1\tScore: 14.71\tmin: 14.71\tmax: 14.71actions= [[1. 1.]]\n",
      "1048778  Evaluations Remaining\n",
      "rewards= -0.03030443690157192\n",
      "Timestep 2\tScore: 14.68\tmin: 14.68\tmax: 14.68actions= [[1. 1.]]\n",
      "1048777  Evaluations Remaining\n",
      "rewards= -0.1492161486360133\n",
      "Timestep 3\tScore: 14.53\tmin: 14.53\tmax: 14.53actions= [[1. 1.]]\n",
      "1048776  Evaluations Remaining\n",
      "rewards= 0.05618585174602586\n",
      "Episode 244\tScore: 14.59\tAverage Score: 14.50\n",
      "actions= [[1. 1.]]\n",
      "1048775  Evaluations Remaining\n",
      "rewards= 13.821808492025541\n",
      "actions= [[1. 1.]]\n",
      "1048774  Evaluations Remaining\n",
      "rewards= -0.1049007889435063\n",
      "Timestep 1\tScore: 13.72\tmin: 13.72\tmax: 13.72actions= [[1. 1.]]\n",
      "1048773  Evaluations Remaining\n",
      "rewards= -0.24483417769304605\n",
      "Timestep 2\tScore: 13.47\tmin: 13.47\tmax: 13.47actions= [[1. 1.]]\n",
      "1048772  Evaluations Remaining\n",
      "rewards= -0.25882727325138033\n",
      "Timestep 3\tScore: 13.21\tmin: 13.21\tmax: 13.21actions= [[1. 1.]]\n",
      "1048771  Evaluations Remaining\n",
      "rewards= 0.024969058046916626\n",
      "Episode 245\tScore: 13.24\tAverage Score: 14.42\n",
      "actions= [[1. 1.]]\n",
      "1048770  Evaluations Remaining\n",
      "rewards= 16.06964660476156\n",
      "actions= [[1. 1.]]\n",
      "1048769  Evaluations Remaining\n",
      "rewards= 0.18427785142268682\n",
      "Timestep 1\tScore: 16.25\tmin: 16.25\tmax: 16.25actions= [[1. 1.]]\n",
      "1048768  Evaluations Remaining\n",
      "rewards= 0.10698283631191874\n",
      "Timestep 2\tScore: 16.36\tmin: 16.36\tmax: 16.36actions= [[1. 1.]]\n",
      "1048767  Evaluations Remaining\n",
      "rewards= -0.26087741218175786\n",
      "Timestep 3\tScore: 16.10\tmin: 16.10\tmax: 16.10actions= [[1. 1.]]\n",
      "1048766  Evaluations Remaining\n",
      "rewards= -0.09020425756937378\n",
      "Episode 246\tScore: 16.01\tAverage Score: 14.45\n",
      "actions= [[1. 1.]]\n",
      "1048765  Evaluations Remaining\n",
      "rewards= 15.984229796901639\n",
      "actions= [[1. 1.]]\n",
      "1048764  Evaluations Remaining\n",
      "rewards= -0.16892466134115391\n",
      "Timestep 1\tScore: 15.82\tmin: 15.82\tmax: 15.82actions= [[1. 1.]]\n",
      "1048763  Evaluations Remaining\n",
      "rewards= 0.03763783899130413\n",
      "Timestep 2\tScore: 15.85\tmin: 15.85\tmax: 15.85actions= [[1. 1.]]\n",
      "1048762  Evaluations Remaining\n",
      "rewards= 0.13951495090399746\n",
      "Timestep 3\tScore: 15.99\tmin: 15.99\tmax: 15.99actions= [[1. 1.]]\n",
      "1048761  Evaluations Remaining\n",
      "rewards= 0.2554708719339742\n",
      "Episode 247\tScore: 16.25\tAverage Score: 14.77\n",
      "actions= [[1. 1.]]\n",
      "1048760  Evaluations Remaining\n",
      "rewards= 14.49599260415946\n",
      "actions= [[1. 1.]]\n",
      "1048759  Evaluations Remaining\n",
      "rewards= -0.04802796967245904\n",
      "Timestep 1\tScore: 14.45\tmin: 14.45\tmax: 14.45actions= [[1. 1.]]\n",
      "1048758  Evaluations Remaining\n",
      "rewards= 0.18550057276692122\n",
      "Timestep 2\tScore: 14.63\tmin: 14.63\tmax: 14.63actions= [[1. 1.]]\n",
      "1048757  Evaluations Remaining\n",
      "rewards= -0.2691543102311944\n",
      "Timestep 3\tScore: 14.36\tmin: 14.36\tmax: 14.36actions= [[1. 1.]]\n",
      "1048756  Evaluations Remaining\n",
      "rewards= -0.05570816727044914\n",
      "Episode 248\tScore: 14.31\tAverage Score: 14.88\n",
      "actions= [[1. 1.]]\n",
      "1048755  Evaluations Remaining\n",
      "rewards= 14.737277040634636\n",
      "actions= [[1. 1.]]\n",
      "1048754  Evaluations Remaining\n",
      "rewards= -0.017412132815123993\n",
      "Timestep 1\tScore: 14.72\tmin: 14.72\tmax: 14.72actions= [[1. 1.]]\n",
      "1048753  Evaluations Remaining\n",
      "rewards= 0.257851091792507\n",
      "Timestep 2\tScore: 14.98\tmin: 14.98\tmax: 14.98actions= [[1. 1.]]\n",
      "1048752  Evaluations Remaining\n",
      "rewards= -0.22269749656268178\n",
      "Timestep 3\tScore: 14.76\tmin: 14.76\tmax: 14.76actions= [[1. 1.]]\n",
      "1048751  Evaluations Remaining\n",
      "rewards= -0.18538358240897734\n",
      "Episode 249\tScore: 14.57\tAverage Score: 14.87\n",
      "actions= [[1. 1.]]\n",
      "1048750  Evaluations Remaining\n",
      "rewards= 14.977493210525184\n",
      "actions= [[1. 1.]]\n",
      "1048749  Evaluations Remaining\n",
      "rewards= -0.24203444135475172\n",
      "Timestep 1\tScore: 14.74\tmin: 14.74\tmax: 14.74actions= [[0. 0.]]\n",
      "1048748  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 0.2673191804905497\n",
      "Timestep 2\tScore: 15.00\tmin: 15.00\tmax: 15.00actions= [[1. 1.]]\n",
      "1048747  Evaluations Remaining\n",
      "rewards= 11.565160925750327\n",
      "Timestep 3\tScore: 26.57\tmin: 26.57\tmax: 26.57actions= [[1. 1.]]\n",
      "1048746  Evaluations Remaining\n",
      "rewards= 0.26515018684079594\n",
      "Episode 250\tScore: 26.83\tAverage Score: 17.59\n",
      "actions= [[1. 1.]]\n",
      "1048745  Evaluations Remaining\n",
      "rewards= 15.928948551652198\n",
      "actions= [[1. 1.]]\n",
      "1048744  Evaluations Remaining\n",
      "rewards= 0.1050827166933459\n",
      "Timestep 1\tScore: 16.03\tmin: 16.03\tmax: 16.03actions= [[1. 1.]]\n",
      "1048743  Evaluations Remaining\n",
      "rewards= 0.0632291735675965\n",
      "Timestep 2\tScore: 16.10\tmin: 16.10\tmax: 16.10actions= [[1. 1.]]\n",
      "1048742  Evaluations Remaining\n",
      "rewards= 0.22142968309725442\n",
      "Timestep 3\tScore: 16.32\tmin: 16.32\tmax: 16.32actions= [[1. 1.]]\n",
      "1048741  Evaluations Remaining\n",
      "rewards= -0.16492294344200475\n",
      "Episode 251\tScore: 16.15\tAverage Score: 17.62\n",
      "actions= [[1. 1.]]\n",
      "1048740  Evaluations Remaining\n",
      "rewards= 15.060695801476603\n",
      "actions= [[1. 1.]]\n",
      "1048739  Evaluations Remaining\n",
      "rewards= 0.1670626429577391\n",
      "Timestep 1\tScore: 15.23\tmin: 15.23\tmax: 15.23actions= [[1. 1.]]\n",
      "1048738  Evaluations Remaining\n",
      "rewards= 0.22017957097381435\n",
      "Timestep 2\tScore: 15.45\tmin: 15.45\tmax: 15.45actions= [[0. 1.]]\n",
      "1048737  Evaluations Remaining\n",
      "rewards= -0.16211814769289967\n",
      "Timestep 3\tScore: 15.29\tmin: 15.29\tmax: 15.29actions= [[1. 1.]]\n",
      "1048736  Evaluations Remaining\n",
      "rewards= 97.15697767904076\n",
      "Episode 252\tScore: 112.44\tAverage Score: 36.8644\n",
      "actions= [[1. 1.]]\n",
      "1048735  Evaluations Remaining\n",
      "rewards= 15.647522732175032\n",
      "actions= [[1. 1.]]\n",
      "1048734  Evaluations Remaining\n",
      "rewards= -0.20758522586067052\n",
      "Timestep 1\tScore: 15.44\tmin: 15.44\tmax: 15.44actions= [[1. 1.]]\n",
      "1048733  Evaluations Remaining\n",
      "rewards= -0.07636500391208934\n",
      "Timestep 2\tScore: 15.36\tmin: 15.36\tmax: 15.36actions= [[1. 1.]]\n",
      "1048732  Evaluations Remaining\n",
      "rewards= 0.2490425346547651\n",
      "Timestep 3\tScore: 15.61\tmin: 15.61\tmax: 15.61actions= [[1. 1.]]\n",
      "1048731  Evaluations Remaining\n",
      "rewards= 0.051490993943066776\n",
      "Episode 253\tScore: 15.66\tAverage Score: 37.13\n",
      "actions= [[1. 1.]]\n",
      "1048730  Evaluations Remaining\n",
      "rewards= 15.796429624881716\n",
      "actions= [[1. 1.]]\n",
      "1048729  Evaluations Remaining\n",
      "rewards= 0.15907613987779312\n",
      "Timestep 1\tScore: 15.96\tmin: 15.96\tmax: 15.96actions= [[1. 1.]]\n",
      "1048728  Evaluations Remaining\n",
      "rewards= 0.25307706702780264\n",
      "Timestep 2\tScore: 16.21\tmin: 16.21\tmax: 16.21actions= [[0. 1.]]\n",
      "1048727  Evaluations Remaining\n",
      "rewards= -0.026925080641607924\n",
      "Timestep 3\tScore: 16.18\tmin: 16.18\tmax: 16.18actions= [[1. 1.]]\n",
      "1048726  Evaluations Remaining\n",
      "rewards= 100.25172524092054\n",
      "Episode 254\tScore: 116.43\tAverage Score: 57.5143\n",
      "actions= [[1. 1.]]\n",
      "1048725  Evaluations Remaining\n",
      "rewards= 15.185878280441152\n",
      "actions= [[1. 1.]]\n",
      "1048724  Evaluations Remaining\n",
      "rewards= 0.18015765555837282\n",
      "Timestep 1\tScore: 15.37\tmin: 15.37\tmax: 15.37actions= [[1. 1.]]\n",
      "1048723  Evaluations Remaining\n",
      "rewards= 0.19210434234075668\n",
      "Timestep 2\tScore: 15.56\tmin: 15.56\tmax: 15.56actions= [[1. 1.]]\n",
      "1048722  Evaluations Remaining\n",
      "rewards= 0.21719228488360276\n",
      "Timestep 3\tScore: 15.78\tmin: 15.78\tmax: 15.78actions= [[1. 1.]]\n",
      "1048721  Evaluations Remaining\n",
      "rewards= -0.24485742416909373\n",
      "Episode 255\tScore: 15.53\tAverage Score: 55.24\n",
      "actions= [[1. 1.]]\n",
      "1048720  Evaluations Remaining\n",
      "rewards= 13.889759702189432\n",
      "actions= [[1. 1.]]\n",
      "1048719  Evaluations Remaining\n",
      "rewards= 0.028445050646125125\n",
      "Timestep 1\tScore: 13.92\tmin: 13.92\tmax: 13.92actions= [[1. 1.]]\n",
      "1048718  Evaluations Remaining\n",
      "rewards= 0.2462842798288647\n",
      "Timestep 2\tScore: 14.16\tmin: 14.16\tmax: 14.16actions= [[1. 1.]]\n",
      "1048717  Evaluations Remaining\n",
      "rewards= -0.030418060171161\n",
      "Timestep 3\tScore: 14.13\tmin: 14.13\tmax: 14.13actions= [[1. 1.]]\n",
      "1048716  Evaluations Remaining\n",
      "rewards= -0.24291326641254773\n",
      "Episode 256\tScore: 13.89\tAverage Score: 54.79\n",
      "actions= [[1. 1.]]\n",
      "1048715  Evaluations Remaining\n",
      "rewards= 14.415056649799238\n",
      "actions= [[1. 1.]]\n",
      "1048714  Evaluations Remaining\n",
      "rewards= -0.028576240316128043\n",
      "Timestep 1\tScore: 14.39\tmin: 14.39\tmax: 14.39actions= [[1. 1.]]\n",
      "1048713  Evaluations Remaining\n",
      "rewards= 0.08567680518024456\n",
      "Timestep 2\tScore: 14.47\tmin: 14.47\tmax: 14.47actions= [[1. 1.]]\n",
      "1048712  Evaluations Remaining\n",
      "rewards= -0.13755218635045097\n",
      "Timestep 3\tScore: 14.33\tmin: 14.33\tmax: 14.33actions= [[1. 1.]]\n",
      "1048711  Evaluations Remaining\n",
      "rewards= 0.04430645263334965\n",
      "Episode 257\tScore: 14.38\tAverage Score: 35.18\n",
      "actions= [[1. 1.]]\n",
      "1048710  Evaluations Remaining\n",
      "rewards= 13.659536673994046\n",
      "actions= [[1. 1.]]\n",
      "1048709  Evaluations Remaining\n",
      "rewards= 0.2703611381869049\n",
      "Timestep 1\tScore: 13.93\tmin: 13.93\tmax: 13.93actions= [[1. 1.]]\n",
      "1048708  Evaluations Remaining\n",
      "rewards= 0.26434067310961495\n",
      "Timestep 2\tScore: 14.19\tmin: 14.19\tmax: 14.19actions= [[1. 1.]]\n",
      "1048707  Evaluations Remaining\n",
      "rewards= 0.237538412204934\n",
      "Timestep 3\tScore: 14.43\tmin: 14.43\tmax: 14.43actions= [[1. 1.]]\n",
      "1048706  Evaluations Remaining\n",
      "rewards= 0.20658179792674325\n",
      "Episode 258\tScore: 14.64\tAverage Score: 34.97\n",
      "actions= [[1. 1.]]\n",
      "1048705  Evaluations Remaining\n",
      "rewards= 15.528155850533858\n",
      "actions= [[0. 1.]]\n",
      "1048704  Evaluations Remaining\n",
      "rewards= 0.18161602354035544\n",
      "Timestep 1\tScore: 15.71\tmin: 15.71\tmax: 15.71actions= [[1. 1.]]\n",
      "1048703  Evaluations Remaining\n",
      "rewards= 93.25199629415802\n",
      "Timestep 2\tScore: 108.96\tmin: 108.96\tmax: 108.96actions= [[1. 1.]]\n",
      "1048702  Evaluations Remaining\n",
      "rewards= 0.01337607879125935\n",
      "Timestep 3\tScore: 108.98\tmin: 108.98\tmax: 108.98actions= [[1. 1.]]\n",
      "1048701  Evaluations Remaining\n",
      "rewards= 0.10932907034296369\n",
      "Episode 259\tScore: 109.08\tAverage Score: 33.5008\n",
      "actions= [[1. 1.]]\n",
      "1048700  Evaluations Remaining\n",
      "rewards= 15.784588723494675\n",
      "actions= [[1. 1.]]\n",
      "1048699  Evaluations Remaining\n",
      "rewards= -0.05946390449424355\n",
      "Timestep 1\tScore: 15.73\tmin: 15.73\tmax: 15.73actions= [[1. 1.]]\n",
      "1048698  Evaluations Remaining\n",
      "rewards= -0.219740753146628\n",
      "Timestep 2\tScore: 15.51\tmin: 15.51\tmax: 15.51actions= [[1. 1.]]\n",
      "1048697  Evaluations Remaining\n",
      "rewards= -0.25983290060601316\n",
      "Timestep 3\tScore: 15.25\tmin: 15.25\tmax: 15.25actions= [[1. 1.]]\n",
      "1048696  Evaluations Remaining\n",
      "rewards= 0.24172169055069537\n",
      "Episode 260\tScore: 15.49\tAverage Score: 33.50\n",
      "actions= [[1. 1.]]\n",
      "1048695  Evaluations Remaining\n",
      "rewards= 16.019136553750627\n",
      "actions= [[1. 1.]]\n",
      "1048694  Evaluations Remaining\n",
      "rewards= -0.07474308469103441\n",
      "Timestep 1\tScore: 15.94\tmin: 15.94\tmax: 15.94actions= [[1. 1.]]\n",
      "1048693  Evaluations Remaining\n",
      "rewards= 0.21914948460061368\n",
      "Timestep 2\tScore: 16.16\tmin: 16.16\tmax: 16.16actions= [[1. 1.]]\n",
      "1048692  Evaluations Remaining\n",
      "rewards= 0.004370594808878803\n",
      "Timestep 3\tScore: 16.17\tmin: 16.17\tmax: 16.17actions= [[1. 1.]]\n",
      "1048691  Evaluations Remaining\n",
      "rewards= 0.2155137647550518\n",
      "Episode 261\tScore: 16.38\tAverage Score: 33.99\n",
      "actions= [[1. 1.]]\n",
      "1048690  Evaluations Remaining\n",
      "rewards= 14.492769687597457\n",
      "actions= [[1. 1.]]\n",
      "1048689  Evaluations Remaining\n",
      "rewards= 0.06682574116412088\n",
      "Timestep 1\tScore: 14.56\tmin: 14.56\tmax: 14.56actions= [[1. 1.]]\n",
      "1048688  Evaluations Remaining\n",
      "rewards= -0.1467302038589775\n",
      "Timestep 2\tScore: 14.41\tmin: 14.41\tmax: 14.41actions= [[1. 1.]]\n",
      "1048687  Evaluations Remaining\n",
      "rewards= 0.08290957412846378\n",
      "Timestep 3\tScore: 14.50\tmin: 14.50\tmax: 14.50actions= [[1. 1.]]\n",
      "1048686  Evaluations Remaining\n",
      "rewards= 0.022749305933166042\n",
      "Episode 262\tScore: 14.52\tAverage Score: 34.02\n",
      "actions= [[1. 1.]]\n",
      "1048685  Evaluations Remaining\n",
      "rewards= 15.518315153219804\n",
      "actions= [[1. 1.]]\n",
      "1048684  Evaluations Remaining\n",
      "rewards= -0.1901583627378458\n",
      "Timestep 1\tScore: 15.33\tmin: 15.33\tmax: 15.33actions= [[1. 1.]]\n",
      "1048683  Evaluations Remaining\n",
      "rewards= -0.1498504990743328\n",
      "Timestep 2\tScore: 15.18\tmin: 15.18\tmax: 15.18actions= [[1. 1.]]\n",
      "1048682  Evaluations Remaining\n",
      "rewards= 0.00721269929355195\n",
      "Timestep 3\tScore: 15.19\tmin: 15.19\tmax: 15.19actions= [[1. 1.]]\n",
      "1048681  Evaluations Remaining\n",
      "rewards= 0.10624182189973652\n",
      "Episode 263\tScore: 15.29\tAverage Score: 34.15\n",
      "actions= [[1. 1.]]\n",
      "1048680  Evaluations Remaining\n",
      "rewards= 14.874350838484984\n",
      "actions= [[1. 1.]]\n",
      "1048679  Evaluations Remaining\n",
      "rewards= -0.11356184407238468\n",
      "Timestep 1\tScore: 14.76\tmin: 14.76\tmax: 14.76actions= [[1. 1.]]\n",
      "1048678  Evaluations Remaining\n",
      "rewards= 0.09729996118282225\n",
      "Timestep 2\tScore: 14.86\tmin: 14.86\tmax: 14.86actions= [[1. 1.]]\n",
      "1048677  Evaluations Remaining\n",
      "rewards= 0.19887891223922471\n",
      "Timestep 3\tScore: 15.06\tmin: 15.06\tmax: 15.06actions= [[0. 0.]]\n",
      "1048676  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= -0.10633239277014805\n",
      "Episode 264\tScore: 14.95\tAverage Score: 15.33\n",
      "actions= [[1. 1.]]\n",
      "1048675  Evaluations Remaining\n",
      "rewards= 16.208784185131215\n",
      "actions= [[1. 1.]]\n",
      "1048674  Evaluations Remaining\n",
      "rewards= -0.2622118748090574\n",
      "Timestep 1\tScore: 15.95\tmin: 15.95\tmax: 15.95actions= [[1. 1.]]\n",
      "1048673  Evaluations Remaining\n",
      "rewards= 0.04451209372619047\n",
      "Timestep 2\tScore: 15.99\tmin: 15.99\tmax: 15.99actions= [[1. 1.]]\n",
      "1048672  Evaluations Remaining\n",
      "rewards= 0.23922245678335008\n",
      "Timestep 3\tScore: 16.23\tmin: 16.23\tmax: 16.23actions= [[1. 1.]]\n",
      "1048671  Evaluations Remaining\n",
      "rewards= 0.15295046839094217\n",
      "Episode 265\tScore: 16.38\tAverage Score: 15.51\n",
      "actions= [[1. 1.]]\n",
      "1048670  Evaluations Remaining\n",
      "rewards= 14.649635067071042\n",
      "actions= [[1. 1.]]\n",
      "1048669  Evaluations Remaining\n",
      "rewards= 0.23301645864872667\n",
      "Timestep 1\tScore: 14.88\tmin: 14.88\tmax: 14.88actions= [[1. 1.]]\n",
      "1048668  Evaluations Remaining\n",
      "rewards= 0.1058084613179795\n",
      "Timestep 2\tScore: 14.99\tmin: 14.99\tmax: 14.99actions= [[1. 1.]]\n",
      "1048667  Evaluations Remaining\n",
      "rewards= 0.24152776452192537\n",
      "Timestep 3\tScore: 15.23\tmin: 15.23\tmax: 15.23actions= [[1. 1.]]\n",
      "1048666  Evaluations Remaining\n",
      "rewards= 0.05351788812703884\n",
      "Episode 266\tScore: 15.28\tAverage Score: 15.29\n",
      "actions= [[1. 1.]]\n",
      "1048665  Evaluations Remaining\n",
      "rewards= 14.404747434336807\n",
      "actions= [[1. 1.]]\n",
      "1048664  Evaluations Remaining\n",
      "rewards= -0.09975603231416796\n",
      "Timestep 1\tScore: 14.30\tmin: 14.30\tmax: 14.30actions= [[1. 1.]]\n",
      "1048663  Evaluations Remaining\n",
      "rewards= 0.13200998907057349\n",
      "Timestep 2\tScore: 14.44\tmin: 14.44\tmax: 14.44actions= [[1. 1.]]\n",
      "1048662  Evaluations Remaining\n",
      "rewards= 0.172993531962077\n",
      "Timestep 3\tScore: 14.61\tmin: 14.61\tmax: 14.61actions= [[1. 1.]]\n",
      "1048661  Evaluations Remaining\n",
      "rewards= -0.06143526327019222\n",
      "Episode 267\tScore: 14.55\tAverage Score: 15.29\n",
      "actions= [[1. 1.]]\n",
      "1048660  Evaluations Remaining\n",
      "rewards= 14.21745602595882\n",
      "actions= [[1. 1.]]\n",
      "1048659  Evaluations Remaining\n",
      "rewards= -0.15700599803792992\n",
      "Timestep 1\tScore: 14.06\tmin: 14.06\tmax: 14.06actions= [[1. 1.]]\n",
      "1048658  Evaluations Remaining\n",
      "rewards= -0.253606581710045\n",
      "Timestep 2\tScore: 13.81\tmin: 13.81\tmax: 13.81actions= [[1. 1.]]\n",
      "1048657  Evaluations Remaining\n",
      "rewards= -0.18316808514506278\n",
      "Timestep 3\tScore: 13.62\tmin: 13.62\tmax: 13.62actions= [[1. 1.]]\n",
      "1048656  Evaluations Remaining\n",
      "rewards= 0.01172247746688626\n",
      "Episode 268\tScore: 13.64\tAverage Score: 14.96\n",
      "actions= [[1. 1.]]\n",
      "1048655  Evaluations Remaining\n",
      "rewards= 14.79494452732477\n",
      "actions= [[1. 1.]]\n",
      "1048654  Evaluations Remaining\n",
      "rewards= 0.24307957634553112\n",
      "Timestep 1\tScore: 15.04\tmin: 15.04\tmax: 15.04actions= [[1. 1.]]\n",
      "1048653  Evaluations Remaining\n",
      "rewards= 0.24659451445378\n",
      "Timestep 2\tScore: 15.28\tmin: 15.28\tmax: 15.28actions= [[1. 1.]]\n",
      "1048652  Evaluations Remaining\n",
      "rewards= -0.06639228003689324\n",
      "Timestep 3\tScore: 15.22\tmin: 15.22\tmax: 15.22actions= [[1. 1.]]\n",
      "1048651  Evaluations Remaining\n",
      "rewards= 0.003664502739396891\n",
      "Episode 269\tScore: 15.22\tAverage Score: 15.01\n",
      "actions= [[1. 1.]]\n",
      "1048650  Evaluations Remaining\n",
      "rewards= 14.468861522172292\n",
      "actions= [[1. 1.]]\n",
      "1048649  Evaluations Remaining\n",
      "rewards= 0.1096507828637514\n",
      "Timestep 1\tScore: 14.58\tmin: 14.58\tmax: 14.58actions= [[1. 1.]]\n",
      "1048648  Evaluations Remaining\n",
      "rewards= -0.25742025117410305\n",
      "Timestep 2\tScore: 14.32\tmin: 14.32\tmax: 14.32actions= [[1. 1.]]\n",
      "1048647  Evaluations Remaining\n",
      "rewards= -0.10056557206267591\n",
      "Timestep 3\tScore: 14.22\tmin: 14.22\tmax: 14.22actions= [[1. 1.]]\n",
      "1048646  Evaluations Remaining\n",
      "rewards= 0.1480186339231273\n",
      "Episode 270\tScore: 14.37\tAverage Score: 14.61\n",
      "actions= [[1. 1.]]\n",
      "1048645  Evaluations Remaining\n",
      "rewards= 16.13686046854416\n",
      "actions= [[1. 1.]]\n",
      "1048644  Evaluations Remaining\n",
      "rewards= 0.14880685495231027\n",
      "Timestep 1\tScore: 16.29\tmin: 16.29\tmax: 16.29actions= [[1. 1.]]\n",
      "1048643  Evaluations Remaining\n",
      "rewards= 0.0203960221842312\n",
      "Timestep 2\tScore: 16.31\tmin: 16.31\tmax: 16.31actions= [[1. 1.]]\n",
      "1048642  Evaluations Remaining\n",
      "rewards= 0.01082121143872472\n",
      "Timestep 3\tScore: 16.32\tmin: 16.32\tmax: 16.32actions= [[1. 1.]]\n",
      "1048641  Evaluations Remaining\n",
      "rewards= -0.24636296377578226\n",
      "Episode 271\tScore: 16.07\tAverage Score: 14.77\n",
      "actions= [[1. 1.]]\n",
      "1048640  Evaluations Remaining\n",
      "rewards= 14.376232526941502\n",
      "actions= [[1. 1.]]\n",
      "1048639  Evaluations Remaining\n",
      "rewards= 0.15423896458752706\n",
      "Timestep 1\tScore: 14.53\tmin: 14.53\tmax: 14.53actions= [[1. 1.]]\n",
      "1048638  Evaluations Remaining\n",
      "rewards= -0.22298961836997266\n",
      "Timestep 2\tScore: 14.31\tmin: 14.31\tmax: 14.31actions= [[1. 1.]]\n",
      "1048637  Evaluations Remaining\n",
      "rewards= 0.062378805695601613\n",
      "Timestep 3\tScore: 14.37\tmin: 14.37\tmax: 14.37actions= [[1. 1.]]\n",
      "1048636  Evaluations Remaining\n",
      "rewards= -0.1723422360290896\n",
      "Episode 272\tScore: 14.20\tAverage Score: 14.70\n",
      "actions= [[1. 1.]]\n",
      "1048635  Evaluations Remaining\n",
      "rewards= 16.346055080598987\n",
      "actions= [[1. 1.]]\n",
      "1048634  Evaluations Remaining\n",
      "rewards= 0.11107166392099455\n",
      "Timestep 1\tScore: 16.46\tmin: 16.46\tmax: 16.46actions= [[1. 1.]]\n",
      "1048633  Evaluations Remaining\n",
      "rewards= 0.1414055016734479\n",
      "Timestep 2\tScore: 16.60\tmin: 16.60\tmax: 16.60actions= [[1. 1.]]\n",
      "1048632  Evaluations Remaining\n",
      "rewards= -0.2546977953685112\n",
      "Timestep 3\tScore: 16.34\tmin: 16.34\tmax: 16.34actions= [[1. 1.]]\n",
      "1048631  Evaluations Remaining\n",
      "rewards= 0.000597662063924087\n",
      "Episode 273\tScore: 16.34\tAverage Score: 15.24\n",
      "actions= [[1. 1.]]\n",
      "1048630  Evaluations Remaining\n",
      "rewards= 15.344085521787175\n",
      "actions= [[0. 0.]]\n",
      "1048629  Evaluations Remaining\n",
      "rewards= -0.26970327509549197\n",
      "Timestep 1\tScore: 15.07\tmin: 15.07\tmax: 15.07actions= [[1. 1.]]\n",
      "1048628  Evaluations Remaining\n",
      "rewards= 11.386571993538912\n",
      "Timestep 2\tScore: 26.46\tmin: 26.46\tmax: 26.46actions= [[1. 1.]]\n",
      "1048627  Evaluations Remaining\n",
      "rewards= -0.03245150788935369\n",
      "Timestep 3\tScore: 26.43\tmin: 26.43\tmax: 26.43actions= [[1. 1.]]\n",
      "1048626  Evaluations Remaining\n",
      "rewards= 0.10788249289526464\n",
      "Episode 274\tScore: 26.54\tAverage Score: 17.50\n",
      "actions= [[1. 1.]]\n",
      "1048625  Evaluations Remaining\n",
      "rewards= 14.729487077047805\n",
      "actions= [[1. 1.]]\n",
      "1048624  Evaluations Remaining\n",
      "rewards= -0.13317894870381153\n",
      "Timestep 1\tScore: 14.60\tmin: 14.60\tmax: 14.60actions= [[1. 1.]]\n",
      "1048623  Evaluations Remaining\n",
      "rewards= 0.039961492460313774\n",
      "Timestep 2\tScore: 14.64\tmin: 14.64\tmax: 14.64actions= [[1. 1.]]\n",
      "1048622  Evaluations Remaining\n",
      "rewards= -0.05509247022735231\n",
      "Timestep 3\tScore: 14.58\tmin: 14.58\tmax: 14.58actions= [[1. 1.]]\n",
      "1048621  Evaluations Remaining\n",
      "rewards= -0.27031980755072693\n",
      "Episode 275\tScore: 14.31\tAverage Score: 17.49\n",
      "actions= [[1. 1.]]\n",
      "1048620  Evaluations Remaining\n",
      "rewards= 16.45450973820091\n",
      "actions= [[1. 1.]]\n",
      "1048619  Evaluations Remaining\n",
      "rewards= 0.18369626930407712\n",
      "Timestep 1\tScore: 16.64\tmin: 16.64\tmax: 16.64actions= [[1. 1.]]\n",
      "1048618  Evaluations Remaining\n",
      "rewards= -0.17584578732641676\n",
      "Timestep 2\tScore: 16.46\tmin: 16.46\tmax: 16.46actions= [[1. 1.]]\n",
      "1048617  Evaluations Remaining\n",
      "rewards= -0.17838243400680875\n",
      "Timestep 3\tScore: 16.28\tmin: 16.28\tmax: 16.28actions= [[1.         0.74519152]]\n",
      "1048616  Evaluations Remaining\n",
      "rewards= -0.20511172767916852\n",
      "Episode 276\tScore: 16.08\tAverage Score: 17.49\n",
      "actions= [[1. 1.]]\n",
      "1048615  Evaluations Remaining\n",
      "rewards= 14.813538366946993\n",
      "actions= [[1. 1.]]\n",
      "1048614  Evaluations Remaining\n",
      "rewards= 0.1952043890159163\n",
      "Timestep 1\tScore: 15.01\tmin: 15.01\tmax: 15.01actions= [[1. 1.]]\n",
      "1048613  Evaluations Remaining\n",
      "rewards= -0.2690002224850647\n",
      "Timestep 2\tScore: 14.74\tmin: 14.74\tmax: 14.74actions= [[1. 1.]]\n",
      "1048612  Evaluations Remaining\n",
      "rewards= -0.09002209456291954\n",
      "Timestep 3\tScore: 14.65\tmin: 14.65\tmax: 14.65actions= [[1. 1.]]\n",
      "1048611  Evaluations Remaining\n",
      "rewards= -0.23795337232863023\n",
      "Episode 277\tScore: 14.41\tAverage Score: 17.54\n",
      "actions= [[1. 1.]]\n",
      "1048610  Evaluations Remaining\n",
      "rewards= 14.188882992222652\n",
      "actions= [[1. 1.]]\n",
      "1048609  Evaluations Remaining\n",
      "rewards= -0.04766825907123673\n",
      "Timestep 1\tScore: 14.14\tmin: 14.14\tmax: 14.14actions= [[1. 1.]]\n",
      "1048608  Evaluations Remaining\n",
      "rewards= 0.2552994311251533\n",
      "Timestep 2\tScore: 14.40\tmin: 14.40\tmax: 14.40actions= [[1. 1.]]\n",
      "1048607  Evaluations Remaining\n",
      "rewards= -0.23489116956612222\n",
      "Timestep 3\tScore: 14.16\tmin: 14.16\tmax: 14.16actions= [[1. 1.]]\n",
      "1048606  Evaluations Remaining\n",
      "rewards= -0.015828599569418955\n",
      "Episode 278\tScore: 14.15\tAverage Score: 17.10\n",
      "actions= [[1. 1.]]\n",
      "1048605  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 15.474582210055924\n",
      "actions= [[1. 1.]]\n",
      "1048604  Evaluations Remaining\n",
      "rewards= 0.02034189234631567\n",
      "Timestep 1\tScore: 15.49\tmin: 15.49\tmax: 15.49actions= [[1. 1.]]\n",
      "1048603  Evaluations Remaining\n",
      "rewards= 0.24880735630293316\n",
      "Timestep 2\tScore: 15.74\tmin: 15.74\tmax: 15.74actions= [[1. 1.]]\n",
      "1048602  Evaluations Remaining\n",
      "rewards= 0.21434972753264425\n",
      "Timestep 3\tScore: 15.96\tmin: 15.96\tmax: 15.96actions= [[1. 1.]]\n",
      "1048601  Evaluations Remaining\n",
      "rewards= -0.1290239310303063\n",
      "Episode 279\tScore: 15.83\tAverage Score: 14.96\n",
      "actions= [[1. 1.]]\n",
      "1048600  Evaluations Remaining\n",
      "rewards= 14.921048005029608\n",
      "actions= [[1. 1.]]\n",
      "1048599  Evaluations Remaining\n",
      "rewards= -0.023011583628972154\n",
      "Timestep 1\tScore: 14.90\tmin: 14.90\tmax: 14.90actions= [[1. 1.]]\n",
      "1048598  Evaluations Remaining\n",
      "rewards= -0.22710955405379174\n",
      "Timestep 2\tScore: 14.67\tmin: 14.67\tmax: 14.67actions= [[1. 1.]]\n",
      "1048597  Evaluations Remaining\n",
      "rewards= 0.14190327052861162\n",
      "Timestep 3\tScore: 14.81\tmin: 14.81\tmax: 14.81actions= [[1. 1.]]\n",
      "1048596  Evaluations Remaining\n",
      "rewards= -0.20745708081450331\n",
      "Episode 280\tScore: 14.61\tAverage Score: 15.01\n",
      "actions= [[1. 1.]]\n",
      "1048595  Evaluations Remaining\n",
      "rewards= 16.038059719765773\n",
      "actions= [[1. 1.]]\n",
      "1048594  Evaluations Remaining\n",
      "rewards= -0.25553684560235634\n",
      "Timestep 1\tScore: 15.78\tmin: 15.78\tmax: 15.78actions= [[1. 1.]]\n",
      "1048593  Evaluations Remaining\n",
      "rewards= 0.19147381930762775\n",
      "Timestep 2\tScore: 15.97\tmin: 15.97\tmax: 15.97actions= [[1. 1.]]\n",
      "1048592  Evaluations Remaining\n",
      "rewards= -0.04239692981399168\n",
      "Timestep 3\tScore: 15.93\tmin: 15.93\tmax: 15.93actions= [[1. 1.]]\n",
      "1048591  Evaluations Remaining\n",
      "rewards= 0.025709787109884807\n",
      "Episode 281\tScore: 15.96\tAverage Score: 14.99\n",
      "actions= [[1. 1.]]\n",
      "1048590  Evaluations Remaining\n",
      "rewards= 15.955354393909444\n",
      "actions= [[1. 1.]]\n",
      "1048589  Evaluations Remaining\n",
      "rewards= -0.12149727462750715\n",
      "Timestep 1\tScore: 15.83\tmin: 15.83\tmax: 15.83actions= [[1. 1.]]\n",
      "1048588  Evaluations Remaining\n",
      "rewards= 0.02932945944523846\n",
      "Timestep 2\tScore: 15.86\tmin: 15.86\tmax: 15.86actions= [[1. 1.]]\n",
      "1048587  Evaluations Remaining\n",
      "rewards= -0.08249562699654822\n",
      "Timestep 3\tScore: 15.78\tmin: 15.78\tmax: 15.78actions= [[1. 1.]]\n",
      "1048586  Evaluations Remaining\n",
      "rewards= -0.03865101482792799\n",
      "Episode 282\tScore: 15.74\tAverage Score: 15.26\n",
      "actions= [[1. 1.]]\n",
      "1048585  Evaluations Remaining\n",
      "rewards= 15.17467751977611\n",
      "actions= [[1. 1.]]\n",
      "1048584  Evaluations Remaining\n",
      "rewards= -0.12191834594610329\n",
      "Timestep 1\tScore: 15.05\tmin: 15.05\tmax: 15.05actions= [[1. 1.]]\n",
      "1048583  Evaluations Remaining\n",
      "rewards= -0.2535510456762382\n",
      "Timestep 2\tScore: 14.80\tmin: 14.80\tmax: 14.80actions= [[1. 1.]]\n",
      "1048582  Evaluations Remaining\n",
      "rewards= -0.2512036771031525\n",
      "Timestep 3\tScore: 14.55\tmin: 14.55\tmax: 14.55actions= [[1. 1.]]\n",
      "1048581  Evaluations Remaining\n",
      "rewards= 0.2097568784916124\n",
      "Episode 283\tScore: 14.76\tAverage Score: 15.38\n",
      "actions= [[1. 1.]]\n",
      "1048580  Evaluations Remaining\n",
      "rewards= 14.089706412511338\n",
      "actions= [[1. 1.]]\n",
      "1048579  Evaluations Remaining\n",
      "rewards= -0.2677665681956558\n",
      "Timestep 1\tScore: 13.82\tmin: 13.82\tmax: 13.82actions= [[1. 1.]]\n",
      "1048578  Evaluations Remaining\n",
      "rewards= -0.10839948241344466\n",
      "Timestep 2\tScore: 13.71\tmin: 13.71\tmax: 13.71actions= [[1. 1.]]\n",
      "1048577  Evaluations Remaining\n",
      "rewards= -0.1652615240556683\n",
      "Timestep 3\tScore: 13.55\tmin: 13.55\tmax: 13.55actions= [[1. 1.]]\n",
      "1048576  Evaluations Remaining\n",
      "rewards= 0.23904907939864461\n",
      "Episode 284\tScore: 13.79\tAverage Score: 14.97\n",
      "actions= [[1. 1.]]\n",
      "1048575  Evaluations Remaining\n",
      "rewards= 13.979113896763522\n",
      "actions= [[1. 1.]]\n",
      "1048574  Evaluations Remaining\n",
      "rewards= -0.14158980084875417\n",
      "Timestep 1\tScore: 13.84\tmin: 13.84\tmax: 13.84actions= [[1. 1.]]\n",
      "1048573  Evaluations Remaining\n",
      "rewards= -0.2219979238420744\n",
      "Timestep 2\tScore: 13.62\tmin: 13.62\tmax: 13.62actions= [[1. 1.]]\n",
      "1048572  Evaluations Remaining\n",
      "rewards= -0.21178760507338978\n",
      "Timestep 3\tScore: 13.40\tmin: 13.40\tmax: 13.40actions= [[1. 1.]]\n",
      "1048571  Evaluations Remaining\n",
      "rewards= 0.011682013752851717\n",
      "Episode 285\tScore: 13.42\tAverage Score: 14.73\n",
      "actions= [[1. 1.]]\n",
      "1048570  Evaluations Remaining\n",
      "rewards= 14.224327164384206\n",
      "actions= [[1. 1.]]\n",
      "1048569  Evaluations Remaining\n",
      "rewards= 0.04072435325544577\n",
      "Timestep 1\tScore: 14.27\tmin: 14.27\tmax: 14.27actions= [[1. 1.]]\n",
      "1048568  Evaluations Remaining\n",
      "rewards= 0.20808227400596602\n",
      "Timestep 2\tScore: 14.47\tmin: 14.47\tmax: 14.47actions= [[1. 1.]]\n",
      "1048567  Evaluations Remaining\n",
      "rewards= -0.0031564968437409746\n",
      "Timestep 3\tScore: 14.47\tmin: 14.47\tmax: 14.47actions= [[1. 1.]]\n",
      "1048566  Evaluations Remaining\n",
      "rewards= -0.1929480806411803\n",
      "Episode 286\tScore: 14.28\tAverage Score: 14.40\n",
      "actions= [[1. 1.]]\n",
      "1048565  Evaluations Remaining\n",
      "rewards= 14.485702145530405\n",
      "actions= [[1. 1.]]\n",
      "1048564  Evaluations Remaining\n",
      "rewards= 0.038649802462284555\n",
      "Timestep 1\tScore: 14.52\tmin: 14.52\tmax: 14.52actions= [[1. 1.]]\n",
      "1048563  Evaluations Remaining\n",
      "rewards= 0.07870295511534708\n",
      "Timestep 2\tScore: 14.60\tmin: 14.60\tmax: 14.60actions= [[1. 1.]]\n",
      "1048562  Evaluations Remaining\n",
      "rewards= -0.00031689696387493527\n",
      "Timestep 3\tScore: 14.60\tmin: 14.60\tmax: 14.60actions= [[1. 1.]]\n",
      "1048561  Evaluations Remaining\n",
      "rewards= -0.03892633338956886\n",
      "Episode 287\tScore: 14.56\tAverage Score: 14.16\n",
      "actions= [[1. 1.]]\n",
      "1048560  Evaluations Remaining\n",
      "rewards= 14.507169878666563\n",
      "actions= [[1. 1.]]\n",
      "1048559  Evaluations Remaining\n",
      "rewards= -0.14138804129781857\n",
      "Timestep 1\tScore: 14.37\tmin: 14.37\tmax: 14.37actions= [[1. 1.]]\n",
      "1048558  Evaluations Remaining\n",
      "rewards= 0.08571967552621995\n",
      "Timestep 2\tScore: 14.45\tmin: 14.45\tmax: 14.45actions= [[1. 1.]]\n",
      "1048557  Evaluations Remaining\n",
      "rewards= -0.04600521373131228\n",
      "Timestep 3\tScore: 14.41\tmin: 14.41\tmax: 14.41actions= [[1. 1.]]\n",
      "1048556  Evaluations Remaining\n",
      "rewards= -0.25543806709055206\n",
      "Episode 288\tScore: 14.15\tAverage Score: 14.04\n",
      "actions= [[1. 1.]]\n",
      "1048555  Evaluations Remaining\n",
      "rewards= 13.800455640880724\n",
      "actions= [[1. 1.]]\n",
      "1048554  Evaluations Remaining\n",
      "rewards= 0.05176348667490149\n",
      "Timestep 1\tScore: 13.85\tmin: 13.85\tmax: 13.85actions= [[1. 1.]]\n",
      "1048553  Evaluations Remaining\n",
      "rewards= 0.11565153699099051\n",
      "Timestep 2\tScore: 13.97\tmin: 13.97\tmax: 13.97actions= [[1. 1.]]\n",
      "1048552  Evaluations Remaining\n",
      "rewards= -0.19641172214959202\n",
      "Timestep 3\tScore: 13.77\tmin: 13.77\tmax: 13.77actions= [[1. 1.]]\n",
      "1048551  Evaluations Remaining\n",
      "rewards= 0.06811398290068871\n",
      "Episode 289\tScore: 13.84\tAverage Score: 14.05\n",
      "actions= [[1. 1.]]\n",
      "1048550  Evaluations Remaining\n",
      "rewards= 13.97272918110728\n",
      "actions= [[1. 1.]]\n",
      "1048549  Evaluations Remaining\n",
      "rewards= -0.18586888176576188\n",
      "Timestep 1\tScore: 13.79\tmin: 13.79\tmax: 13.79actions= [[1. 1.]]\n",
      "1048548  Evaluations Remaining\n",
      "rewards= 0.11578317695204321\n",
      "Timestep 2\tScore: 13.90\tmin: 13.90\tmax: 13.90actions= [[1. 1.]]\n",
      "1048547  Evaluations Remaining\n",
      "rewards= 0.08158333550892882\n",
      "Timestep 3\tScore: 13.98\tmin: 13.98\tmax: 13.98actions= [[1. 1.]]\n",
      "1048546  Evaluations Remaining\n",
      "rewards= -0.22427439157128415\n",
      "Episode 290\tScore: 13.76\tAverage Score: 14.12\n",
      "actions= [[1. 1.]]\n",
      "1048545  Evaluations Remaining\n",
      "rewards= 14.37659835762085\n",
      "actions= [[1. 1.]]\n",
      "1048544  Evaluations Remaining\n",
      "rewards= -0.052215060169906735\n",
      "Timestep 1\tScore: 14.32\tmin: 14.32\tmax: 14.32actions= [[1. 1.]]\n",
      "1048543  Evaluations Remaining\n",
      "rewards= 0.09887077097948627\n",
      "Timestep 2\tScore: 14.42\tmin: 14.42\tmax: 14.42actions= [[1. 1.]]\n",
      "1048542  Evaluations Remaining\n",
      "rewards= -0.12976364000606067\n",
      "Timestep 3\tScore: 14.29\tmin: 14.29\tmax: 14.29actions= [[1. 1.]]\n",
      "1048541  Evaluations Remaining\n",
      "rewards= 0.20798626709366497\n",
      "Episode 291\tScore: 14.50\tAverage Score: 14.16\n",
      "actions= [[1. 1.]]\n",
      "1048540  Evaluations Remaining\n",
      "rewards= 13.870489255869511\n",
      "actions= [[1. 1.]]\n",
      "1048539  Evaluations Remaining\n",
      "rewards= -0.2400948857766254\n",
      "Timestep 1\tScore: 13.63\tmin: 13.63\tmax: 13.63actions= [[1. 1.]]\n",
      "1048538  Evaluations Remaining\n",
      "rewards= -0.032440537071319664\n",
      "Timestep 2\tScore: 13.60\tmin: 13.60\tmax: 13.60actions= [[1. 1.]]\n",
      "1048537  Evaluations Remaining\n",
      "rewards= 0.16577252906816042\n",
      "Timestep 3\tScore: 13.76\tmin: 13.76\tmax: 13.76actions= [[1. 1.]]\n",
      "1048536  Evaluations Remaining\n",
      "rewards= -0.20424186420918655\n",
      "Episode 292\tScore: 13.56\tAverage Score: 13.96\n",
      "actions= [[1. 1.]]\n",
      "1048535  Evaluations Remaining\n",
      "rewards= 14.49347805230295\n",
      "actions= [[1. 1.]]\n",
      "1048534  Evaluations Remaining\n",
      "rewards= -0.25828846937384364\n",
      "Timestep 1\tScore: 14.24\tmin: 14.24\tmax: 14.24actions= [[1. 1.]]\n",
      "1048533  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 0.014825199581943505\n",
      "Timestep 2\tScore: 14.25\tmin: 14.25\tmax: 14.25actions= [[1. 1.]]\n",
      "1048532  Evaluations Remaining\n",
      "rewards= -0.19882352980009665\n",
      "Timestep 3\tScore: 14.05\tmin: 14.05\tmax: 14.05actions= [[1. 1.]]\n",
      "1048531  Evaluations Remaining\n",
      "rewards= -0.06965643677704225\n",
      "Episode 293\tScore: 13.98\tAverage Score: 13.93\n",
      "actions= [[1. 1.]]\n",
      "1048530  Evaluations Remaining\n",
      "rewards= 14.294128535452424\n",
      "actions= [[1. 1.]]\n",
      "1048529  Evaluations Remaining\n",
      "rewards= 0.17045465728371578\n",
      "Timestep 1\tScore: 14.46\tmin: 14.46\tmax: 14.46actions= [[1. 1.]]\n",
      "1048528  Evaluations Remaining\n",
      "rewards= 0.1562813836834449\n",
      "Timestep 2\tScore: 14.62\tmin: 14.62\tmax: 14.62actions= [[1. 1.]]\n",
      "1048527  Evaluations Remaining\n",
      "rewards= -0.04786143819966737\n",
      "Timestep 3\tScore: 14.57\tmin: 14.57\tmax: 14.57actions= [[1. 1.]]\n",
      "1048526  Evaluations Remaining\n",
      "rewards= 0.05245634498253082\n",
      "Episode 294\tScore: 14.63\tAverage Score: 14.09\n",
      "actions= [[1. 1.]]\n",
      "1048525  Evaluations Remaining\n",
      "rewards= 14.909533387631946\n",
      "actions= [[1. 1.]]\n",
      "1048524  Evaluations Remaining\n",
      "rewards= 0.1331092292071343\n",
      "Timestep 1\tScore: 15.04\tmin: 15.04\tmax: 15.04actions= [[1. 1.]]\n",
      "1048523  Evaluations Remaining\n",
      "rewards= 0.16657199888359875\n",
      "Timestep 2\tScore: 15.21\tmin: 15.21\tmax: 15.21actions= [[1. 1.]]\n",
      "1048522  Evaluations Remaining\n",
      "rewards= -0.24990628906300616\n",
      "Timestep 3\tScore: 14.96\tmin: 14.96\tmax: 14.96actions= [[1. 1.]]\n",
      "1048521  Evaluations Remaining\n",
      "rewards= 0.12090674154175352\n",
      "Episode 295\tScore: 15.08\tAverage Score: 14.35\n",
      "actions= [[1. 1.]]\n",
      "1048520  Evaluations Remaining\n",
      "rewards= 13.760764259074186\n",
      "actions= [[1. 1.]]\n",
      "1048519  Evaluations Remaining\n",
      "rewards= -0.205278823224317\n",
      "Timestep 1\tScore: 13.56\tmin: 13.56\tmax: 13.56actions= [[1. 1.]]\n",
      "1048518  Evaluations Remaining\n",
      "rewards= -0.22653187451421752\n",
      "Timestep 2\tScore: 13.33\tmin: 13.33\tmax: 13.33actions= [[1. 1.]]\n",
      "1048517  Evaluations Remaining\n",
      "rewards= 0.07643946249704925\n",
      "Timestep 3\tScore: 13.41\tmin: 13.41\tmax: 13.41actions= [[1. 1.]]\n",
      "1048516  Evaluations Remaining\n",
      "rewards= -0.24898509379775113\n",
      "Episode 296\tScore: 13.16\tAverage Score: 14.08\n",
      "actions= [[1. 1.]]\n",
      "1048515  Evaluations Remaining\n",
      "rewards= 16.431938248349624\n",
      "actions= [[1. 1.]]\n",
      "1048514  Evaluations Remaining\n",
      "rewards= -0.19008689315085014\n",
      "Timestep 1\tScore: 16.24\tmin: 16.24\tmax: 16.24actions= [[1. 1.]]\n",
      "1048513  Evaluations Remaining\n",
      "rewards= -0.024024024941502464\n",
      "Timestep 2\tScore: 16.22\tmin: 16.22\tmax: 16.22actions= [[1. 1.]]\n",
      "1048512  Evaluations Remaining\n",
      "rewards= 0.011571598724388732\n",
      "Timestep 3\tScore: 16.23\tmin: 16.23\tmax: 16.23actions= [[1. 1.]]\n",
      "1048511  Evaluations Remaining\n",
      "rewards= -0.06808928627544697\n",
      "Episode 297\tScore: 16.16\tAverage Score: 14.60\n",
      "actions= [[1. 1.]]\n",
      "1048510  Evaluations Remaining\n",
      "rewards= 14.529133374578342\n",
      "actions= [[1. 1.]]\n",
      "1048509  Evaluations Remaining\n",
      "rewards= 0.06086700791048649\n",
      "Timestep 1\tScore: 14.59\tmin: 14.59\tmax: 14.59actions= [[1. 1.]]\n",
      "1048508  Evaluations Remaining\n",
      "rewards= -0.16594959153856603\n",
      "Timestep 2\tScore: 14.42\tmin: 14.42\tmax: 14.42actions= [[1. 1.]]\n",
      "1048507  Evaluations Remaining\n",
      "rewards= -0.20557140945944674\n",
      "Timestep 3\tScore: 14.22\tmin: 14.22\tmax: 14.22actions= [[1. 1.]]\n",
      "1048506  Evaluations Remaining\n",
      "rewards= 0.0641714464117995\n",
      "Episode 298\tScore: 14.28\tAverage Score: 14.66\n",
      "actions= [[1. 1.]]\n",
      "1048505  Evaluations Remaining\n",
      "rewards= 13.55165782280579\n",
      "actions= [[1. 1.]]\n",
      "1048504  Evaluations Remaining\n",
      "rewards= 0.22743440400680193\n",
      "Timestep 1\tScore: 13.78\tmin: 13.78\tmax: 13.78actions= [[1. 1.]]\n",
      "1048503  Evaluations Remaining\n",
      "rewards= 0.09456405065630502\n",
      "Timestep 2\tScore: 13.87\tmin: 13.87\tmax: 13.87actions= [[0.         0.25040017]]\n",
      "1048502  Evaluations Remaining\n",
      "rewards= 0.13290111713415875\n",
      "Timestep 3\tScore: 14.01\tmin: 14.01\tmax: 14.01actions= [[1. 1.]]\n",
      "1048501  Evaluations Remaining\n",
      "rewards= -58.4495069485425\n",
      "Episode 299\tScore: -44.44\tAverage Score: 2.85.44\n",
      "actions= [[1. 1.]]\n",
      "1048500  Evaluations Remaining\n",
      "rewards= 15.924008078514786\n",
      "actions= [[1. 1.]]\n",
      "1048499  Evaluations Remaining\n",
      "rewards= -0.05952081216832017\n",
      "Timestep 1\tScore: 15.86\tmin: 15.86\tmax: 15.86actions= [[1. 1.]]\n",
      "1048498  Evaluations Remaining\n",
      "rewards= 0.14264113543213508\n",
      "Timestep 2\tScore: 16.01\tmin: 16.01\tmax: 16.01actions= [[1. 1.]]\n",
      "1048497  Evaluations Remaining\n",
      "rewards= 0.24783077207576687\n",
      "Timestep 3\tScore: 16.25\tmin: 16.25\tmax: 16.25actions= [[1. 1.]]\n",
      "1048496  Evaluations Remaining\n",
      "rewards= 0.1643174563864358\n",
      "Episode 300\tScore: 16.42\tAverage Score: 3.122\n",
      "Episode 300\tAverage Score: 3.12\n",
      "actions= [[1. 1.]]\n",
      "1048495  Evaluations Remaining\n",
      "rewards= 15.814157659776644\n",
      "actions= [[1. 1.]]\n",
      "1048494  Evaluations Remaining\n",
      "rewards= -0.12900212597882144\n",
      "Timestep 1\tScore: 15.69\tmin: 15.69\tmax: 15.69actions= [[1. 1.]]\n",
      "1048493  Evaluations Remaining\n",
      "rewards= 0.1968782815292407\n",
      "Timestep 2\tScore: 15.88\tmin: 15.88\tmax: 15.88actions= [[1. 1.]]\n",
      "1048492  Evaluations Remaining\n",
      "rewards= -0.08056109750882579\n",
      "Timestep 3\tScore: 15.80\tmin: 15.80\tmax: 15.80actions= [[1. 1.]]\n",
      "1048491  Evaluations Remaining\n",
      "rewards= 0.11181019433197248\n",
      "Episode 301\tScore: 15.91\tAverage Score: 3.671\n",
      "actions= [[1. 1.]]\n",
      "1048490  Evaluations Remaining\n",
      "rewards= 13.777295991015876\n",
      "actions= [[1. 1.]]\n",
      "1048489  Evaluations Remaining\n",
      "rewards= 0.24433909101390228\n",
      "Timestep 1\tScore: 14.02\tmin: 14.02\tmax: 14.02actions= [[1. 1.]]\n",
      "1048488  Evaluations Remaining\n",
      "rewards= -0.16050708956267323\n",
      "Timestep 2\tScore: 13.86\tmin: 13.86\tmax: 13.86actions= [[1. 1.]]\n",
      "1048487  Evaluations Remaining\n",
      "rewards= -0.05675912226318136\n",
      "Timestep 3\tScore: 13.80\tmin: 13.80\tmax: 13.80actions= [[1. 1.]]\n",
      "1048486  Evaluations Remaining\n",
      "rewards= 0.24979657297075564\n",
      "Episode 302\tScore: 14.05\tAverage Score: 3.255\n",
      "actions= [[1. 1.]]\n",
      "1048485  Evaluations Remaining\n",
      "rewards= 16.128549763405534\n",
      "actions= [[1. 1.]]\n",
      "1048484  Evaluations Remaining\n",
      "rewards= 0.13989246882089956\n",
      "Timestep 1\tScore: 16.27\tmin: 16.27\tmax: 16.27actions= [[1. 1.]]\n",
      "1048483  Evaluations Remaining\n",
      "rewards= -0.24118348810153822\n",
      "Timestep 2\tScore: 16.03\tmin: 16.03\tmax: 16.03actions= [[1. 1.]]\n",
      "1048482  Evaluations Remaining\n",
      "rewards= 0.055238109773119604\n",
      "Timestep 3\tScore: 16.08\tmin: 16.08\tmax: 16.08actions= [[1. 1.]]\n",
      "1048481  Evaluations Remaining\n",
      "rewards= 0.270967899304853\n",
      "Episode 303\tScore: 16.35\tAverage Score: 3.665\n",
      "actions= [[1. 1.]]\n",
      "1048480  Evaluations Remaining\n",
      "rewards= 14.851934324638314\n",
      "actions= [[1. 1.]]\n",
      "1048479  Evaluations Remaining\n",
      "rewards= -0.08176677171973346\n",
      "Timestep 1\tScore: 14.77\tmin: 14.77\tmax: 14.77actions= [[1. 1.]]\n",
      "1048478  Evaluations Remaining\n",
      "rewards= 0.01148023600313719\n",
      "Timestep 2\tScore: 14.78\tmin: 14.78\tmax: 14.78actions= [[1. 1.]]\n",
      "1048477  Evaluations Remaining\n",
      "rewards= -0.023325519156062402\n",
      "Timestep 3\tScore: 14.76\tmin: 14.76\tmax: 14.76actions= [[1. 1.]]\n",
      "1048476  Evaluations Remaining\n",
      "rewards= 0.17277916313688912\n",
      "Episode 304\tScore: 14.93\tAverage Score: 15.53\n",
      "actions= [[1. 1.]]\n",
      "1048475  Evaluations Remaining\n",
      "rewards= 15.635321707576644\n",
      "actions= [[1. 1.]]\n",
      "1048474  Evaluations Remaining\n",
      "rewards= 0.013645602869949425\n",
      "Timestep 1\tScore: 15.65\tmin: 15.65\tmax: 15.65actions= [[1. 1.]]\n",
      "1048473  Evaluations Remaining\n",
      "rewards= 0.1782670994174036\n",
      "Timestep 2\tScore: 15.83\tmin: 15.83\tmax: 15.83actions= [[1. 1.]]\n",
      "1048472  Evaluations Remaining\n",
      "rewards= -0.13955151755378514\n",
      "Timestep 3\tScore: 15.69\tmin: 15.69\tmax: 15.69actions= [[1. 1.]]\n",
      "1048471  Evaluations Remaining\n",
      "rewards= -0.10106064165434514\n",
      "Episode 305\tScore: 15.59\tAverage Score: 15.37\n",
      "actions= [[1. 1.]]\n",
      "1048470  Evaluations Remaining\n",
      "rewards= 16.01376729396661\n",
      "actions= [[1. 1.]]\n",
      "1048469  Evaluations Remaining\n",
      "rewards= 0.19874979160211792\n",
      "Timestep 1\tScore: 16.21\tmin: 16.21\tmax: 16.21actions= [[1. 1.]]\n",
      "1048468  Evaluations Remaining\n",
      "rewards= 0.01603193889426091\n",
      "Timestep 2\tScore: 16.23\tmin: 16.23\tmax: 16.23actions= [[1. 1.]]\n",
      "1048467  Evaluations Remaining\n",
      "rewards= -0.04798762421299907\n",
      "Timestep 3\tScore: 16.18\tmin: 16.18\tmax: 16.18actions= [[1. 1.]]\n",
      "1048466  Evaluations Remaining\n",
      "rewards= -0.22579336260749594\n",
      "Episode 306\tScore: 15.95\tAverage Score: 15.38\n",
      "actions= [[1. 1.]]\n",
      "1048465  Evaluations Remaining\n",
      "rewards= 16.286403201675395\n",
      "actions= [[1. 1.]]\n",
      "1048464  Evaluations Remaining\n",
      "rewards= 0.11265836945937924\n",
      "Timestep 1\tScore: 16.40\tmin: 16.40\tmax: 16.40actions= [[1. 1.]]\n",
      "1048463  Evaluations Remaining\n",
      "rewards= 0.22685983879570504\n",
      "Timestep 2\tScore: 16.63\tmin: 16.63\tmax: 16.63actions= [[1. 1.]]\n",
      "1048462  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= -0.09581200814288815\n",
      "Timestep 3\tScore: 16.53\tmin: 16.53\tmax: 16.53actions= [[1. 1.]]\n",
      "1048461  Evaluations Remaining\n",
      "rewards= 0.2468928849308778\n",
      "Episode 307\tScore: 16.78\tAverage Score: 15.92\n",
      "actions= [[1. 1.]]\n",
      "1048460  Evaluations Remaining\n",
      "rewards= 13.748340351331821\n",
      "actions= [[1. 1.]]\n",
      "1048459  Evaluations Remaining\n",
      "rewards= -0.08420813729438903\n",
      "Timestep 1\tScore: 13.66\tmin: 13.66\tmax: 13.66actions= [[1. 1.]]\n",
      "1048458  Evaluations Remaining\n",
      "rewards= 0.017767893374597943\n",
      "Timestep 2\tScore: 13.68\tmin: 13.68\tmax: 13.68actions= [[1. 1.]]\n",
      "1048457  Evaluations Remaining\n",
      "rewards= -0.19579727959647242\n",
      "Timestep 3\tScore: 13.49\tmin: 13.49\tmax: 13.49actions= [[1. 1.]]\n",
      "1048456  Evaluations Remaining\n",
      "rewards= 0.1033503030001075\n",
      "Episode 308\tScore: 13.59\tAverage Score: 15.37\n",
      "actions= [[1. 1.]]\n",
      "1048455  Evaluations Remaining\n",
      "rewards= 14.504624093267065\n",
      "actions= [[1. 1.]]\n",
      "1048454  Evaluations Remaining\n",
      "rewards= -0.17615318695773086\n",
      "Timestep 1\tScore: 14.33\tmin: 14.33\tmax: 14.33actions= [[1. 1.]]\n",
      "1048453  Evaluations Remaining\n",
      "rewards= -0.08546702112459181\n",
      "Timestep 2\tScore: 14.24\tmin: 14.24\tmax: 14.24actions= [[1. 1.]]\n",
      "1048452  Evaluations Remaining\n",
      "rewards= -0.024567161217712297\n",
      "Timestep 3\tScore: 14.22\tmin: 14.22\tmax: 14.22actions= [[1. 1.]]\n",
      "1048451  Evaluations Remaining\n",
      "rewards= 0.18590833951241503\n",
      "Episode 309\tScore: 14.40\tAverage Score: 15.26\n",
      "actions= [[1. 1.]]\n",
      "1048450  Evaluations Remaining\n",
      "rewards= 16.214182712071874\n",
      "actions= [[1. 1.]]\n",
      "1048449  Evaluations Remaining\n",
      "rewards= -0.17173714724504485\n",
      "Timestep 1\tScore: 16.04\tmin: 16.04\tmax: 16.04actions= [[1. 1.]]\n",
      "1048448  Evaluations Remaining\n",
      "rewards= 0.08584791557220584\n",
      "Timestep 2\tScore: 16.13\tmin: 16.13\tmax: 16.13actions= [[1. 1.]]\n",
      "1048447  Evaluations Remaining\n",
      "rewards= 0.10219179007040813\n",
      "Timestep 3\tScore: 16.23\tmin: 16.23\tmax: 16.23actions= [[1. 1.]]\n",
      "1048446  Evaluations Remaining\n",
      "rewards= 0.09672322708474645\n",
      "Episode 310\tScore: 16.33\tAverage Score: 15.41\n",
      "actions= [[1. 1.]]\n",
      "1048445  Evaluations Remaining\n",
      "rewards= 16.19449311583143\n",
      "actions= [[1. 1.]]\n",
      "1048444  Evaluations Remaining\n",
      "rewards= -0.0918748634936084\n",
      "Timestep 1\tScore: 16.10\tmin: 16.10\tmax: 16.10actions= [[1. 1.]]\n",
      "1048443  Evaluations Remaining\n",
      "rewards= -0.25266202365894674\n",
      "Timestep 2\tScore: 15.85\tmin: 15.85\tmax: 15.85actions= [[1. 1.]]\n",
      "1048442  Evaluations Remaining\n",
      "rewards= -0.09749637580425308\n",
      "Timestep 3\tScore: 15.75\tmin: 15.75\tmax: 15.75actions= [[1. 1.]]\n",
      "1048441  Evaluations Remaining\n",
      "rewards= -0.25950701053200476\n",
      "Episode 311\tScore: 15.49\tAverage Score: 15.32\n",
      "actions= [[1. 1.]]\n",
      "1048440  Evaluations Remaining\n",
      "rewards= 14.00552578486863\n",
      "actions= [[1. 1.]]\n",
      "1048439  Evaluations Remaining\n",
      "rewards= -0.18382920629162802\n",
      "Timestep 1\tScore: 13.82\tmin: 13.82\tmax: 13.82actions= [[1. 1.]]\n",
      "1048438  Evaluations Remaining\n",
      "rewards= -0.10871759630287814\n",
      "Timestep 2\tScore: 13.71\tmin: 13.71\tmax: 13.71actions= [[1. 1.]]\n",
      "1048437  Evaluations Remaining\n",
      "rewards= -0.18922176761919207\n",
      "Timestep 3\tScore: 13.52\tmin: 13.52\tmax: 13.52actions= [[1. 1.]]\n",
      "1048436  Evaluations Remaining\n",
      "rewards= -0.0956907025852276\n",
      "Episode 312\tScore: 13.43\tAverage Score: 14.65\n",
      "actions= [[1. 1.]]\n",
      "1048435  Evaluations Remaining\n",
      "rewards= 14.813369937962388\n",
      "actions= [[1. 1.]]\n",
      "1048434  Evaluations Remaining\n",
      "rewards= -0.12189326149924051\n",
      "Timestep 1\tScore: 14.69\tmin: 14.69\tmax: 14.69actions= [[1. 1.]]\n",
      "1048433  Evaluations Remaining\n",
      "rewards= 0.14306769581471457\n",
      "Timestep 2\tScore: 14.83\tmin: 14.83\tmax: 14.83actions= [[1. 1.]]\n",
      "1048432  Evaluations Remaining\n",
      "rewards= -0.004504490927261351\n",
      "Timestep 3\tScore: 14.83\tmin: 14.83\tmax: 14.83actions= [[1. 1.]]\n",
      "1048431  Evaluations Remaining\n",
      "rewards= -0.1601438357989089\n",
      "Episode 313\tScore: 14.67\tAverage Score: 14.86\n",
      "actions= [[1. 1.]]\n",
      "1048430  Evaluations Remaining\n",
      "rewards= 13.754118039864915\n",
      "actions= [[1. 1.]]\n",
      "1048429  Evaluations Remaining\n",
      "rewards= 0.047031561785667364\n",
      "Timestep 1\tScore: 13.80\tmin: 13.80\tmax: 13.80actions= [[1. 1.]]\n",
      "1048428  Evaluations Remaining\n",
      "rewards= 0.11640960964627389\n",
      "Timestep 2\tScore: 13.92\tmin: 13.92\tmax: 13.92actions= [[1. 1.]]\n",
      "1048427  Evaluations Remaining\n",
      "rewards= 0.19431998946097018\n",
      "Timestep 3\tScore: 14.11\tmin: 14.11\tmax: 14.11actions= [[1. 1.]]\n",
      "1048426  Evaluations Remaining\n",
      "rewards= -0.17660707410611876\n",
      "Episode 314\tScore: 13.94\tAverage Score: 14.77\n",
      "actions= [[1. 1.]]\n",
      "1048425  Evaluations Remaining\n",
      "rewards= 13.677503943127748\n",
      "actions= [[1. 1.]]\n",
      "1048424  Evaluations Remaining\n",
      "rewards= 0.06413588921962132\n",
      "Timestep 1\tScore: 13.74\tmin: 13.74\tmax: 13.74actions= [[1. 1.]]\n",
      "1048423  Evaluations Remaining\n",
      "rewards= -0.12522071388786582\n",
      "Timestep 2\tScore: 13.62\tmin: 13.62\tmax: 13.62actions= [[1. 1.]]\n",
      "1048422  Evaluations Remaining\n",
      "rewards= -0.24215117381322804\n",
      "Timestep 3\tScore: 13.37\tmin: 13.37\tmax: 13.37actions= [[1. 1.]]\n",
      "1048421  Evaluations Remaining\n",
      "rewards= 0.03698712660518666\n",
      "Episode 315\tScore: 13.41\tAverage Score: 14.19\n",
      "actions= [[1. 1.]]\n",
      "1048420  Evaluations Remaining\n",
      "rewards= 16.149248738801305\n",
      "actions= [[1. 1.]]\n",
      "1048419  Evaluations Remaining\n",
      "rewards= -0.2517260636194729\n",
      "Timestep 1\tScore: 15.90\tmin: 15.90\tmax: 15.90actions= [[1. 1.]]\n",
      "1048418  Evaluations Remaining\n",
      "rewards= -0.22311244573557332\n",
      "Timestep 2\tScore: 15.67\tmin: 15.67\tmax: 15.67actions= [[1. 1.]]\n",
      "1048417  Evaluations Remaining\n",
      "rewards= -0.16938425879719254\n",
      "Timestep 3\tScore: 15.51\tmin: 15.51\tmax: 15.51actions= [[1. 1.]]\n",
      "1048416  Evaluations Remaining\n",
      "rewards= -0.1792122088454322\n",
      "Episode 316\tScore: 15.33\tAverage Score: 14.15\n",
      "actions= [[1. 1.]]\n",
      "1048415  Evaluations Remaining\n",
      "rewards= 13.818437638062234\n",
      "actions= [[1. 1.]]\n",
      "1048414  Evaluations Remaining\n",
      "rewards= -0.2666533189051812\n",
      "Timestep 1\tScore: 13.55\tmin: 13.55\tmax: 13.55actions= [[1. 1.]]\n",
      "1048413  Evaluations Remaining\n",
      "rewards= 0.16117458411829766\n",
      "Timestep 2\tScore: 13.71\tmin: 13.71\tmax: 13.71actions= [[1. 1.]]\n",
      "1048412  Evaluations Remaining\n",
      "rewards= -0.03214523967875316\n",
      "Timestep 3\tScore: 13.68\tmin: 13.68\tmax: 13.68actions= [[1. 1.]]\n",
      "1048411  Evaluations Remaining\n",
      "rewards= -0.21138516133161778\n",
      "Episode 317\tScore: 13.47\tAverage Score: 14.16\n",
      "actions= [[1. 1.]]\n",
      "1048410  Evaluations Remaining\n",
      "rewards= 14.109956046508017\n",
      "actions= [[1. 1.]]\n",
      "1048409  Evaluations Remaining\n",
      "rewards= -0.20405823674894963\n",
      "Timestep 1\tScore: 13.91\tmin: 13.91\tmax: 13.91actions= [[0.47359715 1.        ]]\n",
      "1048408  Evaluations Remaining\n",
      "rewards= 0.1931998724666384\n",
      "Timestep 2\tScore: 14.10\tmin: 14.10\tmax: 14.10actions= [[1. 1.]]\n",
      "1048407  Evaluations Remaining\n",
      "rewards= 24.164848782554643\n",
      "Timestep 3\tScore: 38.26\tmin: 38.26\tmax: 38.26actions= [[1. 1.]]\n",
      "1048406  Evaluations Remaining\n",
      "rewards= 0.1551511563856458\n",
      "Episode 318\tScore: 38.42\tAverage Score: 18.91\n",
      "actions= [[1. 1.]]\n",
      "1048405  Evaluations Remaining\n",
      "rewards= 14.745733810896253\n",
      "actions= [[1. 1.]]\n",
      "1048404  Evaluations Remaining\n",
      "rewards= -0.21681856248780296\n",
      "Timestep 1\tScore: 14.53\tmin: 14.53\tmax: 14.53actions= [[1. 1.]]\n",
      "1048403  Evaluations Remaining\n",
      "rewards= -0.20883587898208322\n",
      "Timestep 2\tScore: 14.32\tmin: 14.32\tmax: 14.32actions= [[1. 1.]]\n",
      "1048402  Evaluations Remaining\n",
      "rewards= 0.2300424496391873\n",
      "Timestep 3\tScore: 14.55\tmin: 14.55\tmax: 14.55actions= [[1. 1.]]\n",
      "1048401  Evaluations Remaining\n",
      "rewards= 0.07915833974107045\n",
      "Episode 319\tScore: 14.63\tAverage Score: 19.05\n",
      "actions= [[1. 1.]]\n",
      "1048400  Evaluations Remaining\n",
      "rewards= 14.217404764729913\n",
      "actions= [[1. 1.]]\n",
      "1048399  Evaluations Remaining\n",
      "rewards= -0.12558757417072242\n",
      "Timestep 1\tScore: 14.09\tmin: 14.09\tmax: 14.09actions= [[1. 1.]]\n",
      "1048398  Evaluations Remaining\n",
      "rewards= -0.225920565951502\n",
      "Timestep 2\tScore: 13.87\tmin: 13.87\tmax: 13.87actions= [[1. 1.]]\n",
      "1048397  Evaluations Remaining\n",
      "rewards= -0.020837200490420926\n",
      "Timestep 3\tScore: 13.85\tmin: 13.85\tmax: 13.85actions= [[1. 1.]]\n",
      "1048396  Evaluations Remaining\n",
      "rewards= -0.20887193734571596\n",
      "Episode 320\tScore: 13.64\tAverage Score: 19.10\n",
      "actions= [[1. 1.]]\n",
      "1048395  Evaluations Remaining\n",
      "rewards= 16.052704545879518\n",
      "actions= [[1. 1.]]\n",
      "1048394  Evaluations Remaining\n",
      "rewards= -0.11064349315123767\n",
      "Timestep 1\tScore: 15.94\tmin: 15.94\tmax: 15.94actions= [[1. 1.]]\n",
      "1048393  Evaluations Remaining\n",
      "rewards= -0.11103864644331729\n",
      "Timestep 2\tScore: 15.83\tmin: 15.83\tmax: 15.83actions= [[1. 1.]]\n",
      "1048392  Evaluations Remaining\n",
      "rewards= -0.05191798749052712\n",
      "Timestep 3\tScore: 15.78\tmin: 15.78\tmax: 15.78actions= [[1. 1.]]\n",
      "1048391  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 0.22155455823131742\n",
      "Episode 321\tScore: 16.00\tAverage Score: 19.23\n",
      "actions= [[1. 1.]]\n",
      "1048390  Evaluations Remaining\n",
      "rewards= 15.775423398149536\n",
      "actions= [[1. 1.]]\n",
      "1048389  Evaluations Remaining\n",
      "rewards= 0.2184686469878625\n",
      "Timestep 1\tScore: 15.99\tmin: 15.99\tmax: 15.99actions= [[1. 1.]]\n",
      "1048388  Evaluations Remaining\n",
      "rewards= -0.25534695644042493\n",
      "Timestep 2\tScore: 15.74\tmin: 15.74\tmax: 15.74actions= [[1. 1.]]\n",
      "1048387  Evaluations Remaining\n",
      "rewards= 0.04005529954357279\n",
      "Timestep 3\tScore: 15.78\tmin: 15.78\tmax: 15.78actions= [[1. 1.]]\n",
      "1048386  Evaluations Remaining\n",
      "rewards= 0.2583997951111101\n",
      "Episode 322\tScore: 16.04\tAverage Score: 19.74\n",
      "actions= [[1. 1.]]\n",
      "1048385  Evaluations Remaining\n",
      "rewards= 15.357246018498769\n",
      "actions= [[1. 1.]]\n",
      "1048384  Evaluations Remaining\n",
      "rewards= 0.05846851423624111\n",
      "Timestep 1\tScore: 15.42\tmin: 15.42\tmax: 15.42actions= [[1. 1.]]\n",
      "1048383  Evaluations Remaining\n",
      "rewards= 0.004345299927543955\n",
      "Timestep 2\tScore: 15.42\tmin: 15.42\tmax: 15.42actions= [[1. 1.]]\n",
      "1048382  Evaluations Remaining\n",
      "rewards= 0.03240535266548639\n",
      "Timestep 3\tScore: 15.45\tmin: 15.45\tmax: 15.45actions= [[1. 1.]]\n",
      "1048381  Evaluations Remaining\n",
      "rewards= 0.174197605459963\n",
      "Episode 323\tScore: 15.63\tAverage Score: 15.19\n",
      "actions= [[1. 1.]]\n",
      "1048380  Evaluations Remaining\n",
      "rewards= 14.929449490420009\n",
      "actions= [[1. 1.]]\n",
      "1048379  Evaluations Remaining\n",
      "rewards= 0.2666417267254553\n",
      "Timestep 1\tScore: 15.20\tmin: 15.20\tmax: 15.20actions= [[1. 1.]]\n",
      "1048378  Evaluations Remaining\n",
      "rewards= -0.21123451614807998\n",
      "Timestep 2\tScore: 14.98\tmin: 14.98\tmax: 14.98actions= [[1. 1.]]\n",
      "1048377  Evaluations Remaining\n",
      "rewards= 0.08400924203928284\n",
      "Timestep 3\tScore: 15.07\tmin: 15.07\tmax: 15.07actions= [[1. 1.]]\n",
      "1048376  Evaluations Remaining\n",
      "rewards= 0.07728299851861697\n",
      "Episode 324\tScore: 15.15\tAverage Score: 15.29\n",
      "actions= [[1. 1.]]\n",
      "1048375  Evaluations Remaining\n",
      "rewards= 14.61248176876549\n",
      "actions= [[1. 1.]]\n",
      "1048374  Evaluations Remaining\n",
      "rewards= 0.08711590279920722\n",
      "Timestep 1\tScore: 14.70\tmin: 14.70\tmax: 14.70actions= [[1. 1.]]\n",
      "1048373  Evaluations Remaining\n",
      "rewards= -0.17649269357499264\n",
      "Timestep 2\tScore: 14.52\tmin: 14.52\tmax: 14.52actions= [[1. 1.]]\n",
      "1048372  Evaluations Remaining\n",
      "rewards= 0.24526605954898084\n",
      "Timestep 3\tScore: 14.77\tmin: 14.77\tmax: 14.77actions= [[1. 1.]]\n",
      "1048371  Evaluations Remaining\n",
      "rewards= 0.23263413488118\n",
      "Episode 325\tScore: 15.00\tAverage Score: 15.56\n",
      "actions= [[1. 1.]]\n",
      "1048370  Evaluations Remaining\n",
      "rewards= 13.628900240631191\n",
      "actions= [[1. 1.]]\n",
      "1048369  Evaluations Remaining\n",
      "rewards= 0.2706189949930402\n",
      "Timestep 1\tScore: 13.90\tmin: 13.90\tmax: 13.90actions= [[1. 1.]]\n",
      "1048368  Evaluations Remaining\n",
      "rewards= -0.03313387548151736\n",
      "Timestep 2\tScore: 13.87\tmin: 13.87\tmax: 13.87actions= [[1. 1.]]\n",
      "1048367  Evaluations Remaining\n",
      "rewards= -0.17124053698243147\n",
      "Timestep 3\tScore: 13.70\tmin: 13.70\tmax: 13.70actions= [[1. 1.]]\n",
      "1048366  Evaluations Remaining\n",
      "rewards= 0.24681838047375582\n",
      "Episode 326\tScore: 13.94\tAverage Score: 15.15\n",
      "actions= [[1. 1.]]\n",
      "1048365  Evaluations Remaining\n",
      "rewards= 14.493851579214173\n",
      "actions= [[1. 1.]]\n",
      "1048364  Evaluations Remaining\n",
      "rewards= -0.2009906973479927\n",
      "Timestep 1\tScore: 14.29\tmin: 14.29\tmax: 14.29actions= [[1. 1.]]\n",
      "1048363  Evaluations Remaining\n",
      "rewards= -0.16449148227705468\n",
      "Timestep 2\tScore: 14.13\tmin: 14.13\tmax: 14.13actions= [[1. 1.]]\n",
      "1048362  Evaluations Remaining\n",
      "rewards= -0.1194274602771368\n",
      "Timestep 3\tScore: 14.01\tmin: 14.01\tmax: 14.01actions= [[1. 1.]]\n",
      "1048361  Evaluations Remaining\n",
      "rewards= -0.2350597305354798\n",
      "Episode 327\tScore: 13.77\tAverage Score: 14.70\n",
      "actions= [[1. 1.]]\n",
      "1048360  Evaluations Remaining\n",
      "rewards= 14.406972960856516\n",
      "actions= [[1. 1.]]\n",
      "1048359  Evaluations Remaining\n",
      "rewards= -0.14790183032707294\n",
      "Timestep 1\tScore: 14.26\tmin: 14.26\tmax: 14.26actions= [[1. 1.]]\n",
      "1048358  Evaluations Remaining\n",
      "rewards= 0.24575467155225716\n",
      "Timestep 2\tScore: 14.50\tmin: 14.50\tmax: 14.50actions= [[1. 1.]]\n",
      "1048357  Evaluations Remaining\n",
      "rewards= 0.1682818573711602\n",
      "Timestep 3\tScore: 14.67\tmin: 14.67\tmax: 14.67actions= [[1. 1.]]\n",
      "1048356  Evaluations Remaining\n",
      "rewards= 0.02578206244776382\n",
      "Episode 328\tScore: 14.70\tAverage Score: 14.51\n",
      "actions= [[1. 1.]]\n",
      "1048355  Evaluations Remaining\n",
      "rewards= 14.73961501940017\n",
      "actions= [[1. 1.]]\n",
      "1048354  Evaluations Remaining\n",
      "rewards= -0.054563958182808125\n",
      "Timestep 1\tScore: 14.69\tmin: 14.69\tmax: 14.69actions= [[1. 1.]]\n",
      "1048353  Evaluations Remaining\n",
      "rewards= -0.09385705166111125\n",
      "Timestep 2\tScore: 14.59\tmin: 14.59\tmax: 14.59actions= [[1. 1.]]\n",
      "1048352  Evaluations Remaining\n",
      "rewards= 0.02881649282933596\n",
      "Timestep 3\tScore: 14.62\tmin: 14.62\tmax: 14.62actions= [[1. 1.]]\n",
      "1048351  Evaluations Remaining\n",
      "rewards= 0.13914224062981306\n",
      "Episode 329\tScore: 14.76\tAverage Score: 14.43\n",
      "actions= [[1. 1.]]\n",
      "1048350  Evaluations Remaining\n",
      "rewards= 15.915506181515656\n",
      "actions= [[1. 1.]]\n",
      "1048349  Evaluations Remaining\n",
      "rewards= 0.16003115490517272\n",
      "Timestep 1\tScore: 16.08\tmin: 16.08\tmax: 16.08actions= [[1. 1.]]\n",
      "1048348  Evaluations Remaining\n",
      "rewards= 0.010940940535312471\n",
      "Timestep 2\tScore: 16.09\tmin: 16.09\tmax: 16.09actions= [[1. 1.]]\n",
      "1048347  Evaluations Remaining\n",
      "rewards= 0.12416921047007179\n",
      "Timestep 3\tScore: 16.21\tmin: 16.21\tmax: 16.21actions= [[1. 1.]]\n",
      "1048346  Evaluations Remaining\n",
      "rewards= 0.21886048103107836\n",
      "Episode 330\tScore: 16.43\tAverage Score: 14.72\n",
      "actions= [[1. 1.]]\n",
      "1048345  Evaluations Remaining\n",
      "rewards= 13.64995216068388\n",
      "actions= [[1. 1.]]\n",
      "1048344  Evaluations Remaining\n",
      "rewards= -0.04131667435133002\n",
      "Timestep 1\tScore: 13.61\tmin: 13.61\tmax: 13.61actions= [[1. 1.]]\n",
      "1048343  Evaluations Remaining\n",
      "rewards= -0.0062261833436840774\n",
      "Timestep 2\tScore: 13.60\tmin: 13.60\tmax: 13.60actions= [[1. 1.]]\n",
      "1048342  Evaluations Remaining\n",
      "rewards= -0.01662398305229651\n",
      "Timestep 3\tScore: 13.59\tmin: 13.59\tmax: 13.59actions= [[1. 1.]]\n",
      "1048341  Evaluations Remaining\n",
      "rewards= 0.0007285140928559031\n",
      "Episode 331\tScore: 13.59\tAverage Score: 14.65\n",
      "actions= [[1. 1.]]\n",
      "1048340  Evaluations Remaining\n",
      "rewards= 16.056672306413105\n",
      "actions= [[1. 1.]]\n",
      "1048339  Evaluations Remaining\n",
      "rewards= -0.2584704460153464\n",
      "Timestep 1\tScore: 15.80\tmin: 15.80\tmax: 15.80actions= [[1. 1.]]\n",
      "1048338  Evaluations Remaining\n",
      "rewards= -0.18953473534664989\n",
      "Timestep 2\tScore: 15.61\tmin: 15.61\tmax: 15.61actions= [[1. 1.]]\n",
      "1048337  Evaluations Remaining\n",
      "rewards= -0.04437204393333527\n",
      "Timestep 3\tScore: 15.56\tmin: 15.56\tmax: 15.56actions= [[1. 1.]]\n",
      "1048336  Evaluations Remaining\n",
      "rewards= 0.2650706383196124\n",
      "Episode 332\tScore: 15.83\tAverage Score: 15.06\n",
      "actions= [[1. 1.]]\n",
      "1048335  Evaluations Remaining\n",
      "rewards= 13.831060122883159\n",
      "actions= [[1. 1.]]\n",
      "1048334  Evaluations Remaining\n",
      "rewards= 0.022480079795444752\n",
      "Timestep 1\tScore: 13.85\tmin: 13.85\tmax: 13.85actions= [[1. 1.]]\n",
      "1048333  Evaluations Remaining\n",
      "rewards= -0.25017819671584185\n",
      "Timestep 2\tScore: 13.60\tmin: 13.60\tmax: 13.60actions= [[1. 1.]]\n",
      "1048332  Evaluations Remaining\n",
      "rewards= 0.14574667849485445\n",
      "Timestep 3\tScore: 13.75\tmin: 13.75\tmax: 13.75actions= [[1. 1.]]\n",
      "1048331  Evaluations Remaining\n",
      "rewards= -0.27041396482380753\n",
      "Episode 333\tScore: 13.48\tAverage Score: 14.82\n",
      "actions= [[0.         0.25312943]]\n",
      "1048330  Evaluations Remaining\n",
      "rewards= 16.21323066827514\n",
      "actions= [[1. 1.]]\n",
      "1048329  Evaluations Remaining\n",
      "rewards= -60.29147436412958\n",
      "Timestep 1\tScore: -44.08\tmin: -44.08\tmax: -44.08actions= [[1. 1.]]\n",
      "1048328  Evaluations Remaining\n",
      "rewards= 0.26072710833942025\n",
      "Timestep 2\tScore: -43.82\tmin: -43.82\tmax: -43.82actions= [[1. 1.]]\n",
      "1048327  Evaluations Remaining\n",
      "rewards= 0.25217662357637494\n",
      "Timestep 3\tScore: -43.57\tmin: -43.57\tmax: -43.57actions= [[1. 1.]]\n",
      "1048326  Evaluations Remaining\n",
      "rewards= 0.15928432561261685\n",
      "Episode 334\tScore: -43.41\tAverage Score: 3.18.41\n",
      "actions= [[1. 1.]]\n",
      "1048325  Evaluations Remaining\n",
      "rewards= 15.624506632047005\n",
      "actions= [[1. 1.]]\n",
      "1048324  Evaluations Remaining\n",
      "rewards= -0.010920974151742424\n",
      "Timestep 1\tScore: 15.61\tmin: 15.61\tmax: 15.61actions= [[1. 1.]]\n",
      "1048323  Evaluations Remaining\n",
      "rewards= -0.10246777471141622\n",
      "Timestep 2\tScore: 15.51\tmin: 15.51\tmax: 15.51actions= [[1. 1.]]\n",
      "1048322  Evaluations Remaining\n",
      "rewards= 0.13409181873994447\n",
      "Timestep 3\tScore: 15.65\tmin: 15.65\tmax: 15.65actions= [[1. 1.]]\n",
      "1048321  Evaluations Remaining\n",
      "rewards= -0.11144623926508412\n",
      "Episode 335\tScore: 15.53\tAverage Score: 3.003\n",
      "actions= [[1. 1.]]\n",
      "1048320  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 15.387084346087226\n",
      "actions= [[1. 1.]]\n",
      "1048319  Evaluations Remaining\n",
      "rewards= -0.2656535901011061\n",
      "Timestep 1\tScore: 15.12\tmin: 15.12\tmax: 15.12actions= [[1. 1.]]\n",
      "1048318  Evaluations Remaining\n",
      "rewards= 0.06976815694127714\n",
      "Timestep 2\tScore: 15.19\tmin: 15.19\tmax: 15.19actions= [[1. 1.]]\n",
      "1048317  Evaluations Remaining\n",
      "rewards= 0.21200477808004692\n",
      "Timestep 3\tScore: 15.40\tmin: 15.40\tmax: 15.40actions= [[1. 1.]]\n",
      "1048316  Evaluations Remaining\n",
      "rewards= 0.16712366795648093\n",
      "Episode 336\tScore: 15.57\tAverage Score: 3.407\n",
      "actions= [[1. 1.]]\n",
      "1048315  Evaluations Remaining\n",
      "rewards= 14.342894296066667\n",
      "actions= [[1. 1.]]\n",
      "1048314  Evaluations Remaining\n",
      "rewards= -0.01108606884363006\n",
      "Timestep 1\tScore: 14.33\tmin: 14.33\tmax: 14.33actions= [[1. 1.]]\n",
      "1048313  Evaluations Remaining\n",
      "rewards= -0.21980843982983478\n",
      "Timestep 2\tScore: 14.11\tmin: 14.11\tmax: 14.11actions= [[1. 1.]]\n",
      "1048312  Evaluations Remaining\n",
      "rewards= -0.16536244479805617\n",
      "Timestep 3\tScore: 13.95\tmin: 13.95\tmax: 13.95actions= [[1. 1.]]\n",
      "1048311  Evaluations Remaining\n",
      "rewards= -0.22327116468494745\n",
      "Episode 337\tScore: 13.72\tAverage Score: 2.982\n",
      "actions= [[1. 1.]]\n",
      "1048310  Evaluations Remaining\n",
      "rewards= 13.887315809056487\n",
      "actions= [[1. 1.]]\n",
      "1048309  Evaluations Remaining\n",
      "rewards= 0.2362283159889378\n",
      "Timestep 1\tScore: 14.12\tmin: 14.12\tmax: 14.12actions= [[1. 1.]]\n",
      "1048308  Evaluations Remaining\n",
      "rewards= 0.16333038039505876\n",
      "Timestep 2\tScore: 14.29\tmin: 14.29\tmax: 14.29actions= [[1. 1.]]\n",
      "1048307  Evaluations Remaining\n",
      "rewards= 0.12125616633447533\n",
      "Timestep 3\tScore: 14.41\tmin: 14.41\tmax: 14.41actions= [[1. 1.]]\n",
      "1048306  Evaluations Remaining\n",
      "rewards= 0.23100488606191938\n",
      "Episode 338\tScore: 14.64\tAverage Score: 3.214\n",
      "actions= [[1. 1.]]\n",
      "1048305  Evaluations Remaining\n",
      "rewards= 14.67118025637222\n",
      "actions= [[1. 1.]]\n",
      "1048304  Evaluations Remaining\n",
      "rewards= -0.028601718217898142\n",
      "Timestep 1\tScore: 14.64\tmin: 14.64\tmax: 14.64actions= [[1. 1.]]\n",
      "1048303  Evaluations Remaining\n",
      "rewards= -0.19752289884963314\n",
      "Timestep 2\tScore: 14.45\tmin: 14.45\tmax: 14.45actions= [[1. 1.]]\n",
      "1048302  Evaluations Remaining\n",
      "rewards= -0.028642793760546237\n",
      "Timestep 3\tScore: 14.42\tmin: 14.42\tmax: 14.42actions= [[1. 1.]]\n",
      "1048301  Evaluations Remaining\n",
      "rewards= 0.08209079793875595\n",
      "Episode 339\tScore: 14.50\tAverage Score: 14.79\n",
      "actions= [[1. 1.]]\n",
      "1048300  Evaluations Remaining\n",
      "rewards= 14.542264880749672\n",
      "actions= [[1. 1.]]\n",
      "1048299  Evaluations Remaining\n",
      "rewards= 0.22202629241812\n",
      "Timestep 1\tScore: 14.76\tmin: 14.76\tmax: 14.76actions= [[1. 1.]]\n",
      "1048298  Evaluations Remaining\n",
      "rewards= -0.16041804562951123\n",
      "Timestep 2\tScore: 14.60\tmin: 14.60\tmax: 14.60actions= [[1. 1.]]\n",
      "1048297  Evaluations Remaining\n",
      "rewards= -0.010143777446729452\n",
      "Timestep 3\tScore: 14.59\tmin: 14.59\tmax: 14.59actions= [[1. 1.]]\n",
      "1048296  Evaluations Remaining\n",
      "rewards= 0.1099739519269387\n",
      "Episode 340\tScore: 14.70\tAverage Score: 14.63\n",
      "actions= [[1. 1.]]\n",
      "1048295  Evaluations Remaining\n",
      "rewards= 15.377869317710463\n",
      "actions= [[1. 1.]]\n",
      "1048294  Evaluations Remaining\n",
      "rewards= 0.1594454116328019\n",
      "Timestep 1\tScore: 15.54\tmin: 15.54\tmax: 15.54actions= [[1. 1.]]\n",
      "1048293  Evaluations Remaining\n",
      "rewards= 0.1886065407757087\n",
      "Timestep 2\tScore: 15.73\tmin: 15.73\tmax: 15.73actions= [[1. 1.]]\n",
      "1048292  Evaluations Remaining\n",
      "rewards= -0.12718194683610706\n",
      "Timestep 3\tScore: 15.60\tmin: 15.60\tmax: 15.60actions= [[1. 1.]]\n",
      "1048291  Evaluations Remaining\n",
      "rewards= 0.11582760904044997\n",
      "Episode 341\tScore: 15.71\tAverage Score: 14.66\n",
      "actions= [[1. 1.]]\n",
      "1048290  Evaluations Remaining\n",
      "rewards= 14.348090055844823\n",
      "actions= [[1. 1.]]\n",
      "1048289  Evaluations Remaining\n",
      "rewards= 0.18900374114292617\n",
      "Timestep 1\tScore: 14.54\tmin: 14.54\tmax: 14.54actions= [[1. 1.]]\n",
      "1048288  Evaluations Remaining\n",
      "rewards= -0.21467374665627315\n",
      "Timestep 2\tScore: 14.32\tmin: 14.32\tmax: 14.32actions= [[1. 1.]]\n",
      "1048287  Evaluations Remaining\n",
      "rewards= 0.02191815921661311\n",
      "Timestep 3\tScore: 14.34\tmin: 14.34\tmax: 14.34actions= [[1. 1.]]\n",
      "1048286  Evaluations Remaining\n",
      "rewards= -0.10956923686857323\n",
      "Episode 342\tScore: 14.23\tAverage Score: 14.76\n",
      "actions= [[1. 1.]]\n",
      "1048285  Evaluations Remaining\n",
      "rewards= 15.636778293364925\n",
      "actions= [[1. 1.]]\n",
      "1048284  Evaluations Remaining\n",
      "rewards= -0.17260544225004892\n",
      "Timestep 1\tScore: 15.46\tmin: 15.46\tmax: 15.46actions= [[1. 1.]]\n",
      "1048283  Evaluations Remaining\n",
      "rewards= 0.018643651200751066\n",
      "Timestep 2\tScore: 15.48\tmin: 15.48\tmax: 15.48actions= [[1. 1.]]\n",
      "1048282  Evaluations Remaining\n",
      "rewards= 0.139125986377727\n",
      "Timestep 3\tScore: 15.62\tmin: 15.62\tmax: 15.62actions= [[1. 1.]]\n",
      "1048281  Evaluations Remaining\n",
      "rewards= 0.17020220597205293\n",
      "Episode 343\tScore: 15.79\tAverage Score: 14.99\n",
      "actions= [[1. 1.]]\n",
      "1048280  Evaluations Remaining\n",
      "rewards= 16.213671890589758\n",
      "actions= [[1. 1.]]\n",
      "1048279  Evaluations Remaining\n",
      "rewards= 0.2409051628686818\n",
      "Timestep 1\tScore: 16.45\tmin: 16.45\tmax: 16.45actions= [[1. 1.]]\n",
      "1048278  Evaluations Remaining\n",
      "rewards= 0.23776640709971852\n",
      "Timestep 2\tScore: 16.69\tmin: 16.69\tmax: 16.69actions= [[1. 1.]]\n",
      "1048277  Evaluations Remaining\n",
      "rewards= 0.16422364239792664\n",
      "Timestep 3\tScore: 16.86\tmin: 16.86\tmax: 16.86actions= [[1. 1.]]\n",
      "1048276  Evaluations Remaining\n",
      "rewards= 0.17204247217735835\n",
      "Episode 344\tScore: 17.03\tAverage Score: 15.49\n",
      "actions= [[1. 1.]]\n",
      "1048275  Evaluations Remaining\n",
      "rewards= 14.631059546973356\n",
      "actions= [[1. 1.]]\n",
      "1048274  Evaluations Remaining\n",
      "rewards= -0.043070731925034966\n",
      "Timestep 1\tScore: 14.59\tmin: 14.59\tmax: 14.59actions= [[1. 1.]]\n",
      "1048273  Evaluations Remaining\n",
      "rewards= -0.17241748411189217\n",
      "Timestep 2\tScore: 14.42\tmin: 14.42\tmax: 14.42actions= [[1. 1.]]\n",
      "1048272  Evaluations Remaining\n",
      "rewards= 0.1887778273142513\n",
      "Timestep 3\tScore: 14.60\tmin: 14.60\tmax: 14.60actions= [[1. 1.]]\n",
      "1048271  Evaluations Remaining\n",
      "rewards= 0.05559395478912643\n",
      "Episode 345\tScore: 14.66\tAverage Score: 15.49\n",
      "actions= [[1. 1.]]\n",
      "1048270  Evaluations Remaining\n",
      "rewards= 15.946779410210413\n",
      "actions= [[1. 1.]]\n",
      "1048269  Evaluations Remaining\n",
      "rewards= -0.042169306483494484\n",
      "Timestep 1\tScore: 15.90\tmin: 15.90\tmax: 15.90actions= [[1. 1.]]\n",
      "1048268  Evaluations Remaining\n",
      "rewards= 0.20987103192230494\n",
      "Timestep 2\tScore: 16.11\tmin: 16.11\tmax: 16.11actions= [[1. 1.]]\n",
      "1048267  Evaluations Remaining\n",
      "rewards= 0.12898866498067862\n",
      "Timestep 3\tScore: 16.24\tmin: 16.24\tmax: 16.24actions= [[1. 1.]]\n",
      "1048266  Evaluations Remaining\n",
      "rewards= -0.11508515045464573\n",
      "Episode 346\tScore: 16.13\tAverage Score: 15.57\n",
      "actions= [[1. 1.]]\n",
      "1048265  Evaluations Remaining\n",
      "rewards= 14.186956080685329\n",
      "actions= [[1. 1.]]\n",
      "1048264  Evaluations Remaining\n",
      "rewards= 0.028315736461312024\n",
      "Timestep 1\tScore: 14.22\tmin: 14.22\tmax: 14.22actions= [[1. 1.]]\n",
      "1048263  Evaluations Remaining\n",
      "rewards= 0.25855571048501025\n",
      "Timestep 2\tScore: 14.47\tmin: 14.47\tmax: 14.47actions= [[1. 1.]]\n",
      "1048262  Evaluations Remaining\n",
      "rewards= 0.014088742932230947\n",
      "Timestep 3\tScore: 14.49\tmin: 14.49\tmax: 14.49actions= [[1. 1.]]\n",
      "1048261  Evaluations Remaining\n",
      "rewards= 0.25371037605934665\n",
      "Episode 347\tScore: 14.74\tAverage Score: 15.67\n",
      "actions= [[0. 0.]]\n",
      "1048260  Evaluations Remaining\n",
      "rewards= 2.5924719124372055\n",
      "actions= [[1. 1.]]\n",
      "1048259  Evaluations Remaining\n",
      "rewards= 11.921032926454346\n",
      "Timestep 1\tScore: 14.51\tmin: 14.51\tmax: 14.51actions= [[1. 1.]]\n",
      "1048258  Evaluations Remaining\n",
      "rewards= 0.07400917456950706\n",
      "Timestep 2\tScore: 14.59\tmin: 14.59\tmax: 14.59actions= [[1. 1.]]\n",
      "1048257  Evaluations Remaining\n",
      "rewards= -0.013308729368461947\n",
      "Timestep 3\tScore: 14.57\tmin: 14.57\tmax: 14.57actions= [[1. 1.]]\n",
      "1048256  Evaluations Remaining\n",
      "rewards= 0.13345570371513382\n",
      "Episode 348\tScore: 14.71\tAverage Score: 15.45\n",
      "actions= [[1. 1.]]\n",
      "1048255  Evaluations Remaining\n",
      "rewards= 14.801392175275934\n",
      "actions= [[1. 1.]]\n",
      "1048254  Evaluations Remaining\n",
      "rewards= 0.04781139695078718\n",
      "Timestep 1\tScore: 14.85\tmin: 14.85\tmax: 14.85actions= [[1. 1.]]\n",
      "1048253  Evaluations Remaining\n",
      "rewards= -0.17713674366570853\n",
      "Timestep 2\tScore: 14.67\tmin: 14.67\tmax: 14.67actions= [[1. 1.]]\n",
      "1048252  Evaluations Remaining\n",
      "rewards= -0.17637414827111098\n",
      "Timestep 3\tScore: 14.50\tmin: 14.50\tmax: 14.50actions= [[1. 1.]]\n",
      "1048251  Evaluations Remaining\n",
      "rewards= 0.26094804912895864\n",
      "Episode 349\tScore: 14.76\tAverage Score: 15.00\n",
      "actions= [[1. 1.]]\n",
      "1048250  Evaluations Remaining\n",
      "rewards= 13.972225890699645\n",
      "actions= [[1. 1.]]\n",
      "1048249  Evaluations Remaining\n",
      "rewards= -0.09718522865821422\n",
      "Timestep 1\tScore: 13.88\tmin: 13.88\tmax: 13.88actions= [[1. 1.]]\n",
      "1048248  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 0.04197852581637296\n",
      "Timestep 2\tScore: 13.92\tmin: 13.92\tmax: 13.92actions= [[1. 1.]]\n",
      "1048247  Evaluations Remaining\n",
      "rewards= 0.2600778998526736\n",
      "Timestep 3\tScore: 14.18\tmin: 14.18\tmax: 14.18actions= [[0. 0.]]\n",
      "1048246  Evaluations Remaining\n",
      "rewards= -0.19932124700654796\n",
      "Episode 350\tScore: 13.98\tAverage Score: 14.86\n",
      "actions= [[1. 1.]]\n",
      "1048245  Evaluations Remaining\n",
      "rewards= 15.89788283862311\n",
      "actions= [[1. 1.]]\n",
      "1048244  Evaluations Remaining\n",
      "rewards= 0.21448391449387394\n",
      "Timestep 1\tScore: 16.11\tmin: 16.11\tmax: 16.11actions= [[1. 1.]]\n",
      "1048243  Evaluations Remaining\n",
      "rewards= 0.04680549572452941\n",
      "Timestep 2\tScore: 16.16\tmin: 16.16\tmax: 16.16actions= [[1. 1.]]\n",
      "1048242  Evaluations Remaining\n",
      "rewards= 0.19832186030357724\n",
      "Timestep 3\tScore: 16.36\tmin: 16.36\tmax: 16.36actions= [[1. 1.]]\n",
      "1048241  Evaluations Remaining\n",
      "rewards= -0.05975720373677973\n",
      "Episode 351\tScore: 16.30\tAverage Score: 14.90\n",
      "actions= [[1. 1.]]\n",
      "1048240  Evaluations Remaining\n",
      "rewards= 16.09315948557947\n",
      "actions= [[1. 1.]]\n",
      "1048239  Evaluations Remaining\n",
      "rewards= -0.23397504151330661\n",
      "Timestep 1\tScore: 15.86\tmin: 15.86\tmax: 15.86actions= [[1. 1.]]\n",
      "1048238  Evaluations Remaining\n",
      "rewards= -0.24528289207743148\n",
      "Timestep 2\tScore: 15.61\tmin: 15.61\tmax: 15.61actions= [[1. 1.]]\n",
      "1048237  Evaluations Remaining\n",
      "rewards= -0.2275487763400994\n",
      "Timestep 3\tScore: 15.39\tmin: 15.39\tmax: 15.39actions= [[1. 1.]]\n",
      "1048236  Evaluations Remaining\n",
      "rewards= 0.25644923414128495\n",
      "Episode 352\tScore: 15.64\tAverage Score: 15.08\n",
      "actions= [[1. 1.]]\n",
      "1048235  Evaluations Remaining\n",
      "rewards= 15.928011514488821\n",
      "actions= [[1. 1.]]\n",
      "1048234  Evaluations Remaining\n",
      "rewards= -0.008632061632611432\n",
      "Timestep 1\tScore: 15.92\tmin: 15.92\tmax: 15.92actions= [[1. 1.]]\n",
      "1048233  Evaluations Remaining\n",
      "rewards= -0.24039201141719113\n",
      "Timestep 2\tScore: 15.68\tmin: 15.68\tmax: 15.68actions= [[1. 1.]]\n",
      "1048232  Evaluations Remaining\n",
      "rewards= 0.0035700914842689002\n",
      "Timestep 3\tScore: 15.68\tmin: 15.68\tmax: 15.68actions= [[1. 1.]]\n",
      "1048231  Evaluations Remaining\n",
      "rewards= 0.19182808625201409\n",
      "Episode 353\tScore: 15.87\tAverage Score: 15.31\n",
      "actions= [[1. 1.]]\n",
      "1048230  Evaluations Remaining\n",
      "rewards= 15.50329496828676\n",
      "actions= [[1. 1.]]\n",
      "1048229  Evaluations Remaining\n",
      "rewards= 0.11347140526073529\n",
      "Timestep 1\tScore: 15.62\tmin: 15.62\tmax: 15.62actions= [[1. 1.]]\n",
      "1048228  Evaluations Remaining\n",
      "rewards= -0.19601757405544618\n",
      "Timestep 2\tScore: 15.42\tmin: 15.42\tmax: 15.42actions= [[1. 1.]]\n",
      "1048227  Evaluations Remaining\n",
      "rewards= 0.03608547974677068\n",
      "Timestep 3\tScore: 15.46\tmin: 15.46\tmax: 15.46actions= [[1. 1.]]\n",
      "1048226  Evaluations Remaining\n",
      "rewards= 0.1108292856791242\n",
      "Episode 354\tScore: 15.57\tAverage Score: 15.47\n",
      "actions= [[1. 1.]]\n",
      "1048225  Evaluations Remaining\n",
      "rewards= 15.041378207638443\n",
      "actions= [[1. 1.]]\n",
      "1048224  Evaluations Remaining\n",
      "rewards= 0.16988601106111734\n",
      "Timestep 1\tScore: 15.21\tmin: 15.21\tmax: 15.21actions= [[1. 1.]]\n",
      "1048223  Evaluations Remaining\n",
      "rewards= -0.2271706791610013\n",
      "Timestep 2\tScore: 14.98\tmin: 14.98\tmax: 14.98actions= [[1. 1.]]\n",
      "1048222  Evaluations Remaining\n",
      "rewards= 0.08116399831980514\n",
      "Timestep 3\tScore: 15.07\tmin: 15.07\tmax: 15.07actions= [[1. 1.]]\n",
      "1048221  Evaluations Remaining\n",
      "rewards= 0.1964743943244831\n",
      "Episode 355\tScore: 15.26\tAverage Score: 15.73\n",
      "actions= [[1. 1.]]\n",
      "1048220  Evaluations Remaining\n",
      "rewards= 14.45002305345163\n",
      "actions= [[1. 1.]]\n",
      "1048219  Evaluations Remaining\n",
      "rewards= 0.04733431335893856\n",
      "Timestep 1\tScore: 14.50\tmin: 14.50\tmax: 14.50actions= [[1. 1.]]\n",
      "1048218  Evaluations Remaining\n",
      "rewards= -0.12800358279213064\n",
      "Timestep 2\tScore: 14.37\tmin: 14.37\tmax: 14.37actions= [[1. 1.]]\n",
      "1048217  Evaluations Remaining\n",
      "rewards= -0.16467694959673285\n",
      "Timestep 3\tScore: 14.20\tmin: 14.20\tmax: 14.20actions= [[1. 1.]]\n",
      "1048216  Evaluations Remaining\n",
      "rewards= -0.19182809869674733\n",
      "Episode 356\tScore: 14.01\tAverage Score: 15.27\n",
      "actions= [[1. 1.]]\n",
      "1048215  Evaluations Remaining\n",
      "rewards= 14.86266189979843\n",
      "actions= [[1. 1.]]\n",
      "1048214  Evaluations Remaining\n",
      "rewards= -0.24245221504264203\n",
      "Timestep 1\tScore: 14.62\tmin: 14.62\tmax: 14.62actions= [[1. 1.]]\n",
      "1048213  Evaluations Remaining\n",
      "rewards= 0.12933501103403122\n",
      "Timestep 2\tScore: 14.75\tmin: 14.75\tmax: 14.75actions= [[1. 1.]]\n",
      "1048212  Evaluations Remaining\n",
      "rewards= -0.04595806860675555\n",
      "Timestep 3\tScore: 14.70\tmin: 14.70\tmax: 14.70actions= [[1. 1.]]\n",
      "1048211  Evaluations Remaining\n",
      "rewards= -0.18115848350359665\n",
      "Episode 357\tScore: 14.52\tAverage Score: 15.05\n",
      "actions= [[1. 1.]]\n",
      "1048210  Evaluations Remaining\n",
      "rewards= 14.781414934082894\n",
      "actions= [[1. 1.]]\n",
      "1048209  Evaluations Remaining\n",
      "rewards= 0.17991495864671636\n",
      "Timestep 1\tScore: 14.96\tmin: 14.96\tmax: 14.96actions= [[1. 1.]]\n",
      "1048208  Evaluations Remaining\n",
      "rewards= -0.13536590456096853\n",
      "Timestep 2\tScore: 14.83\tmin: 14.83\tmax: 14.83actions= [[1. 1.]]\n",
      "1048207  Evaluations Remaining\n",
      "rewards= 0.25228000119081484\n",
      "Timestep 3\tScore: 15.08\tmin: 15.08\tmax: 15.08actions= [[1. 1.]]\n",
      "1048206  Evaluations Remaining\n",
      "rewards= -0.20847447393127005\n",
      "Episode 358\tScore: 14.87\tAverage Score: 14.85\n",
      "actions= [[1. 1.]]\n",
      "1048205  Evaluations Remaining\n",
      "rewards= 15.194565713794045\n",
      "actions= [[1. 1.]]\n",
      "1048204  Evaluations Remaining\n",
      "rewards= 0.2643634667622443\n",
      "Timestep 1\tScore: 15.46\tmin: 15.46\tmax: 15.46actions= [[1. 1.]]\n",
      "1048203  Evaluations Remaining\n",
      "rewards= -0.26665895371729276\n",
      "Timestep 2\tScore: 15.19\tmin: 15.19\tmax: 15.19actions= [[1. 1.]]\n",
      "1048202  Evaluations Remaining\n",
      "rewards= -0.18481704258820386\n",
      "Timestep 3\tScore: 15.01\tmin: 15.01\tmax: 15.01actions= [[1. 1.]]\n",
      "1048201  Evaluations Remaining\n",
      "rewards= 0.04178442248376513\n",
      "Episode 359\tScore: 15.05\tAverage Score: 14.74\n",
      "actions= [[1. 1.]]\n",
      "1048200  Evaluations Remaining\n",
      "rewards= 13.49310142570273\n",
      "actions= [[1. 1.]]\n",
      "1048199  Evaluations Remaining\n",
      "rewards= 0.2708370702030205\n",
      "Timestep 1\tScore: 13.76\tmin: 13.76\tmax: 13.76actions= [[1. 1.]]\n",
      "1048198  Evaluations Remaining\n",
      "rewards= -0.15187657007571698\n",
      "Timestep 2\tScore: 13.61\tmin: 13.61\tmax: 13.61actions= [[1. 1.]]\n",
      "1048197  Evaluations Remaining\n",
      "rewards= -0.06591539429252702\n",
      "Timestep 3\tScore: 13.55\tmin: 13.55\tmax: 13.55actions= [[1. 1.]]\n",
      "1048196  Evaluations Remaining\n",
      "rewards= 0.049525876610980735\n",
      "Episode 360\tScore: 13.60\tAverage Score: 14.41\n",
      "actions= [[1. 1.]]\n",
      "1048195  Evaluations Remaining\n",
      "rewards= 15.88624877973592\n",
      "actions= [[1. 1.]]\n",
      "1048194  Evaluations Remaining\n",
      "rewards= 0.16706083829646046\n",
      "Timestep 1\tScore: 16.05\tmin: 16.05\tmax: 16.05actions= [[1. 1.]]\n",
      "1048193  Evaluations Remaining\n",
      "rewards= -0.14891973364337252\n",
      "Timestep 2\tScore: 15.90\tmin: 15.90\tmax: 15.90actions= [[1. 1.]]\n",
      "1048192  Evaluations Remaining\n",
      "rewards= -0.11865781185413082\n",
      "Timestep 3\tScore: 15.79\tmin: 15.79\tmax: 15.79actions= [[1. 1.]]\n",
      "1048191  Evaluations Remaining\n",
      "rewards= -0.13641084637103296\n",
      "Episode 361\tScore: 15.65\tAverage Score: 14.74\n",
      "actions= [[1. 1.]]\n",
      "1048190  Evaluations Remaining\n",
      "rewards= 16.221267166535476\n",
      "actions= [[1. 1.]]\n",
      "1048189  Evaluations Remaining\n",
      "rewards= -0.18090543546128268\n",
      "Timestep 1\tScore: 16.04\tmin: 16.04\tmax: 16.04actions= [[1. 1.]]\n",
      "1048188  Evaluations Remaining\n",
      "rewards= 0.2146192202845678\n",
      "Timestep 2\tScore: 16.25\tmin: 16.25\tmax: 16.25actions= [[1. 1.]]\n",
      "1048187  Evaluations Remaining\n",
      "rewards= 0.0880744604318413\n",
      "Timestep 3\tScore: 16.34\tmin: 16.34\tmax: 16.34actions= [[1. 1.]]\n",
      "1048186  Evaluations Remaining\n",
      "rewards= -0.22029420193457971\n",
      "Episode 362\tScore: 16.12\tAverage Score: 15.06\n",
      "actions= [[1. 1.]]\n",
      "1048185  Evaluations Remaining\n",
      "rewards= 14.146372811019022\n",
      "actions= [[1. 1.]]\n",
      "1048184  Evaluations Remaining\n",
      "rewards= 0.26817630548079796\n",
      "Timestep 1\tScore: 14.41\tmin: 14.41\tmax: 14.41actions= [[1. 1.]]\n",
      "1048183  Evaluations Remaining\n",
      "rewards= 0.012971791130513388\n",
      "Timestep 2\tScore: 14.43\tmin: 14.43\tmax: 14.43actions= [[1. 1.]]\n",
      "1048182  Evaluations Remaining\n",
      "rewards= 0.026970795942763637\n",
      "Timestep 3\tScore: 14.45\tmin: 14.45\tmax: 14.45actions= [[1. 1.]]\n",
      "1048181  Evaluations Remaining\n",
      "rewards= -0.1704768650930233\n",
      "Episode 363\tScore: 14.28\tAverage Score: 14.94\n",
      "actions= [[1. 1.]]\n",
      "1048180  Evaluations Remaining\n",
      "rewards= 13.93296556950066\n",
      "actions= [[1. 1.]]\n",
      "1048179  Evaluations Remaining\n",
      "rewards= -0.01723833806905839\n",
      "Timestep 1\tScore: 13.92\tmin: 13.92\tmax: 13.92actions= [[1. 1.]]\n",
      "1048178  Evaluations Remaining\n",
      "rewards= -0.07264976361230424\n",
      "Timestep 2\tScore: 13.84\tmin: 13.84\tmax: 13.84actions= [[1. 1.]]\n",
      "1048177  Evaluations Remaining\n",
      "rewards= -0.07880821576476116\n",
      "Timestep 3\tScore: 13.76\tmin: 13.76\tmax: 13.76actions= [[1. 1.]]\n",
      "1048176  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 0.19832975985002088\n",
      "Episode 364\tScore: 13.96\tAverage Score: 14.72\n",
      "actions= [[1. 1.]]\n",
      "1048175  Evaluations Remaining\n",
      "rewards= 15.928179312632217\n",
      "actions= [[1. 1.]]\n",
      "1048174  Evaluations Remaining\n",
      "rewards= 0.17070490623657308\n",
      "Timestep 1\tScore: 16.10\tmin: 16.10\tmax: 16.10actions= [[1. 1.]]\n",
      "1048173  Evaluations Remaining\n",
      "rewards= -0.09968402583490876\n",
      "Timestep 2\tScore: 16.00\tmin: 16.00\tmax: 16.00actions= [[1. 1.]]\n",
      "1048172  Evaluations Remaining\n",
      "rewards= 0.03994939459756486\n",
      "Timestep 3\tScore: 16.04\tmin: 16.04\tmax: 16.04actions= [[1. 1.]]\n",
      "1048171  Evaluations Remaining\n",
      "rewards= 0.19726989304083142\n",
      "Episode 365\tScore: 16.24\tAverage Score: 15.25\n",
      "actions= [[1. 1.]]\n",
      "1048170  Evaluations Remaining\n",
      "rewards= 15.10199620698752\n",
      "actions= [[1. 1.]]\n",
      "1048169  Evaluations Remaining\n",
      "rewards= -0.13456268263055815\n",
      "Timestep 1\tScore: 14.97\tmin: 14.97\tmax: 14.97actions= [[1. 1.]]\n",
      "1048168  Evaluations Remaining\n",
      "rewards= -0.010264800925554596\n",
      "Timestep 2\tScore: 14.96\tmin: 14.96\tmax: 14.96actions= [[1. 1.]]\n",
      "1048167  Evaluations Remaining\n",
      "rewards= -0.016444972474161546\n",
      "Timestep 3\tScore: 14.94\tmin: 14.94\tmax: 14.94actions= [[0. 0.]]\n",
      "1048166  Evaluations Remaining\n",
      "rewards= -0.04787432553907811\n",
      "Episode 366\tScore: 14.89\tAverage Score: 15.10\n",
      "actions= [[1. 1.]]\n",
      "1048165  Evaluations Remaining\n",
      "rewards= 14.532340435706814\n",
      "actions= [[1. 1.]]\n",
      "1048164  Evaluations Remaining\n",
      "rewards= -0.1254195792844457\n",
      "Timestep 1\tScore: 14.41\tmin: 14.41\tmax: 14.41actions= [[1. 1.]]\n",
      "1048163  Evaluations Remaining\n",
      "rewards= -0.23933033793680947\n",
      "Timestep 2\tScore: 14.17\tmin: 14.17\tmax: 14.17actions= [[1. 1.]]\n",
      "1048162  Evaluations Remaining\n",
      "rewards= -0.22309219026766813\n",
      "Timestep 3\tScore: 13.94\tmin: 13.94\tmax: 13.94actions= [[1. 1.]]\n",
      "1048161  Evaluations Remaining\n",
      "rewards= 0.06889428804369535\n",
      "Episode 367\tScore: 14.01\tAverage Score: 14.68\n",
      "actions= [[1. 1.]]\n",
      "1048160  Evaluations Remaining\n",
      "rewards= 15.14442492213932\n",
      "actions= [[1. 1.]]\n",
      "1048159  Evaluations Remaining\n",
      "rewards= -0.1806759015903343\n",
      "Timestep 1\tScore: 14.96\tmin: 14.96\tmax: 14.96actions= [[1. 1.]]\n",
      "1048158  Evaluations Remaining\n",
      "rewards= -0.06376888326638142\n",
      "Timestep 2\tScore: 14.90\tmin: 14.90\tmax: 14.90actions= [[1. 1.]]\n",
      "1048157  Evaluations Remaining\n",
      "rewards= 0.2219272852305103\n",
      "Timestep 3\tScore: 15.12\tmin: 15.12\tmax: 15.12actions= [[1. 1.]]\n",
      "1048156  Evaluations Remaining\n",
      "rewards= -0.2570408783309519\n",
      "Episode 368\tScore: 14.86\tAverage Score: 14.79\n",
      "actions= [[1. 1.]]\n",
      "1048155  Evaluations Remaining\n",
      "rewards= 15.402660098799693\n",
      "actions= [[1. 1.]]\n",
      "1048154  Evaluations Remaining\n",
      "rewards= 0.10050161574359606\n",
      "Timestep 1\tScore: 15.50\tmin: 15.50\tmax: 15.50actions= [[1. 1.]]\n",
      "1048153  Evaluations Remaining\n",
      "rewards= 0.13786258175567934\n",
      "Timestep 2\tScore: 15.64\tmin: 15.64\tmax: 15.64actions= [[1. 1.]]\n",
      "1048152  Evaluations Remaining\n",
      "rewards= -0.21137289418510585\n",
      "Timestep 3\tScore: 15.43\tmin: 15.43\tmax: 15.43actions= [[1. 1.]]\n",
      "1048151  Evaluations Remaining\n",
      "rewards= -0.05970329734182611\n",
      "Episode 369\tScore: 15.37\tAverage Score: 15.08\n",
      "actions= [[1. 1.]]\n",
      "1048150  Evaluations Remaining\n",
      "rewards= 14.871649473501215\n",
      "actions= [[1. 1.]]\n",
      "1048149  Evaluations Remaining\n",
      "rewards= -0.14874898115119617\n",
      "Timestep 1\tScore: 14.72\tmin: 14.72\tmax: 14.72actions= [[1. 1.]]\n",
      "1048148  Evaluations Remaining\n",
      "rewards= 0.08182867636124236\n",
      "Timestep 2\tScore: 14.80\tmin: 14.80\tmax: 14.80actions= [[1. 1.]]\n",
      "1048147  Evaluations Remaining\n",
      "rewards= 0.25281829981660664\n",
      "Timestep 3\tScore: 15.06\tmin: 15.06\tmax: 15.06actions= [[1. 1.]]\n",
      "1048146  Evaluations Remaining\n",
      "rewards= 0.14698905186498745\n",
      "Episode 370\tScore: 15.20\tAverage Score: 14.87\n",
      "actions= [[1. 1.]]\n",
      "1048145  Evaluations Remaining\n",
      "rewards= 16.2222717091561\n",
      "actions= [[1. 1.]]\n",
      "1048144  Evaluations Remaining\n",
      "rewards= -0.021774000849085873\n",
      "Timestep 1\tScore: 16.20\tmin: 16.20\tmax: 16.20actions= [[1. 1.]]\n",
      "1048143  Evaluations Remaining\n",
      "rewards= -0.10812707780551412\n",
      "Timestep 2\tScore: 16.09\tmin: 16.09\tmax: 16.09actions= [[1. 1.]]\n",
      "1048142  Evaluations Remaining\n",
      "rewards= -0.2655591411112015\n",
      "Timestep 3\tScore: 15.83\tmin: 15.83\tmax: 15.83actions= [[1. 1.]]\n",
      "1048141  Evaluations Remaining\n",
      "rewards= 0.025793713796229856\n",
      "Episode 371\tScore: 15.85\tAverage Score: 15.06\n",
      "actions= [[1. 1.]]\n",
      "1048140  Evaluations Remaining\n",
      "rewards= 16.126675373514445\n",
      "actions= [[1. 1.]]\n",
      "1048139  Evaluations Remaining\n",
      "rewards= 0.19033247928009178\n",
      "Timestep 1\tScore: 16.32\tmin: 16.32\tmax: 16.32actions= [[1. 1.]]\n",
      "1048138  Evaluations Remaining\n",
      "rewards= -0.17234235219638938\n",
      "Timestep 2\tScore: 16.14\tmin: 16.14\tmax: 16.14actions= [[1. 1.]]\n",
      "1048137  Evaluations Remaining\n",
      "rewards= -0.2709640588083153\n",
      "Timestep 3\tScore: 15.87\tmin: 15.87\tmax: 15.87actions= [[1. 1.]]\n",
      "1048136  Evaluations Remaining\n",
      "rewards= -0.07274172288405722\n",
      "Episode 372\tScore: 15.80\tAverage Score: 15.42\n",
      "actions= [[1. 1.]]\n",
      "1048135  Evaluations Remaining\n",
      "rewards= 14.90207003682739\n",
      "actions= [[1. 1.]]\n",
      "1048134  Evaluations Remaining\n",
      "rewards= 0.20974895477997002\n",
      "Timestep 1\tScore: 15.11\tmin: 15.11\tmax: 15.11actions= [[1. 1.]]\n",
      "1048133  Evaluations Remaining\n",
      "rewards= -0.13920285766318008\n",
      "Timestep 2\tScore: 14.97\tmin: 14.97\tmax: 14.97actions= [[1. 1.]]\n",
      "1048132  Evaluations Remaining\n",
      "rewards= -0.003396388847985321\n",
      "Timestep 3\tScore: 14.97\tmin: 14.97\tmax: 14.97actions= [[1. 1.]]\n",
      "1048131  Evaluations Remaining\n",
      "rewards= 0.11975332695890195\n",
      "Episode 373\tScore: 15.09\tAverage Score: 15.46\n",
      "actions= [[1. 1.]]\n",
      "1048130  Evaluations Remaining\n",
      "rewards= 15.746628868253737\n",
      "actions= [[1. 1.]]\n",
      "1048129  Evaluations Remaining\n",
      "rewards= -0.06447275774515582\n",
      "Timestep 1\tScore: 15.68\tmin: 15.68\tmax: 15.68actions= [[1. 1.]]\n",
      "1048128  Evaluations Remaining\n",
      "rewards= -0.04104107936971646\n",
      "Timestep 2\tScore: 15.64\tmin: 15.64\tmax: 15.64actions= [[1. 1.]]\n",
      "1048127  Evaluations Remaining\n",
      "rewards= -0.08150639179357233\n",
      "Timestep 3\tScore: 15.56\tmin: 15.56\tmax: 15.56actions= [[1. 1.]]\n",
      "1048126  Evaluations Remaining\n",
      "rewards= 0.17517957237428528\n",
      "Episode 374\tScore: 15.73\tAverage Score: 15.54\n",
      "actions= [[1. 1.]]\n",
      "1048125  Evaluations Remaining\n",
      "rewards= 13.536833922508013\n",
      "actions= [[1. 1.]]\n",
      "1048124  Evaluations Remaining\n",
      "rewards= -0.2288691329897623\n",
      "Timestep 1\tScore: 13.31\tmin: 13.31\tmax: 13.31actions= [[1. 1.]]\n",
      "1048123  Evaluations Remaining\n",
      "rewards= 0.07671759704362735\n",
      "Timestep 2\tScore: 13.38\tmin: 13.38\tmax: 13.38actions= [[1. 1.]]\n",
      "1048122  Evaluations Remaining\n",
      "rewards= -0.1365869342090864\n",
      "Timestep 3\tScore: 13.25\tmin: 13.25\tmax: 13.25actions= [[1. 1.]]\n",
      "1048121  Evaluations Remaining\n",
      "rewards= -0.24151230972839866\n",
      "Episode 375\tScore: 13.01\tAverage Score: 15.10\n",
      "actions= [[1. 1.]]\n",
      "1048120  Evaluations Remaining\n",
      "rewards= 14.62729834131734\n",
      "actions= [[1. 1.]]\n",
      "1048119  Evaluations Remaining\n",
      "rewards= 0.21802715320494848\n",
      "Timestep 1\tScore: 14.85\tmin: 14.85\tmax: 14.85actions= [[1. 1.]]\n",
      "1048118  Evaluations Remaining\n",
      "rewards= -0.0811286121685395\n",
      "Timestep 2\tScore: 14.76\tmin: 14.76\tmax: 14.76actions= [[1. 1.]]\n",
      "1048117  Evaluations Remaining\n",
      "rewards= 0.06582652676975442\n",
      "Timestep 3\tScore: 14.83\tmin: 14.83\tmax: 14.83actions= [[1. 1.]]\n",
      "1048116  Evaluations Remaining\n",
      "rewards= 0.21975687554651957\n",
      "Episode 376\tScore: 15.05\tAverage Score: 14.94\n",
      "actions= [[1. 1.]]\n",
      "1048115  Evaluations Remaining\n",
      "rewards= 15.934340132958901\n",
      "actions= [[1. 1.]]\n",
      "1048114  Evaluations Remaining\n",
      "rewards= 0.02458508651019331\n",
      "Timestep 1\tScore: 15.96\tmin: 15.96\tmax: 15.96actions= [[1. 1.]]\n",
      "1048113  Evaluations Remaining\n",
      "rewards= -0.08270533298456728\n",
      "Timestep 2\tScore: 15.88\tmin: 15.88\tmax: 15.88actions= [[1. 1.]]\n",
      "1048112  Evaluations Remaining\n",
      "rewards= -0.2449675959946327\n",
      "Timestep 3\tScore: 15.63\tmin: 15.63\tmax: 15.63actions= [[1. 1.]]\n",
      "1048111  Evaluations Remaining\n",
      "rewards= -0.22134162776000066\n",
      "Episode 377\tScore: 15.41\tAverage Score: 14.86\n",
      "actions= [[1. 1.]]\n",
      "1048110  Evaluations Remaining\n",
      "rewards= 15.0685896801802\n",
      "actions= [[1. 1.]]\n",
      "1048109  Evaluations Remaining\n",
      "rewards= -0.1500799339564196\n",
      "Timestep 1\tScore: 14.92\tmin: 14.92\tmax: 14.92actions= [[1. 1.]]\n",
      "1048108  Evaluations Remaining\n",
      "rewards= -0.22697414504701818\n",
      "Timestep 2\tScore: 14.69\tmin: 14.69\tmax: 14.69actions= [[1. 1.]]\n",
      "1048107  Evaluations Remaining\n",
      "rewards= 0.1898955494943806\n",
      "Timestep 3\tScore: 14.88\tmin: 14.88\tmax: 14.88actions= [[1. 1.]]\n",
      "1048106  Evaluations Remaining\n",
      "rewards= 0.15214813909460823\n",
      "Episode 378\tScore: 15.03\tAverage Score: 14.85\n",
      "actions= [[1. 1.]]\n",
      "1048105  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 15.722346610554014\n",
      "actions= [[1. 1.]]\n",
      "1048104  Evaluations Remaining\n",
      "rewards= -0.2053020949829656\n",
      "Timestep 1\tScore: 15.52\tmin: 15.52\tmax: 15.52actions= [[1. 1.]]\n",
      "1048103  Evaluations Remaining\n",
      "rewards= 0.05246250685967624\n",
      "Timestep 2\tScore: 15.57\tmin: 15.57\tmax: 15.57actions= [[1. 1.]]\n",
      "1048102  Evaluations Remaining\n",
      "rewards= 0.12648302959762603\n",
      "Timestep 3\tScore: 15.70\tmin: 15.70\tmax: 15.70actions= [[1. 1.]]\n",
      "1048101  Evaluations Remaining\n",
      "rewards= 0.18696663190398155\n",
      "Episode 379\tScore: 15.88\tAverage Score: 14.88\n",
      "actions= [[1. 1.]]\n",
      "1048100  Evaluations Remaining\n",
      "rewards= 14.451277304758024\n",
      "actions= [[1. 1.]]\n",
      "1048099  Evaluations Remaining\n",
      "rewards= -0.20724211599658826\n",
      "Timestep 1\tScore: 14.24\tmin: 14.24\tmax: 14.24actions= [[1. 1.]]\n",
      "1048098  Evaluations Remaining\n",
      "rewards= -0.1492042128982618\n",
      "Timestep 2\tScore: 14.09\tmin: 14.09\tmax: 14.09actions= [[1. 1.]]\n",
      "1048097  Evaluations Remaining\n",
      "rewards= -0.14542418623898445\n",
      "Timestep 3\tScore: 13.95\tmin: 13.95\tmax: 13.95actions= [[1. 1.]]\n",
      "1048096  Evaluations Remaining\n",
      "rewards= -0.029690894359077014\n",
      "Episode 380\tScore: 13.92\tAverage Score: 15.06\n",
      "actions= [[1. 1.]]\n",
      "1048095  Evaluations Remaining\n",
      "rewards= 14.720736532647184\n",
      "actions= [[1. 1.]]\n",
      "1048094  Evaluations Remaining\n",
      "rewards= 0.25745769857600687\n",
      "Timestep 1\tScore: 14.98\tmin: 14.98\tmax: 14.98actions= [[1. 1.]]\n",
      "1048093  Evaluations Remaining\n",
      "rewards= -0.2545011499520351\n",
      "Timestep 2\tScore: 14.72\tmin: 14.72\tmax: 14.72actions= [[1. 1.]]\n",
      "1048092  Evaluations Remaining\n",
      "rewards= 0.010398121040621877\n",
      "Timestep 3\tScore: 14.73\tmin: 14.73\tmax: 14.73actions= [[1. 1.]]\n",
      "1048091  Evaluations Remaining\n",
      "rewards= 0.21254768911152944\n",
      "Episode 381\tScore: 14.95\tAverage Score: 15.04\n",
      "actions= [[1. 1.]]\n",
      "1048090  Evaluations Remaining\n",
      "rewards= 15.2858308253074\n",
      "actions= [[1. 1.]]\n",
      "1048089  Evaluations Remaining\n",
      "rewards= 0.22010187599378161\n",
      "Timestep 1\tScore: 15.51\tmin: 15.51\tmax: 15.51actions= [[1. 1.]]\n",
      "1048088  Evaluations Remaining\n",
      "rewards= -0.142010647967882\n",
      "Timestep 2\tScore: 15.36\tmin: 15.36\tmax: 15.36actions= [[1. 1.]]\n",
      "1048087  Evaluations Remaining\n",
      "rewards= 0.06510089580024792\n",
      "Timestep 3\tScore: 15.43\tmin: 15.43\tmax: 15.43actions= [[1. 1.]]\n",
      "1048086  Evaluations Remaining\n",
      "rewards= -0.120718483736169\n",
      "Episode 382\tScore: 15.31\tAverage Score: 15.02\n",
      "actions= [[1. 1.]]\n",
      "1048085  Evaluations Remaining\n",
      "rewards= 13.680612247394157\n",
      "actions= [[1. 1.]]\n",
      "1048084  Evaluations Remaining\n",
      "rewards= -0.07058452593737252\n",
      "Timestep 1\tScore: 13.61\tmin: 13.61\tmax: 13.61actions= [[1. 1.]]\n",
      "1048083  Evaluations Remaining\n",
      "rewards= 0.26715422427425395\n",
      "Timestep 2\tScore: 13.88\tmin: 13.88\tmax: 13.88actions= [[1. 1.]]\n",
      "1048082  Evaluations Remaining\n",
      "rewards= -0.025087193955664944\n",
      "Timestep 3\tScore: 13.85\tmin: 13.85\tmax: 13.85actions= [[1. 1.]]\n",
      "1048081  Evaluations Remaining\n",
      "rewards= -0.23415137022917465\n",
      "Episode 383\tScore: 13.62\tAverage Score: 14.74\n",
      "actions= [[1. 1.]]\n",
      "1048080  Evaluations Remaining\n",
      "rewards= 13.525533893587623\n",
      "actions= [[1. 1.]]\n",
      "1048079  Evaluations Remaining\n",
      "rewards= 0.004381747531256419\n",
      "Timestep 1\tScore: 13.53\tmin: 13.53\tmax: 13.53actions= [[1. 1.]]\n",
      "1048078  Evaluations Remaining\n",
      "rewards= -0.2527856452371635\n",
      "Timestep 2\tScore: 13.28\tmin: 13.28\tmax: 13.28actions= [[1. 1.]]\n",
      "1048077  Evaluations Remaining\n",
      "rewards= -0.012795828830957756\n",
      "Timestep 3\tScore: 13.26\tmin: 13.26\tmax: 13.26actions= [[1. 1.]]\n",
      "1048076  Evaluations Remaining\n",
      "rewards= -0.1096871991559274\n",
      "Episode 384\tScore: 13.15\tAverage Score: 14.19\n",
      "actions= [[1. 1.]]\n",
      "1048075  Evaluations Remaining\n",
      "rewards= 16.011255431147596\n",
      "actions= [[1. 1.]]\n",
      "1048074  Evaluations Remaining\n",
      "rewards= -0.05198598567819035\n",
      "Timestep 1\tScore: 15.96\tmin: 15.96\tmax: 15.96actions= [[1. 1.]]\n",
      "1048073  Evaluations Remaining\n",
      "rewards= 0.24288434270284087\n",
      "Timestep 2\tScore: 16.20\tmin: 16.20\tmax: 16.20actions= [[1. 1.]]\n",
      "1048072  Evaluations Remaining\n",
      "rewards= -0.2077991566431785\n",
      "Timestep 3\tScore: 15.99\tmin: 15.99\tmax: 15.99actions= [[1. 1.]]\n",
      "1048071  Evaluations Remaining\n",
      "rewards= -0.1953743400418566\n",
      "Episode 385\tScore: 15.80\tAverage Score: 14.57\n",
      "actions= [[1. 1.]]\n",
      "1048070  Evaluations Remaining\n",
      "rewards= 15.16301124356592\n",
      "actions= [[1. 1.]]\n",
      "1048069  Evaluations Remaining\n",
      "rewards= -0.1402885687153579\n",
      "Timestep 1\tScore: 15.02\tmin: 15.02\tmax: 15.02actions= [[1. 1.]]\n",
      "1048068  Evaluations Remaining\n",
      "rewards= 0.2026220757613708\n",
      "Timestep 2\tScore: 15.23\tmin: 15.23\tmax: 15.23actions= [[0. 0.]]\n",
      "1048067  Evaluations Remaining\n",
      "rewards= -0.22318751981182228\n",
      "Timestep 3\tScore: 15.00\tmin: 15.00\tmax: 15.00actions= [[1. 1.]]\n",
      "1048066  Evaluations Remaining\n",
      "rewards= 11.495792325225935\n",
      "Episode 386\tScore: 26.50\tAverage Score: 16.88\n",
      "actions= [[1. 1.]]\n",
      "1048065  Evaluations Remaining\n",
      "rewards= 13.891786409565256\n",
      "actions= [[1. 1.]]\n",
      "1048064  Evaluations Remaining\n",
      "rewards= 0.19745228282535354\n",
      "Timestep 1\tScore: 14.09\tmin: 14.09\tmax: 14.09actions= [[1. 1.]]\n",
      "1048063  Evaluations Remaining\n",
      "rewards= 0.16985942028574774\n",
      "Timestep 2\tScore: 14.26\tmin: 14.26\tmax: 14.26actions= [[1. 1.]]\n",
      "1048062  Evaluations Remaining\n",
      "rewards= 0.24295687307583247\n",
      "Timestep 3\tScore: 14.50\tmin: 14.50\tmax: 14.50actions= [[1. 1.]]\n",
      "1048061  Evaluations Remaining\n",
      "rewards= 0.03690583179441642\n",
      "Episode 387\tScore: 14.54\tAverage Score: 16.72\n",
      "actions= [[1. 1.]]\n",
      "1048060  Evaluations Remaining\n",
      "rewards= 15.947549792126305\n",
      "actions= [[1. 1.]]\n",
      "1048059  Evaluations Remaining\n",
      "rewards= -0.0365406226595546\n",
      "Timestep 1\tScore: 15.91\tmin: 15.91\tmax: 15.91actions= [[1. 1.]]\n",
      "1048058  Evaluations Remaining\n",
      "rewards= 0.16742110808341337\n",
      "Timestep 2\tScore: 16.08\tmin: 16.08\tmax: 16.08actions= [[1. 1.]]\n",
      "1048057  Evaluations Remaining\n",
      "rewards= 0.26169007485843165\n",
      "Timestep 3\tScore: 16.34\tmin: 16.34\tmax: 16.34actions= [[1. 1.]]\n",
      "1048056  Evaluations Remaining\n",
      "rewards= -0.20715647311415752\n",
      "Episode 388\tScore: 16.13\tAverage Score: 17.22\n",
      "actions= [[1. 1.]]\n",
      "1048055  Evaluations Remaining\n",
      "rewards= 14.242985148668204\n",
      "actions= [[1. 1.]]\n",
      "1048054  Evaluations Remaining\n",
      "rewards= -0.018736060716759262\n",
      "Timestep 1\tScore: 14.22\tmin: 14.22\tmax: 14.22actions= [[1. 1.]]\n",
      "1048053  Evaluations Remaining\n",
      "rewards= 0.13090402390388745\n",
      "Timestep 2\tScore: 14.36\tmin: 14.36\tmax: 14.36actions= [[1. 1.]]\n",
      "1048052  Evaluations Remaining\n",
      "rewards= 0.19146703424738432\n",
      "Timestep 3\tScore: 14.55\tmin: 14.55\tmax: 14.55actions= [[1. 1.]]\n",
      "1048051  Evaluations Remaining\n",
      "rewards= -0.17959502285129814\n",
      "Episode 389\tScore: 14.37\tAverage Score: 17.47\n",
      "actions= [[1. 1.]]\n",
      "1048050  Evaluations Remaining\n",
      "rewards= 16.16320030817574\n",
      "actions= [[1. 1.]]\n",
      "1048049  Evaluations Remaining\n",
      "rewards= 0.14404517710112286\n",
      "Timestep 1\tScore: 16.31\tmin: 16.31\tmax: 16.31actions= [[0. 0.]]\n",
      "1048048  Evaluations Remaining\n",
      "rewards= -0.03002237284222886\n",
      "Timestep 2\tScore: 16.28\tmin: 16.28\tmax: 16.28actions= [[1. 1.]]\n",
      "1048047  Evaluations Remaining\n",
      "rewards= 12.974456182316544\n",
      "Timestep 3\tScore: 29.25\tmin: 29.25\tmax: 29.25actions= [[1. 1.]]\n",
      "1048046  Evaluations Remaining\n",
      "rewards= 0.023964878205065432\n",
      "Episode 390\tScore: 29.28\tAverage Score: 20.16\n",
      "actions= [[1. 1.]]\n",
      "1048045  Evaluations Remaining\n",
      "rewards= 15.218134766834075\n",
      "actions= [[1. 1.]]\n",
      "1048044  Evaluations Remaining\n",
      "rewards= 0.15015130298160262\n",
      "Timestep 1\tScore: 15.37\tmin: 15.37\tmax: 15.37actions= [[1. 1.]]\n",
      "1048043  Evaluations Remaining\n",
      "rewards= 0.228853610192306\n",
      "Timestep 2\tScore: 15.60\tmin: 15.60\tmax: 15.60actions= [[1. 1.]]\n",
      "1048042  Evaluations Remaining\n",
      "rewards= -0.19845308928954397\n",
      "Timestep 3\tScore: 15.40\tmin: 15.40\tmax: 15.40actions= [[1. 1.]]\n",
      "1048041  Evaluations Remaining\n",
      "rewards= -0.23698191618556885\n",
      "Episode 391\tScore: 15.16\tAverage Score: 17.90\n",
      "actions= [[1. 1.]]\n",
      "1048040  Evaluations Remaining\n",
      "rewards= 16.3216804749578\n",
      "actions= [[1. 1.]]\n",
      "1048039  Evaluations Remaining\n",
      "rewards= -0.025288457799470532\n",
      "Timestep 1\tScore: 16.30\tmin: 16.30\tmax: 16.30actions= [[1. 1.]]\n",
      "1048038  Evaluations Remaining\n",
      "rewards= 0.06973520051066995\n",
      "Timestep 2\tScore: 16.37\tmin: 16.37\tmax: 16.37actions= [[1. 1.]]\n",
      "1048037  Evaluations Remaining\n",
      "rewards= 0.2474293404209642\n",
      "Timestep 3\tScore: 16.61\tmin: 16.61\tmax: 16.61actions= [[1. 1.]]\n",
      "1048036  Evaluations Remaining\n",
      "rewards= 0.14251517802021185\n",
      "Episode 392\tScore: 16.76\tAverage Score: 18.34\n",
      "actions= [[1. 1.]]\n",
      "1048035  Evaluations Remaining\n",
      "rewards= 14.9792011490983\n",
      "actions= [[1. 1.]]\n",
      "1048034  Evaluations Remaining\n",
      "rewards= 0.015593809915494639\n",
      "Timestep 1\tScore: 14.99\tmin: 14.99\tmax: 14.99actions= [[1. 1.]]\n",
      "1048033  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 0.017816920315345097\n",
      "Timestep 2\tScore: 15.01\tmin: 15.01\tmax: 15.01actions= [[1. 1.]]\n",
      "1048032  Evaluations Remaining\n",
      "rewards= 0.10462979286320939\n",
      "Timestep 3\tScore: 15.12\tmin: 15.12\tmax: 15.12actions= [[1. 1.]]\n",
      "1048031  Evaluations Remaining\n",
      "rewards= 0.015342396030074035\n",
      "Episode 393\tScore: 15.13\tAverage Score: 18.14\n",
      "actions= [[1. 1.]]\n",
      "1048030  Evaluations Remaining\n",
      "rewards= 16.353856047517812\n",
      "actions= [[1. 1.]]\n",
      "1048029  Evaluations Remaining\n",
      "rewards= -0.1591031981953539\n",
      "Timestep 1\tScore: 16.19\tmin: 16.19\tmax: 16.19actions= [[1. 1.]]\n",
      "1048028  Evaluations Remaining\n",
      "rewards= 0.09948521392753396\n",
      "Timestep 2\tScore: 16.29\tmin: 16.29\tmax: 16.29actions= [[1. 1.]]\n",
      "1048027  Evaluations Remaining\n",
      "rewards= 0.15748184907555274\n",
      "Timestep 3\tScore: 16.45\tmin: 16.45\tmax: 16.45actions= [[1. 1.]]\n",
      "1048026  Evaluations Remaining\n",
      "rewards= -0.2592961731472472\n",
      "Episode 394\tScore: 16.19\tAverage Score: 18.50\n",
      "actions= [[1. 1.]]\n",
      "1048025  Evaluations Remaining\n",
      "rewards= 14.756953517316001\n",
      "actions= [[1. 1.]]\n",
      "1048024  Evaluations Remaining\n",
      "rewards= -0.26356124759535504\n",
      "Timestep 1\tScore: 14.49\tmin: 14.49\tmax: 14.49actions= [[1. 1.]]\n",
      "1048023  Evaluations Remaining\n",
      "rewards= 0.14763105681425692\n",
      "Timestep 2\tScore: 14.64\tmin: 14.64\tmax: 14.64actions= [[1. 1.]]\n",
      "1048022  Evaluations Remaining\n",
      "rewards= 0.024540101226305122\n",
      "Timestep 3\tScore: 14.67\tmin: 14.67\tmax: 14.67actions= [[1. 1.]]\n",
      "1048021  Evaluations Remaining\n",
      "rewards= -0.22041169816874007\n",
      "Episode 395\tScore: 14.45\tAverage Score: 15.54\n",
      "actions= [[1. 1.]]\n",
      "1048020  Evaluations Remaining\n",
      "rewards= 14.011565040798658\n",
      "actions= [[1. 1.]]\n",
      "1048019  Evaluations Remaining\n",
      "rewards= -0.22043163476462757\n",
      "Timestep 1\tScore: 13.79\tmin: 13.79\tmax: 13.79actions= [[1. 1.]]\n",
      "1048018  Evaluations Remaining\n",
      "rewards= -0.18233641930366762\n",
      "Timestep 2\tScore: 13.61\tmin: 13.61\tmax: 13.61actions= [[1. 1.]]\n",
      "1048017  Evaluations Remaining\n",
      "rewards= -0.05012960345397088\n",
      "Timestep 3\tScore: 13.56\tmin: 13.56\tmax: 13.56actions= [[1. 1.]]\n",
      "1048016  Evaluations Remaining\n",
      "rewards= 0.02442850119338047\n",
      "Episode 396\tScore: 13.58\tAverage Score: 15.22\n",
      "actions= [[1. 1.]]\n",
      "1048015  Evaluations Remaining\n",
      "rewards= 15.975007508706078\n",
      "actions= [[1. 1.]]\n",
      "1048014  Evaluations Remaining\n",
      "rewards= 0.2124431728511782\n",
      "Timestep 1\tScore: 16.19\tmin: 16.19\tmax: 16.19actions= [[1. 1.]]\n",
      "1048013  Evaluations Remaining\n",
      "rewards= 0.031176645773092204\n",
      "Timestep 2\tScore: 16.22\tmin: 16.22\tmax: 16.22actions= [[1. 1.]]\n",
      "1048012  Evaluations Remaining\n",
      "rewards= -0.18965169031932394\n",
      "Timestep 3\tScore: 16.03\tmin: 16.03\tmax: 16.03actions= [[1. 1.]]\n",
      "1048011  Evaluations Remaining\n",
      "rewards= -0.1552681629143513\n",
      "Episode 397\tScore: 15.87\tAverage Score: 15.05\n",
      "actions= [[1. 1.]]\n",
      "1048010  Evaluations Remaining\n",
      "rewards= 14.887634374130597\n",
      "actions= [[1. 1.]]\n",
      "1048009  Evaluations Remaining\n",
      "rewards= 0.21377226899359725\n",
      "Timestep 1\tScore: 15.10\tmin: 15.10\tmax: 15.10actions= [[1. 1.]]\n",
      "1048008  Evaluations Remaining\n",
      "rewards= -0.1971551637200446\n",
      "Timestep 2\tScore: 14.90\tmin: 14.90\tmax: 14.90actions= [[1. 1.]]\n",
      "1048007  Evaluations Remaining\n",
      "rewards= -0.23593534559556995\n",
      "Timestep 3\tScore: 14.67\tmin: 14.67\tmax: 14.67actions= [[1. 1.]]\n",
      "1048006  Evaluations Remaining\n",
      "rewards= -0.10768848006255238\n",
      "Episode 398\tScore: 14.56\tAverage Score: 14.93\n",
      "actions= [[1. 1.]]\n",
      "1048005  Evaluations Remaining\n",
      "rewards= 16.154190915726865\n",
      "actions= [[1. 1.]]\n",
      "1048004  Evaluations Remaining\n",
      "rewards= -0.22836023629583435\n",
      "Timestep 1\tScore: 15.93\tmin: 15.93\tmax: 15.93actions= [[1. 1.]]\n",
      "1048003  Evaluations Remaining\n",
      "rewards= -0.14581592590579318\n",
      "Timestep 2\tScore: 15.78\tmin: 15.78\tmax: 15.78actions= [[1. 1.]]\n",
      "1048002  Evaluations Remaining\n",
      "rewards= 0.056465171822964955\n",
      "Timestep 3\tScore: 15.84\tmin: 15.84\tmax: 15.84actions= [[1. 1.]]\n",
      "1048001  Evaluations Remaining\n",
      "rewards= -0.12081817824962648\n",
      "Episode 399\tScore: 15.72\tAverage Score: 14.84\n",
      "actions= [[1. 1.]]\n",
      "1048000  Evaluations Remaining\n",
      "rewards= 14.283212920793092\n",
      "actions= [[1. 1.]]\n",
      "1047999  Evaluations Remaining\n",
      "rewards= -0.1700125518227238\n",
      "Timestep 1\tScore: 14.11\tmin: 14.11\tmax: 14.11actions= [[1. 1.]]\n",
      "1047998  Evaluations Remaining\n",
      "rewards= -0.0014195298043668814\n",
      "Timestep 2\tScore: 14.11\tmin: 14.11\tmax: 14.11actions= [[1. 1.]]\n",
      "1047997  Evaluations Remaining\n",
      "rewards= -0.22671378581633883\n",
      "Timestep 3\tScore: 13.89\tmin: 13.89\tmax: 13.89actions= [[1. 1.]]\n",
      "1047996  Evaluations Remaining\n",
      "rewards= -0.23952588517554085\n",
      "Episode 400\tScore: 13.65\tAverage Score: 14.68\n",
      "Episode 400\tAverage Score: 14.68\n",
      "actions= [[1. 1.]]\n",
      "1047995  Evaluations Remaining\n",
      "rewards= 14.973448191016894\n",
      "actions= [[1. 1.]]\n",
      "1047994  Evaluations Remaining\n",
      "rewards= 0.16151327235884416\n",
      "Timestep 1\tScore: 15.13\tmin: 15.13\tmax: 15.13actions= [[1. 1.]]\n",
      "1047993  Evaluations Remaining\n",
      "rewards= -0.049886071295122125\n",
      "Timestep 2\tScore: 15.09\tmin: 15.09\tmax: 15.09actions= [[1. 1.]]\n",
      "1047992  Evaluations Remaining\n",
      "rewards= 0.17700452979771875\n",
      "Timestep 3\tScore: 15.26\tmin: 15.26\tmax: 15.26actions= [[1. 1.]]\n",
      "1047991  Evaluations Remaining\n",
      "rewards= 0.2516039655557285\n",
      "Episode 401\tScore: 15.51\tAverage Score: 15.06\n",
      "actions= [[1. 1.]]\n",
      "1047990  Evaluations Remaining\n",
      "rewards= 15.902632910714752\n",
      "actions= [[1. 1.]]\n",
      "1047989  Evaluations Remaining\n",
      "rewards= -0.08702024108554074\n",
      "Timestep 1\tScore: 15.82\tmin: 15.82\tmax: 15.82actions= [[1. 1.]]\n",
      "1047988  Evaluations Remaining\n",
      "rewards= -0.2681313036163657\n",
      "Timestep 2\tScore: 15.55\tmin: 15.55\tmax: 15.55actions= [[1. 1.]]\n",
      "1047987  Evaluations Remaining\n",
      "rewards= 0.19157135612875864\n",
      "Timestep 3\tScore: 15.74\tmin: 15.74\tmax: 15.74actions= [[1. 1.]]\n",
      "1047986  Evaluations Remaining\n",
      "rewards= 0.005874894330545111\n",
      "Episode 402\tScore: 15.74\tAverage Score: 15.04\n",
      "actions= [[1. 1.]]\n",
      "1047985  Evaluations Remaining\n",
      "rewards= 13.528813589301164\n",
      "actions= [[1. 1.]]\n",
      "1047984  Evaluations Remaining\n",
      "rewards= -0.026385481069386874\n",
      "Timestep 1\tScore: 13.50\tmin: 13.50\tmax: 13.50actions= [[1. 1.]]\n",
      "1047983  Evaluations Remaining\n",
      "rewards= -0.05870825752486031\n",
      "Timestep 2\tScore: 13.44\tmin: 13.44\tmax: 13.44actions= [[1. 1.]]\n",
      "1047982  Evaluations Remaining\n",
      "rewards= 0.03258490584319329\n",
      "Timestep 3\tScore: 13.48\tmin: 13.48\tmax: 13.48actions= [[1. 1.]]\n",
      "1047981  Evaluations Remaining\n",
      "rewards= 0.048342738963035536\n",
      "Episode 403\tScore: 13.52\tAverage Score: 14.83\n",
      "actions= [[1. 1.]]\n",
      "1047980  Evaluations Remaining\n",
      "rewards= 16.302390726451595\n",
      "actions= [[1. 1.]]\n",
      "1047979  Evaluations Remaining\n",
      "rewards= 0.269745363374025\n",
      "Timestep 1\tScore: 16.57\tmin: 16.57\tmax: 16.57actions= [[1. 1.]]\n",
      "1047978  Evaluations Remaining\n",
      "rewards= 0.200585900064294\n",
      "Timestep 2\tScore: 16.77\tmin: 16.77\tmax: 16.77actions= [[1. 1.]]\n",
      "1047977  Evaluations Remaining\n",
      "rewards= -0.22272949544446252\n",
      "Timestep 3\tScore: 16.55\tmin: 16.55\tmax: 16.55actions= [[1. 1.]]\n",
      "1047976  Evaluations Remaining\n",
      "rewards= -0.19884432115748263\n",
      "Episode 404\tScore: 16.35\tAverage Score: 14.96\n",
      "actions= [[1. 1.]]\n",
      "1047975  Evaluations Remaining\n",
      "rewards= 13.568826583331843\n",
      "actions= [[1. 1.]]\n",
      "1047974  Evaluations Remaining\n",
      "rewards= -0.2669694092719004\n",
      "Timestep 1\tScore: 13.30\tmin: 13.30\tmax: 13.30actions= [[1. 1.]]\n",
      "1047973  Evaluations Remaining\n",
      "rewards= -0.18879077000608202\n",
      "Timestep 2\tScore: 13.11\tmin: 13.11\tmax: 13.11actions= [[1. 1.]]\n",
      "1047972  Evaluations Remaining\n",
      "rewards= 0.24579349076381662\n",
      "Timestep 3\tScore: 13.36\tmin: 13.36\tmax: 13.36actions= [[1. 1.]]\n",
      "1047971  Evaluations Remaining\n",
      "rewards= 0.1060086793313566\n",
      "Episode 405\tScore: 13.46\tAverage Score: 14.92\n",
      "actions= [[1. 1.]]\n",
      "1047970  Evaluations Remaining\n",
      "rewards= 13.70293601792936\n",
      "actions= [[1. 1.]]\n",
      "1047969  Evaluations Remaining\n",
      "rewards= -0.21484387186081522\n",
      "Timestep 1\tScore: 13.49\tmin: 13.49\tmax: 13.49actions= [[1. 1.]]\n",
      "1047968  Evaluations Remaining\n",
      "rewards= -0.2513604537972749\n",
      "Timestep 2\tScore: 13.24\tmin: 13.24\tmax: 13.24actions= [[1. 1.]]\n",
      "1047967  Evaluations Remaining\n",
      "rewards= -0.21949902919406128\n",
      "Timestep 3\tScore: 13.02\tmin: 13.02\tmax: 13.02actions= [[1. 1.]]\n",
      "1047966  Evaluations Remaining\n",
      "rewards= 0.2010461666997121\n",
      "Episode 406\tScore: 13.22\tAverage Score: 14.46\n",
      "actions= [[1. 1.]]\n",
      "1047965  Evaluations Remaining\n",
      "rewards= 14.142442990449592\n",
      "actions= [[1. 1.]]\n",
      "1047964  Evaluations Remaining\n",
      "rewards= -0.26464990210977435\n",
      "Timestep 1\tScore: 13.88\tmin: 13.88\tmax: 13.88actions= [[1. 1.]]\n",
      "1047963  Evaluations Remaining\n",
      "rewards= -0.023547821684641868\n",
      "Timestep 2\tScore: 13.85\tmin: 13.85\tmax: 13.85actions= [[1. 1.]]\n",
      "1047962  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 0.17325335162988864\n",
      "Timestep 3\tScore: 14.03\tmin: 14.03\tmax: 14.03actions= [[1. 1.]]\n",
      "1047961  Evaluations Remaining\n",
      "rewards= -0.16495919745350607\n",
      "Episode 407\tScore: 13.86\tAverage Score: 14.08\n",
      "actions= [[1. 1.]]\n",
      "1047960  Evaluations Remaining\n",
      "rewards= 14.625286105316228\n",
      "actions= [[1. 1.]]\n",
      "1047959  Evaluations Remaining\n",
      "rewards= 0.25896393513145144\n",
      "Timestep 1\tScore: 14.88\tmin: 14.88\tmax: 14.88actions= [[1. 1.]]\n",
      "1047958  Evaluations Remaining\n",
      "rewards= 0.2108852233719105\n",
      "Timestep 2\tScore: 15.10\tmin: 15.10\tmax: 15.10actions= [[1. 1.]]\n",
      "1047957  Evaluations Remaining\n",
      "rewards= 0.13690060920267433\n",
      "Timestep 3\tScore: 15.23\tmin: 15.23\tmax: 15.23actions= [[1. 1.]]\n",
      "1047956  Evaluations Remaining\n",
      "rewards= -0.21032663561219023\n",
      "Episode 408\tScore: 15.02\tAverage Score: 14.38\n",
      "actions= [[1. 1.]]\n",
      "1047955  Evaluations Remaining\n",
      "rewards= 14.989584277334247\n",
      "actions= [[1. 1.]]\n",
      "1047954  Evaluations Remaining\n",
      "rewards= -0.26551637412122187\n",
      "Timestep 1\tScore: 14.72\tmin: 14.72\tmax: 14.72actions= [[1. 1.]]\n",
      "1047953  Evaluations Remaining\n",
      "rewards= 0.20997648976359917\n",
      "Timestep 2\tScore: 14.93\tmin: 14.93\tmax: 14.93actions= [[1. 1.]]\n",
      "1047952  Evaluations Remaining\n",
      "rewards= -0.10707301803220526\n",
      "Timestep 3\tScore: 14.83\tmin: 14.83\tmax: 14.83actions= [[1. 1.]]\n",
      "1047951  Evaluations Remaining\n",
      "rewards= 0.06623080409956827\n",
      "Episode 409\tScore: 14.89\tAverage Score: 14.09\n",
      "actions= [[1. 1.]]\n",
      "1047950  Evaluations Remaining\n",
      "rewards= 14.132643305769108\n",
      "actions= [[1. 1.]]\n",
      "1047949  Evaluations Remaining\n",
      "rewards= 0.06660500021515237\n",
      "Timestep 1\tScore: 14.20\tmin: 14.20\tmax: 14.20actions= [[1. 1.]]\n",
      "1047948  Evaluations Remaining\n",
      "rewards= -0.16061254342648335\n",
      "Timestep 2\tScore: 14.04\tmin: 14.04\tmax: 14.04actions= [[1. 1.]]\n",
      "1047947  Evaluations Remaining\n",
      "rewards= -0.0037641290948151607\n",
      "Timestep 3\tScore: 14.03\tmin: 14.03\tmax: 14.03actions= [[1. 1.]]\n",
      "1047946  Evaluations Remaining\n",
      "rewards= 0.13793243911524877\n",
      "Episode 410\tScore: 14.17\tAverage Score: 14.23\n",
      "actions= [[1. 1.]]\n",
      "1047945  Evaluations Remaining\n",
      "rewards= 14.10899556081378\n",
      "actions= [[1. 1.]]\n",
      "1047944  Evaluations Remaining\n",
      "rewards= -0.16661655452727242\n",
      "Timestep 1\tScore: 13.94\tmin: 13.94\tmax: 13.94actions= [[1. 1.]]\n",
      "1047943  Evaluations Remaining\n",
      "rewards= -0.12621786634839838\n",
      "Timestep 2\tScore: 13.82\tmin: 13.82\tmax: 13.82actions= [[1. 1.]]\n",
      "1047942  Evaluations Remaining\n",
      "rewards= -0.13760297786573306\n",
      "Timestep 3\tScore: 13.68\tmin: 13.68\tmax: 13.68actions= [[1. 1.]]\n",
      "1047941  Evaluations Remaining\n",
      "rewards= 0.17901102778257183\n",
      "Episode 411\tScore: 13.86\tAverage Score: 14.36\n",
      "actions= [[1. 1.]]\n",
      "1047940  Evaluations Remaining\n",
      "rewards= 13.839487708122704\n",
      "actions= [[1. 1.]]\n",
      "1047939  Evaluations Remaining\n",
      "rewards= -0.21723416265599127\n",
      "Timestep 1\tScore: 13.62\tmin: 13.62\tmax: 13.62actions= [[1. 1.]]\n",
      "1047938  Evaluations Remaining\n",
      "rewards= 0.012453845533194396\n",
      "Timestep 2\tScore: 13.63\tmin: 13.63\tmax: 13.63actions= [[1. 1.]]\n",
      "1047937  Evaluations Remaining\n",
      "rewards= -0.013789844066199208\n",
      "Timestep 3\tScore: 13.62\tmin: 13.62\tmax: 13.62actions= [[1. 1.]]\n",
      "1047936  Evaluations Remaining\n",
      "rewards= 0.03880187544664393\n",
      "Episode 412\tScore: 13.66\tAverage Score: 14.32\n",
      "actions= [[1. 1.]]\n",
      "1047935  Evaluations Remaining\n",
      "rewards= 14.620022788719503\n",
      "actions= [[1. 1.]]\n",
      "1047934  Evaluations Remaining\n",
      "rewards= -0.05412508553544981\n",
      "Timestep 1\tScore: 14.57\tmin: 14.57\tmax: 14.57actions= [[1. 1.]]\n",
      "1047933  Evaluations Remaining\n",
      "rewards= -0.17767505346531687\n",
      "Timestep 2\tScore: 14.39\tmin: 14.39\tmax: 14.39actions= [[1. 1.]]\n",
      "1047932  Evaluations Remaining\n",
      "rewards= 0.13234014170627262\n",
      "Timestep 3\tScore: 14.52\tmin: 14.52\tmax: 14.52actions= [[1. 1.]]\n",
      "1047931  Evaluations Remaining\n",
      "rewards= -0.19270930294553512\n",
      "Episode 413\tScore: 14.33\tAverage Score: 14.18\n",
      "actions= [[1. 1.]]\n",
      "1047930  Evaluations Remaining\n",
      "rewards= 16.416017743870306\n",
      "actions= [[1. 1.]]\n",
      "1047929  Evaluations Remaining\n",
      "rewards= 0.22509661667116942\n",
      "Timestep 1\tScore: 16.64\tmin: 16.64\tmax: 16.64actions= [[1. 1.]]\n",
      "1047928  Evaluations Remaining\n",
      "rewards= -0.008546048099901782\n",
      "Timestep 2\tScore: 16.63\tmin: 16.63\tmax: 16.63actions= [[1. 1.]]\n",
      "1047927  Evaluations Remaining\n",
      "rewards= -0.029980418237175677\n",
      "Timestep 3\tScore: 16.60\tmin: 16.60\tmax: 16.60actions= [[1. 1.]]\n",
      "1047926  Evaluations Remaining\n",
      "rewards= 0.21785083687402995\n",
      "Episode 414\tScore: 16.82\tAverage Score: 14.57\n",
      "actions= [[1. 1.]]\n",
      "1047925  Evaluations Remaining\n",
      "rewards= 15.678333695242218\n",
      "actions= [[1. 1.]]\n",
      "1047924  Evaluations Remaining\n",
      "rewards= 0.17241237728042158\n",
      "Timestep 1\tScore: 15.85\tmin: 15.85\tmax: 15.85actions= [[1. 1.]]\n",
      "1047923  Evaluations Remaining\n",
      "rewards= 0.04842907940321739\n",
      "Timestep 2\tScore: 15.90\tmin: 15.90\tmax: 15.90actions= [[1. 1.]]\n",
      "1047922  Evaluations Remaining\n",
      "rewards= 0.26236769017494455\n",
      "Timestep 3\tScore: 16.16\tmin: 16.16\tmax: 16.16actions= [[1. 1.]]\n",
      "1047921  Evaluations Remaining\n",
      "rewards= 0.023783582028175765\n",
      "Episode 415\tScore: 16.19\tAverage Score: 14.97\n",
      "actions= [[1. 1.]]\n",
      "1047920  Evaluations Remaining\n",
      "rewards= 14.94738992051676\n",
      "actions= [[1. 1.]]\n",
      "1047919  Evaluations Remaining\n",
      "rewards= 0.07366638606164244\n",
      "Timestep 1\tScore: 15.02\tmin: 15.02\tmax: 15.02actions= [[1. 1.]]\n",
      "1047918  Evaluations Remaining\n",
      "rewards= -0.26586287365209404\n",
      "Timestep 2\tScore: 14.76\tmin: 14.76\tmax: 14.76actions= [[1. 1.]]\n",
      "1047917  Evaluations Remaining\n",
      "rewards= -0.1522551795044471\n",
      "Timestep 3\tScore: 14.60\tmin: 14.60\tmax: 14.60actions= [[1. 1.]]\n",
      "1047916  Evaluations Remaining\n",
      "rewards= -0.2607939952608169\n",
      "Episode 416\tScore: 14.34\tAverage Score: 15.07\n",
      "actions= [[1. 1.]]\n",
      "1047915  Evaluations Remaining\n",
      "rewards= 14.136401095318547\n",
      "actions= [[1. 1.]]\n",
      "1047914  Evaluations Remaining\n",
      "rewards= 0.037404058802264384\n",
      "Timestep 1\tScore: 14.17\tmin: 14.17\tmax: 14.17actions= [[1. 1.]]\n",
      "1047913  Evaluations Remaining\n",
      "rewards= -0.06845086507527132\n",
      "Timestep 2\tScore: 14.11\tmin: 14.11\tmax: 14.11actions= [[1. 1.]]\n",
      "1047912  Evaluations Remaining\n",
      "rewards= -0.17160413811991537\n",
      "Timestep 3\tScore: 13.93\tmin: 13.93\tmax: 13.93actions= [[1. 1.]]\n",
      "1047911  Evaluations Remaining\n",
      "rewards= 0.17819576862697328\n",
      "Episode 417\tScore: 14.11\tAverage Score: 15.16\n",
      "actions= [[1. 1.]]\n",
      "1047910  Evaluations Remaining\n",
      "rewards= 14.782103314422056\n",
      "actions= [[1. 1.]]\n",
      "1047909  Evaluations Remaining\n",
      "rewards= 0.22574644490633888\n",
      "Timestep 1\tScore: 15.01\tmin: 15.01\tmax: 15.01actions= [[1. 1.]]\n",
      "1047908  Evaluations Remaining\n",
      "rewards= 0.17317117889391742\n",
      "Timestep 2\tScore: 15.18\tmin: 15.18\tmax: 15.18actions= [[1. 1.]]\n",
      "1047907  Evaluations Remaining\n",
      "rewards= -0.06013217772628332\n",
      "Timestep 3\tScore: 15.12\tmin: 15.12\tmax: 15.12actions= [[1. 1.]]\n",
      "1047906  Evaluations Remaining\n",
      "rewards= -0.2162973879250738\n",
      "Episode 418\tScore: 14.90\tAverage Score: 15.27\n",
      "actions= [[1. 1.]]\n",
      "1047905  Evaluations Remaining\n",
      "rewards= 15.655974626313823\n",
      "actions= [[1. 1.]]\n",
      "1047904  Evaluations Remaining\n",
      "rewards= -0.23617436403220537\n",
      "Timestep 1\tScore: 15.42\tmin: 15.42\tmax: 15.42actions= [[1. 1.]]\n",
      "1047903  Evaluations Remaining\n",
      "rewards= 0.023515689770015946\n",
      "Timestep 2\tScore: 15.44\tmin: 15.44\tmax: 15.44actions= [[1. 1.]]\n",
      "1047902  Evaluations Remaining\n",
      "rewards= -0.12951599081513976\n",
      "Timestep 3\tScore: 15.31\tmin: 15.31\tmax: 15.31actions= [[1. 1.]]\n",
      "1047901  Evaluations Remaining\n",
      "rewards= -0.0565732036826585\n",
      "Episode 419\tScore: 15.26\tAverage Score: 14.96\n",
      "actions= [[1. 1.]]\n",
      "1047900  Evaluations Remaining\n",
      "rewards= 16.381985298448207\n",
      "actions= [[1. 1.]]\n",
      "1047899  Evaluations Remaining\n",
      "rewards= -0.11383982561116923\n",
      "Timestep 1\tScore: 16.27\tmin: 16.27\tmax: 16.27actions= [[1. 1.]]\n",
      "1047898  Evaluations Remaining\n",
      "rewards= -0.21852698616155397\n",
      "Timestep 2\tScore: 16.05\tmin: 16.05\tmax: 16.05actions= [[1. 1.]]\n",
      "1047897  Evaluations Remaining\n",
      "rewards= -0.1853168931138356\n",
      "Timestep 3\tScore: 15.86\tmin: 15.86\tmax: 15.86actions= [[1. 1.]]\n",
      "1047896  Evaluations Remaining\n",
      "rewards= 0.2665313058717125\n",
      "Episode 420\tScore: 16.13\tAverage Score: 14.95\n",
      "actions= [[1. 1.]]\n",
      "1047895  Evaluations Remaining\n",
      "rewards= 13.560258040075986\n",
      "actions= [[1. 1.]]\n",
      "1047894  Evaluations Remaining\n",
      "rewards= -0.11792117208212094\n",
      "Timestep 1\tScore: 13.44\tmin: 13.44\tmax: 13.44actions= [[1. 1.]]\n",
      "1047893  Evaluations Remaining\n",
      "rewards= 0.21873975882473706\n",
      "Timestep 2\tScore: 13.66\tmin: 13.66\tmax: 13.66actions= [[1. 1.]]\n",
      "1047892  Evaluations Remaining\n",
      "rewards= 0.0005703688699449927\n",
      "Timestep 3\tScore: 13.66\tmin: 13.66\tmax: 13.66actions= [[1. 1.]]\n",
      "1047891  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= -0.1844703933575924\n",
      "Episode 421\tScore: 13.48\tAverage Score: 14.78\n",
      "actions= [[1. 1.]]\n",
      "1047890  Evaluations Remaining\n",
      "rewards= 13.772450076790165\n",
      "actions= [[1. 1.]]\n",
      "1047889  Evaluations Remaining\n",
      "rewards= -0.1844643783095372\n",
      "Timestep 1\tScore: 13.59\tmin: 13.59\tmax: 13.59actions= [[1. 1.]]\n",
      "1047888  Evaluations Remaining\n",
      "rewards= 0.14708214598164382\n",
      "Timestep 2\tScore: 13.74\tmin: 13.74\tmax: 13.74actions= [[1. 1.]]\n",
      "1047887  Evaluations Remaining\n",
      "rewards= 0.21424581174526347\n",
      "Timestep 3\tScore: 13.95\tmin: 13.95\tmax: 13.95actions= [[1. 1.]]\n",
      "1047886  Evaluations Remaining\n",
      "rewards= 0.15688181500218557\n",
      "Episode 422\tScore: 14.11\tAverage Score: 14.78\n",
      "actions= [[1. 1.]]\n",
      "1047885  Evaluations Remaining\n",
      "rewards= 15.950483215122361\n",
      "actions= [[1. 1.]]\n",
      "1047884  Evaluations Remaining\n",
      "rewards= 0.24044503781377902\n",
      "Timestep 1\tScore: 16.19\tmin: 16.19\tmax: 16.19actions= [[1. 1.]]\n",
      "1047883  Evaluations Remaining\n",
      "rewards= -0.14324818131125872\n",
      "Timestep 2\tScore: 16.05\tmin: 16.05\tmax: 16.05actions= [[1. 1.]]\n",
      "1047882  Evaluations Remaining\n",
      "rewards= 0.061389232383255\n",
      "Timestep 3\tScore: 16.11\tmin: 16.11\tmax: 16.11actions= [[1. 1.]]\n",
      "1047881  Evaluations Remaining\n",
      "rewards= -0.04228953667916491\n",
      "Episode 423\tScore: 16.07\tAverage Score: 15.01\n",
      "actions= [[1. 1.]]\n",
      "1047880  Evaluations Remaining\n",
      "rewards= 13.933093333812677\n",
      "actions= [[1. 1.]]\n",
      "1047879  Evaluations Remaining\n",
      "rewards= 0.181721626421385\n",
      "Timestep 1\tScore: 14.11\tmin: 14.11\tmax: 14.11actions= [[1. 1.]]\n",
      "1047878  Evaluations Remaining\n",
      "rewards= 0.1963795412840117\n",
      "Timestep 2\tScore: 14.31\tmin: 14.31\tmax: 14.31actions= [[1. 1.]]\n",
      "1047877  Evaluations Remaining\n",
      "rewards= 0.16802553765097494\n",
      "Timestep 3\tScore: 14.48\tmin: 14.48\tmax: 14.48actions= [[1. 1.]]\n",
      "1047876  Evaluations Remaining\n",
      "rewards= 0.121212469570529\n",
      "Episode 424\tScore: 14.60\tAverage Score: 14.88\n",
      "actions= [[1. 1.]]\n",
      "1047875  Evaluations Remaining\n",
      "rewards= 15.627440204596578\n",
      "actions= [[1. 1.]]\n",
      "1047874  Evaluations Remaining\n",
      "rewards= -0.07970661208257424\n",
      "Timestep 1\tScore: 15.55\tmin: 15.55\tmax: 15.55actions= [[1. 1.]]\n",
      "1047873  Evaluations Remaining\n",
      "rewards= -0.15357214318851753\n",
      "Timestep 2\tScore: 15.39\tmin: 15.39\tmax: 15.39actions= [[1. 1.]]\n",
      "1047872  Evaluations Remaining\n",
      "rewards= -0.20463623594224645\n",
      "Timestep 3\tScore: 15.19\tmin: 15.19\tmax: 15.19actions= [[1. 1.]]\n",
      "1047871  Evaluations Remaining\n",
      "rewards= 0.010939159952861655\n",
      "Episode 425\tScore: 15.20\tAverage Score: 14.69\n",
      "actions= [[1. 1.]]\n",
      "1047870  Evaluations Remaining\n",
      "rewards= 14.954462675260448\n",
      "actions= [[1. 1.]]\n",
      "1047869  Evaluations Remaining\n",
      "rewards= -0.1970761656419029\n",
      "Timestep 1\tScore: 14.76\tmin: 14.76\tmax: 14.76actions= [[1. 1.]]\n",
      "1047868  Evaluations Remaining\n",
      "rewards= -0.20739962781249943\n",
      "Timestep 2\tScore: 14.55\tmin: 14.55\tmax: 14.55actions= [[1. 1.]]\n",
      "1047867  Evaluations Remaining\n",
      "rewards= -0.16169031040423798\n",
      "Timestep 3\tScore: 14.39\tmin: 14.39\tmax: 14.39actions= [[1. 1.]]\n",
      "1047866  Evaluations Remaining\n",
      "rewards= 0.02361777094756201\n",
      "Episode 426\tScore: 14.41\tAverage Score: 14.88\n",
      "actions= [[1. 1.]]\n",
      "1047865  Evaluations Remaining\n",
      "rewards= 15.313942418721588\n",
      "actions= [[1. 1.]]\n",
      "1047864  Evaluations Remaining\n",
      "rewards= 0.2433593418605855\n",
      "Timestep 1\tScore: 15.56\tmin: 15.56\tmax: 15.56actions= [[1. 1.]]\n",
      "1047863  Evaluations Remaining\n",
      "rewards= -0.022388718246140193\n",
      "Timestep 2\tScore: 15.53\tmin: 15.53\tmax: 15.53actions= [[1. 1.]]\n",
      "1047862  Evaluations Remaining\n",
      "rewards= -0.10118007629756409\n",
      "Timestep 3\tScore: 15.43\tmin: 15.43\tmax: 15.43actions= [[1. 1.]]\n",
      "1047861  Evaluations Remaining\n",
      "rewards= 0.19161110597638098\n",
      "Episode 427\tScore: 15.63\tAverage Score: 15.18\n",
      "actions= [[1. 1.]]\n",
      "1047860  Evaluations Remaining\n",
      "rewards= 16.299559081304423\n",
      "actions= [[1. 1.]]\n",
      "1047859  Evaluations Remaining\n",
      "rewards= 0.2365502872781864\n",
      "Timestep 1\tScore: 16.54\tmin: 16.54\tmax: 16.54actions= [[1. 1.]]\n",
      "1047858  Evaluations Remaining\n",
      "rewards= -0.08823794687428377\n",
      "Timestep 2\tScore: 16.45\tmin: 16.45\tmax: 16.45actions= [[1. 1.]]\n",
      "1047857  Evaluations Remaining\n",
      "rewards= 0.05058256972478414\n",
      "Timestep 3\tScore: 16.50\tmin: 16.50\tmax: 16.50actions= [[1. 1.]]\n",
      "1047856  Evaluations Remaining\n",
      "rewards= -0.2695054768874261\n",
      "Episode 428\tScore: 16.23\tAverage Score: 15.21\n",
      "actions= [[1. 1.]]\n",
      "1047855  Evaluations Remaining\n",
      "rewards= 14.296709800991785\n",
      "actions= [[0.86215085 1.        ]]\n",
      "1047854  Evaluations Remaining\n",
      "rewards= 0.147920921540996\n",
      "Timestep 1\tScore: 14.44\tmin: 14.44\tmax: 14.44actions= [[0.96178311 1.        ]]\n",
      "1047853  Evaluations Remaining\n",
      "rewards= -0.18788060969954623\n",
      "Timestep 2\tScore: 14.26\tmin: 14.26\tmax: 14.26actions= [[1. 1.]]\n",
      "1047852  Evaluations Remaining\n",
      "rewards= -0.28946931835462575\n",
      "Timestep 3\tScore: 13.97\tmin: 13.97\tmax: 13.97actions= [[1. 1.]]\n",
      "1047851  Evaluations Remaining\n",
      "rewards= 0.024137015859575506\n",
      "Episode 429\tScore: 13.99\tAverage Score: 15.09\n",
      "actions= [[0.7161873 1.       ]]\n",
      "1047850  Evaluations Remaining\n",
      "rewards= 8.654489206453569\n",
      "actions= [[0.41044572 1.        ]]\n",
      "1047849  Evaluations Remaining\n",
      "rewards= -0.2056916827070836\n",
      "Timestep 1\tScore: 8.45\tmin: 8.45\tmax: 8.45actions= [[0.51243871 1.        ]]\n",
      "1047848  Evaluations Remaining\n",
      "rewards= 3.749020564653161\n",
      "Timestep 2\tScore: 12.20\tmin: 12.20\tmax: 12.20actions= [[0.66871393 1.        ]]\n",
      "1047847  Evaluations Remaining\n",
      "rewards= 5.755407864752021\n",
      "Timestep 3\tScore: 17.95\tmin: 17.95\tmax: 17.95actions= [[0.68031639 1.        ]]\n",
      "1047846  Evaluations Remaining\n",
      "rewards= 0.5064897537169673\n",
      "Episode 430\tScore: 18.46\tAverage Score: 15.74\n",
      "actions= [[0.33091483 1.        ]]\n",
      "1047845  Evaluations Remaining\n",
      "rewards= 74.32824805914854\n",
      "actions= [[0.07641758 1.        ]]\n",
      "1047844  Evaluations Remaining\n",
      "rewards= -0.33438991323443146\n",
      "Timestep 1\tScore: 73.99\tmin: 73.99\tmax: 73.99actions= [[0.16298601 1.        ]]\n",
      "1047843  Evaluations Remaining\n",
      "rewards= -0.13893621457685823\n",
      "Timestep 2\tScore: 73.85\tmin: 73.85\tmax: 73.85actions= [[0.12371746 1.        ]]\n",
      "1047842  Evaluations Remaining\n",
      "rewards= -0.20133728195557765\n",
      "Timestep 3\tScore: 73.65\tmin: 73.65\tmax: 73.65actions= [[0.21783826 1.        ]]\n",
      "1047841  Evaluations Remaining\n",
      "rewards= 0.24139786475173297\n",
      "Episode 431\tScore: 73.89\tAverage Score: 27.64\n",
      "actions= [[0.04492399 1.        ]]\n",
      "1047840  Evaluations Remaining\n",
      "rewards= 99.51231320378781\n",
      "actions= [[0. 1.]]\n",
      "1047839  Evaluations Remaining\n",
      "rewards= -0.05243986612916407\n",
      "Timestep 1\tScore: 99.46\tmin: 99.46\tmax: 99.46actions= [[0. 1.]]\n",
      "1047838  Evaluations Remaining\n",
      "rewards= -0.14339318240403331\n",
      "Timestep 2\tScore: 99.32\tmin: 99.32\tmax: 99.32actions= [[0. 1.]]\n",
      "1047837  Evaluations Remaining\n",
      "rewards= -0.0356476444324314\n",
      "Timestep 3\tScore: 99.28\tmin: 99.28\tmax: 99.28actions= [[0. 1.]]\n",
      "1047836  Evaluations Remaining\n",
      "rewards= -0.026297891250908645\n",
      "Episode 432\tScore: 99.25\tAverage Score: 44.37\n",
      "actions= [[0. 1.]]\n",
      "1047835  Evaluations Remaining\n",
      "rewards= 97.12210860891265\n",
      "actions= [[0. 1.]]\n",
      "1047834  Evaluations Remaining\n",
      "rewards= -0.01014089476543134\n",
      "Timestep 1\tScore: 97.11\tmin: 97.11\tmax: 97.11actions= [[0. 1.]]\n",
      "1047833  Evaluations Remaining\n",
      "rewards= -0.06872995165738294\n",
      "Timestep 2\tScore: 97.04\tmin: 97.04\tmax: 97.04actions= [[0. 1.]]\n",
      "1047832  Evaluations Remaining\n",
      "rewards= 0.10350259336831202\n",
      "Timestep 3\tScore: 97.15\tmin: 97.15\tmax: 97.15actions= [[0. 1.]]\n",
      "1047831  Evaluations Remaining\n",
      "rewards= 0.02616000217270642\n",
      "Episode 433\tScore: 97.17\tAverage Score: 60.55\n",
      "actions= [[0. 1.]]\n",
      "1047830  Evaluations Remaining\n",
      "rewards= 97.63433430164577\n",
      "actions= [[0. 1.]]\n",
      "1047829  Evaluations Remaining\n",
      "rewards= -0.15622916254514552\n",
      "Timestep 1\tScore: 97.48\tmin: 97.48\tmax: 97.48actions= [[0. 1.]]\n",
      "1047828  Evaluations Remaining\n",
      "rewards= -0.0335007165331036\n",
      "Timestep 2\tScore: 97.44\tmin: 97.44\tmax: 97.44actions= [[0. 1.]]\n",
      "1047827  Evaluations Remaining\n",
      "rewards= 0.20631455547683863\n",
      "Timestep 3\tScore: 97.65\tmin: 97.65\tmax: 97.65actions= [[0. 1.]]\n",
      "1047826  Evaluations Remaining\n",
      "rewards= 0.2131315688754234\n",
      "Episode 434\tScore: 97.86\tAverage Score: 77.33\n",
      "actions= [[0. 1.]]\n",
      "1047825  Evaluations Remaining\n",
      "rewards= 97.56436083814978\n",
      "actions= [[0. 1.]]\n",
      "1047824  Evaluations Remaining\n",
      "rewards= 0.08894481312298952\n",
      "Timestep 1\tScore: 97.65\tmin: 97.65\tmax: 97.65actions= [[0. 1.]]\n",
      "1047823  Evaluations Remaining\n",
      "rewards= 0.09788427708495107\n",
      "Timestep 2\tScore: 97.75\tmin: 97.75\tmax: 97.75actions= [[0. 1.]]\n",
      "1047822  Evaluations Remaining\n",
      "rewards= 0.0154022362703099\n",
      "Timestep 3\tScore: 97.77\tmin: 97.77\tmax: 97.77actions= [[0. 1.]]\n",
      "1047821  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= -0.03613028506487792\n",
      "Episode 435\tScore: 97.73\tAverage Score: 93.18\n",
      "actions= [[0. 1.]]\n",
      "1047820  Evaluations Remaining\n",
      "rewards= 96.15903884036157\n",
      "actions= [[0. 1.]]\n",
      "1047819  Evaluations Remaining\n",
      "rewards= 0.24281492253238968\n",
      "Timestep 1\tScore: 96.40\tmin: 96.40\tmax: 96.40actions= [[0. 1.]]\n",
      "1047818  Evaluations Remaining\n",
      "rewards= 0.24021683203513478\n",
      "Timestep 2\tScore: 96.64\tmin: 96.64\tmax: 96.64actions= [[0. 1.]]\n",
      "1047817  Evaluations Remaining\n",
      "rewards= -0.016087914480976018\n",
      "Timestep 3\tScore: 96.63\tmin: 96.63\tmax: 96.63actions= [[0. 1.]]\n",
      "1047816  Evaluations Remaining\n",
      "rewards= -0.14329137700956585\n",
      "Episode 436\tScore: 96.48\tAverage Score: 97.70\n",
      "actions= [[0. 1.]]\n",
      "1047815  Evaluations Remaining\n",
      "rewards= 92.35226965292644\n",
      "actions= [[0. 1.]]\n",
      "1047814  Evaluations Remaining\n",
      "rewards= -0.0392756973648698\n",
      "Timestep 1\tScore: 92.31\tmin: 92.31\tmax: 92.31actions= [[0. 1.]]\n",
      "1047813  Evaluations Remaining\n",
      "rewards= -0.09695574955764918\n",
      "Timestep 2\tScore: 92.22\tmin: 92.22\tmax: 92.22actions= [[0. 1.]]\n",
      "1047812  Evaluations Remaining\n",
      "rewards= 0.13244938864641842\n",
      "Timestep 3\tScore: 92.35\tmin: 92.35\tmax: 92.35actions= [[0. 1.]]\n",
      "1047811  Evaluations Remaining\n",
      "rewards= -0.153889396229983\n",
      "Episode 437\tScore: 92.19\tAverage Score: 96.29\n",
      "actions= [[0. 1.]]\n",
      "1047810  Evaluations Remaining\n",
      "rewards= 102.38255030758017\n",
      "actions= [[0. 1.]]\n",
      "1047809  Evaluations Remaining\n",
      "rewards= 0.03485666658743147\n",
      "Timestep 1\tScore: 102.42\tmin: 102.42\tmax: 102.42actions= [[0. 1.]]\n",
      "1047808  Evaluations Remaining\n",
      "rewards= -0.26669202256823166\n",
      "Timestep 2\tScore: 102.15\tmin: 102.15\tmax: 102.15actions= [[0. 1.]]\n",
      "1047807  Evaluations Remaining\n",
      "rewards= -0.16388266643020533\n",
      "Timestep 3\tScore: 101.99\tmin: 101.99\tmax: 101.99actions= [[0. 1.]]\n",
      "1047806  Evaluations Remaining\n",
      "rewards= -0.18010909775244555\n",
      "Episode 438\tScore: 101.81\tAverage Score: 97.2281\n",
      "actions= [[0. 1.]]\n",
      "1047805  Evaluations Remaining\n",
      "rewards= 108.70186272421873\n",
      "actions= [[0. 1.]]\n",
      "1047804  Evaluations Remaining\n",
      "rewards= -0.16169239526793833\n",
      "Timestep 1\tScore: 108.54\tmin: 108.54\tmax: 108.54actions= [[0. 1.]]\n",
      "1047803  Evaluations Remaining\n",
      "rewards= 0.1401442555318968\n",
      "Timestep 2\tScore: 108.68\tmin: 108.68\tmax: 108.68actions= [[0. 1.]]\n",
      "1047802  Evaluations Remaining\n",
      "rewards= 0.17743506747297122\n",
      "Timestep 3\tScore: 108.86\tmin: 108.86\tmax: 108.86actions= [[0. 1.]]\n",
      "1047801  Evaluations Remaining\n",
      "rewards= 0.007155215618648292\n",
      "Episode 439\tScore: 108.86\tAverage Score: 99.4286\n",
      "actions= [[0. 1.]]\n",
      "1047800  Evaluations Remaining\n",
      "rewards= 108.44880052411763\n",
      "actions= [[0. 1.]]\n",
      "1047799  Evaluations Remaining\n",
      "rewards= 0.13941222783566198\n",
      "Timestep 1\tScore: 108.59\tmin: 108.59\tmax: 108.59actions= [[0. 1.]]\n",
      "1047798  Evaluations Remaining\n",
      "rewards= 0.20550121082218054\n",
      "Timestep 2\tScore: 108.79\tmin: 108.79\tmax: 108.79actions= [[0. 1.]]\n",
      "1047797  Evaluations Remaining\n",
      "rewards= 0.23972488421458227\n",
      "Timestep 3\tScore: 109.03\tmin: 109.03\tmax: 109.03actions= [[0. 1.]]\n",
      "1047796  Evaluations Remaining\n",
      "rewards= 0.031068407804608622\n",
      "Episode 440\tScore: 109.06\tAverage Score: 101.686\n",
      "actions= [[0. 1.]]\n",
      "1047795  Evaluations Remaining\n",
      "rewards= 92.79352118661258\n",
      "actions= [[0. 1.]]\n",
      "1047794  Evaluations Remaining\n",
      "rewards= 0.1410439284998386\n",
      "Timestep 1\tScore: 92.93\tmin: 92.93\tmax: 92.93actions= [[0. 1.]]\n",
      "1047793  Evaluations Remaining\n",
      "rewards= -0.08714643112615805\n",
      "Timestep 2\tScore: 92.85\tmin: 92.85\tmax: 92.85actions= [[0. 1.]]\n",
      "1047792  Evaluations Remaining\n",
      "rewards= 0.01709062801822947\n",
      "Timestep 3\tScore: 92.86\tmin: 92.86\tmax: 92.86actions= [[0. 1.]]\n",
      "1047791  Evaluations Remaining\n",
      "rewards= -0.10375901030695589\n",
      "Episode 441\tScore: 92.76\tAverage Score: 100.94\n",
      "actions= [[0. 1.]]\n",
      "1047790  Evaluations Remaining\n",
      "rewards= 101.6604902332141\n",
      "actions= [[0. 1.]]\n",
      "1047789  Evaluations Remaining\n",
      "rewards= 0.03807085731043758\n",
      "Timestep 1\tScore: 101.70\tmin: 101.70\tmax: 101.70actions= [[0. 1.]]\n",
      "1047788  Evaluations Remaining\n",
      "rewards= 0.12965069534118756\n",
      "Timestep 2\tScore: 101.83\tmin: 101.83\tmax: 101.83actions= [[0. 1.]]\n",
      "1047787  Evaluations Remaining\n",
      "rewards= 0.21430593331800818\n",
      "Timestep 3\tScore: 102.04\tmin: 102.04\tmax: 102.04actions= [[0. 1.]]\n",
      "1047786  Evaluations Remaining\n",
      "rewards= 0.10939602676647775\n",
      "Episode 442\tScore: 102.15\tAverage Score: 102.935\n",
      "actions= [[0. 1.]]\n",
      "1047785  Evaluations Remaining\n",
      "rewards= 92.73117307323434\n",
      "actions= [[0. 1.]]\n",
      "1047784  Evaluations Remaining\n",
      "rewards= -0.18795778172370836\n",
      "Timestep 1\tScore: 92.54\tmin: 92.54\tmax: 92.54actions= [[0. 1.]]\n",
      "1047783  Evaluations Remaining\n",
      "rewards= -0.12631605285980374\n",
      "Timestep 2\tScore: 92.42\tmin: 92.42\tmax: 92.42actions= [[0. 1.]]\n",
      "1047782  Evaluations Remaining\n",
      "rewards= 0.2285106211191592\n",
      "Timestep 3\tScore: 92.65\tmin: 92.65\tmax: 92.65actions= [[0. 1.]]\n",
      "1047781  Evaluations Remaining\n",
      "rewards= 0.0005254625827064707\n",
      "Episode 443\tScore: 92.65\tAverage Score: 101.10\n",
      "actions= [[0. 1.]]\n",
      "1047780  Evaluations Remaining\n",
      "rewards= 95.02340725242767\n",
      "actions= [[0. 1.]]\n",
      "1047779  Evaluations Remaining\n",
      "rewards= 0.12491880535042998\n",
      "Timestep 1\tScore: 95.15\tmin: 95.15\tmax: 95.15actions= [[0. 1.]]\n",
      "1047778  Evaluations Remaining\n",
      "rewards= -0.24012042726709737\n",
      "Timestep 2\tScore: 94.91\tmin: 94.91\tmax: 94.91actions= [[0. 1.]]\n",
      "1047777  Evaluations Remaining\n",
      "rewards= -0.11503008944161364\n",
      "Timestep 3\tScore: 94.79\tmin: 94.79\tmax: 94.79actions= [[0. 1.]]\n",
      "1047776  Evaluations Remaining\n",
      "rewards= 0.23950409543537\n",
      "Episode 444\tScore: 95.03\tAverage Score: 98.33\n",
      "actions= [[0. 1.]]\n",
      "1047775  Evaluations Remaining\n",
      "rewards= 97.69756489765078\n",
      "actions= [[0. 1.]]\n",
      "1047774  Evaluations Remaining\n",
      "rewards= 0.1922150098575961\n",
      "Timestep 1\tScore: 97.89\tmin: 97.89\tmax: 97.89actions= [[0. 1.]]\n",
      "1047773  Evaluations Remaining\n",
      "rewards= 0.00956427944563254\n",
      "Timestep 2\tScore: 97.90\tmin: 97.90\tmax: 97.90actions= [[0. 1.]]\n",
      "1047772  Evaluations Remaining\n",
      "rewards= -0.0454704309089311\n",
      "Timestep 3\tScore: 97.85\tmin: 97.85\tmax: 97.85actions= [[0. 1.]]\n",
      "1047771  Evaluations Remaining\n",
      "rewards= -0.0017176646774665905\n",
      "Episode 445\tScore: 97.85\tAverage Score: 96.09\n",
      "actions= [[0. 1.]]\n",
      "1047770  Evaluations Remaining\n",
      "rewards= 98.62970682149351\n",
      "actions= [[0. 1.]]\n",
      "1047769  Evaluations Remaining\n",
      "rewards= 0.1646380296464125\n",
      "Timestep 1\tScore: 98.79\tmin: 98.79\tmax: 98.79actions= [[0. 1.]]\n",
      "1047768  Evaluations Remaining\n",
      "rewards= 0.16604203821347197\n",
      "Timestep 2\tScore: 98.96\tmin: 98.96\tmax: 98.96actions= [[0. 1.]]\n",
      "1047767  Evaluations Remaining\n",
      "rewards= 0.08041759980997121\n",
      "Timestep 3\tScore: 99.04\tmin: 99.04\tmax: 99.04actions= [[0. 1.]]\n",
      "1047766  Evaluations Remaining\n",
      "rewards= 0.20916799473033088\n",
      "Episode 446\tScore: 99.25\tAverage Score: 97.39\n",
      "actions= [[0. 1.]]\n",
      "1047765  Evaluations Remaining\n",
      "rewards= 106.33360361666439\n",
      "actions= [[0. 1.]]\n",
      "1047764  Evaluations Remaining\n",
      "rewards= -0.2541486186274162\n",
      "Timestep 1\tScore: 106.08\tmin: 106.08\tmax: 106.08actions= [[0. 1.]]\n",
      "1047763  Evaluations Remaining\n",
      "rewards= 0.16387879020477802\n",
      "Timestep 2\tScore: 106.24\tmin: 106.24\tmax: 106.24actions= [[0. 1.]]\n",
      "1047762  Evaluations Remaining\n",
      "rewards= 0.1748366739159244\n",
      "Timestep 3\tScore: 106.42\tmin: 106.42\tmax: 106.42actions= [[0. 1.]]\n",
      "1047761  Evaluations Remaining\n",
      "rewards= -0.16878791268067195\n",
      "Episode 447\tScore: 106.25\tAverage Score: 98.2125\n",
      "actions= [[0. 1.]]\n",
      "1047760  Evaluations Remaining\n",
      "rewards= 98.55800994405881\n",
      "actions= [[0. 1.]]\n",
      "1047759  Evaluations Remaining\n",
      "rewards= 0.1376253041264066\n",
      "Timestep 1\tScore: 98.70\tmin: 98.70\tmax: 98.70actions= [[0. 1.]]\n",
      "1047758  Evaluations Remaining\n",
      "rewards= 0.025354990808084565\n",
      "Timestep 2\tScore: 98.72\tmin: 98.72\tmax: 98.72actions= [[0. 1.]]\n",
      "1047757  Evaluations Remaining\n",
      "rewards= -0.23354467911775334\n",
      "Timestep 3\tScore: 98.49\tmin: 98.49\tmax: 98.49actions= [[0. 1.]]\n",
      "1047756  Evaluations Remaining\n",
      "rewards= -0.15967421421524852\n",
      "Episode 448\tScore: 98.33\tAverage Score: 99.34\n",
      "actions= [[0. 1.]]\n",
      "1047755  Evaluations Remaining\n",
      "rewards= 92.86300937521968\n",
      "actions= [[0. 1.]]\n",
      "1047754  Evaluations Remaining\n",
      "rewards= -0.20571161622181977\n",
      "Timestep 1\tScore: 92.66\tmin: 92.66\tmax: 92.66actions= [[0. 1.]]\n",
      "1047753  Evaluations Remaining\n",
      "rewards= -0.09674926650114202\n",
      "Timestep 2\tScore: 92.56\tmin: 92.56\tmax: 92.56actions= [[0. 1.]]\n",
      "1047752  Evaluations Remaining\n",
      "rewards= 0.18241551400925538\n",
      "Timestep 3\tScore: 92.74\tmin: 92.74\tmax: 92.74actions= [[0. 1.]]\n",
      "1047751  Evaluations Remaining\n",
      "rewards= 0.07023694985828266\n",
      "Episode 449\tScore: 92.81\tAverage Score: 98.90\n",
      "actions= [[0. 1.]]\n",
      "1047750  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 107.02087747709618\n",
      "actions= [[0. 1.]]\n",
      "1047749  Evaluations Remaining\n",
      "rewards= 0.22552002629482093\n",
      "Timestep 1\tScore: 107.25\tmin: 107.25\tmax: 107.25actions= [[0. 1.]]\n",
      "1047748  Evaluations Remaining\n",
      "rewards= -0.17914457308713416\n",
      "Timestep 2\tScore: 107.07\tmin: 107.07\tmax: 107.07actions= [[0. 1.]]\n",
      "1047747  Evaluations Remaining\n",
      "rewards= 0.0041773586070061874\n",
      "Timestep 3\tScore: 107.07\tmin: 107.07\tmax: 107.07actions= [[0. 1.]]\n",
      "1047746  Evaluations Remaining\n",
      "rewards= 0.22904787116257763\n",
      "Episode 450\tScore: 107.30\tAverage Score: 100.790\n",
      "actions= [[0. 1.]]\n",
      "1047745  Evaluations Remaining\n",
      "rewards= 92.1792254118526\n",
      "actions= [[0. 1.]]\n",
      "1047744  Evaluations Remaining\n",
      "rewards= 0.2639874749967599\n",
      "Timestep 1\tScore: 92.44\tmin: 92.44\tmax: 92.44actions= [[0. 1.]]\n",
      "1047743  Evaluations Remaining\n",
      "rewards= 0.21158468419123366\n",
      "Timestep 2\tScore: 92.65\tmin: 92.65\tmax: 92.65actions= [[0. 1.]]\n",
      "1047742  Evaluations Remaining\n",
      "rewards= -0.16374890405972709\n",
      "Timestep 3\tScore: 92.49\tmin: 92.49\tmax: 92.49actions= [[0. 1.]]\n",
      "1047741  Evaluations Remaining\n",
      "rewards= 0.07155416394502812\n",
      "Episode 451\tScore: 92.56\tAverage Score: 99.45\n",
      "actions= [[0. 1.]]\n",
      "1047740  Evaluations Remaining\n",
      "rewards= 109.68549469737701\n",
      "actions= [[0. 1.]]\n",
      "1047739  Evaluations Remaining\n",
      "rewards= -0.08192574125847818\n",
      "Timestep 1\tScore: 109.60\tmin: 109.60\tmax: 109.60actions= [[0. 1.]]\n",
      "1047738  Evaluations Remaining\n",
      "rewards= 0.24594430194110606\n",
      "Timestep 2\tScore: 109.85\tmin: 109.85\tmax: 109.85actions= [[0. 1.]]\n",
      "1047737  Evaluations Remaining\n",
      "rewards= -0.25074479584023246\n",
      "Timestep 3\tScore: 109.60\tmin: 109.60\tmax: 109.60actions= [[0. 1.]]\n",
      "1047736  Evaluations Remaining\n",
      "rewards= -0.1799127599807484\n",
      "Episode 452\tScore: 109.42\tAverage Score: 100.082\n",
      "actions= [[0. 1.]]\n",
      "1047735  Evaluations Remaining\n",
      "rewards= 100.45549241884686\n",
      "actions= [[0. 1.]]\n",
      "1047734  Evaluations Remaining\n",
      "rewards= 0.22391586897375904\n",
      "Timestep 1\tScore: 100.68\tmin: 100.68\tmax: 100.68actions= [[0. 1.]]\n",
      "1047733  Evaluations Remaining\n",
      "rewards= 0.15049861875395854\n",
      "Timestep 2\tScore: 100.83\tmin: 100.83\tmax: 100.83actions= [[0. 1.]]\n",
      "1047732  Evaluations Remaining\n",
      "rewards= -0.1982935618736703\n",
      "Timestep 3\tScore: 100.63\tmin: 100.63\tmax: 100.63actions= [[0. 1.]]\n",
      "1047731  Evaluations Remaining\n",
      "rewards= 0.0904606417090541\n",
      "Episode 453\tScore: 100.72\tAverage Score: 100.562\n",
      "actions= [[0. 1.]]\n",
      "1047730  Evaluations Remaining\n",
      "rewards= 98.71984951989653\n",
      "actions= [[0. 1.]]\n",
      "1047729  Evaluations Remaining\n",
      "rewards= 0.11924655847391996\n",
      "Timestep 1\tScore: 98.84\tmin: 98.84\tmax: 98.84actions= [[0. 1.]]\n",
      "1047728  Evaluations Remaining\n",
      "rewards= -0.1822303581579976\n",
      "Timestep 2\tScore: 98.66\tmin: 98.66\tmax: 98.66actions= [[0. 1.]]\n",
      "1047727  Evaluations Remaining\n",
      "rewards= -0.12970074629370076\n",
      "Timestep 3\tScore: 98.53\tmin: 98.53\tmax: 98.53actions= [[0. 1.]]\n",
      "1047726  Evaluations Remaining\n",
      "rewards= 0.21432721184279124\n",
      "Episode 454\tScore: 98.74\tAverage Score: 101.75\n",
      "actions= [[0. 1.]]\n",
      "1047725  Evaluations Remaining\n",
      "rewards= 103.45249724274765\n",
      "actions= [[0. 1.]]\n",
      "1047724  Evaluations Remaining\n",
      "rewards= 0.02483801893810922\n",
      "Timestep 1\tScore: 103.48\tmin: 103.48\tmax: 103.48actions= [[0. 1.]]\n",
      "1047723  Evaluations Remaining\n",
      "rewards= 0.26472785815510713\n",
      "Timestep 2\tScore: 103.74\tmin: 103.74\tmax: 103.74actions= [[0. 1.]]\n",
      "1047722  Evaluations Remaining\n",
      "rewards= 0.247773818762969\n",
      "Timestep 3\tScore: 103.99\tmin: 103.99\tmax: 103.99actions= [[0. 1.]]\n",
      "1047721  Evaluations Remaining\n",
      "rewards= -0.19839147596367424\n",
      "Episode 455\tScore: 103.79\tAverage Score: 101.059\n",
      "actions= [[0. 1.]]\n",
      "1047720  Evaluations Remaining\n",
      "rewards= 107.67214124446467\n",
      "actions= [[0. 1.]]\n",
      "1047719  Evaluations Remaining\n",
      "rewards= -0.15677409967444556\n",
      "Timestep 1\tScore: 107.52\tmin: 107.52\tmax: 107.52actions= [[0. 1.]]\n",
      "1047718  Evaluations Remaining\n",
      "rewards= -0.03535696349726347\n",
      "Timestep 2\tScore: 107.48\tmin: 107.48\tmax: 107.48actions= [[0. 1.]]\n",
      "1047717  Evaluations Remaining\n",
      "rewards= 0.14335227278235374\n",
      "Timestep 3\tScore: 107.62\tmin: 107.62\tmax: 107.62actions= [[0. 1.]]\n",
      "1047716  Evaluations Remaining\n",
      "rewards= 0.02560141245206582\n",
      "Episode 456\tScore: 107.65\tAverage Score: 104.065\n",
      "actions= [[0. 1.]]\n",
      "1047715  Evaluations Remaining\n",
      "rewards= 108.6273587268593\n",
      "actions= [[0. 1.]]\n",
      "1047714  Evaluations Remaining\n",
      "rewards= 0.212087821267803\n",
      "Timestep 1\tScore: 108.84\tmin: 108.84\tmax: 108.84actions= [[0. 1.]]\n",
      "1047713  Evaluations Remaining\n",
      "rewards= -0.16845881401258733\n",
      "Timestep 2\tScore: 108.67\tmin: 108.67\tmax: 108.67actions= [[0. 1.]]\n",
      "1047712  Evaluations Remaining\n",
      "rewards= -0.022189683024040896\n",
      "Timestep 3\tScore: 108.65\tmin: 108.65\tmax: 108.65actions= [[0. 1.]]\n",
      "1047711  Evaluations Remaining\n",
      "rewards= -0.02633893486287242\n",
      "Episode 457\tScore: 108.62\tAverage Score: 103.912\n",
      "actions= [[0. 1.]]\n",
      "1047710  Evaluations Remaining\n",
      "rewards= 92.99910784088934\n",
      "actions= [[0. 1.]]\n",
      "1047709  Evaluations Remaining\n",
      "rewards= -0.21321479126907672\n",
      "Timestep 1\tScore: 92.79\tmin: 92.79\tmax: 92.79actions= [[0. 1.]]\n",
      "1047708  Evaluations Remaining\n",
      "rewards= 0.030657169958054453\n",
      "Timestep 2\tScore: 92.82\tmin: 92.82\tmax: 92.82actions= [[0. 1.]]\n",
      "1047707  Evaluations Remaining\n",
      "rewards= -0.20242972964504302\n",
      "Timestep 3\tScore: 92.61\tmin: 92.61\tmax: 92.61actions= [[0. 1.]]\n",
      "1047706  Evaluations Remaining\n",
      "rewards= -0.2521809548975784\n",
      "Episode 458\tScore: 92.36\tAverage Score: 102.23\n",
      "actions= [[0. 1.]]\n",
      "1047705  Evaluations Remaining\n",
      "rewards= 100.01386232722056\n",
      "actions= [[0. 1.]]\n",
      "1047704  Evaluations Remaining\n",
      "rewards= 0.006365862906634767\n",
      "Timestep 1\tScore: 100.02\tmin: 100.02\tmax: 100.02actions= [[0. 1.]]\n",
      "1047703  Evaluations Remaining\n",
      "rewards= 0.023842551278280055\n",
      "Timestep 2\tScore: 100.04\tmin: 100.04\tmax: 100.04actions= [[0. 1.]]\n",
      "1047702  Evaluations Remaining\n",
      "rewards= 0.10873724372983595\n",
      "Timestep 3\tScore: 100.15\tmin: 100.15\tmax: 100.15actions= [[0. 1.]]\n",
      "1047701  Evaluations Remaining\n",
      "rewards= 0.1658472654657519\n",
      "Episode 459\tScore: 100.32\tAverage Score: 102.552\n",
      "actions= [[0. 1.]]\n",
      "1047700  Evaluations Remaining\n",
      "rewards= 111.49839185283852\n",
      "actions= [[0. 1.]]\n",
      "1047699  Evaluations Remaining\n",
      "rewards= 0.11129439698987875\n",
      "Timestep 1\tScore: 111.61\tmin: 111.61\tmax: 111.61actions= [[0. 1.]]\n",
      "1047698  Evaluations Remaining\n",
      "rewards= 0.1886233453104018\n",
      "Timestep 2\tScore: 111.80\tmin: 111.80\tmax: 111.80actions= [[0. 1.]]\n",
      "1047697  Evaluations Remaining\n",
      "rewards= 0.25548566251909355\n",
      "Timestep 3\tScore: 112.05\tmin: 112.05\tmax: 112.05actions= [[0. 1.]]\n",
      "1047696  Evaluations Remaining\n",
      "rewards= -0.23606164248700967\n",
      "Episode 460\tScore: 111.82\tAverage Score: 104.152\n",
      "actions= [[0. 1.]]\n",
      "1047695  Evaluations Remaining\n",
      "rewards= 102.67695977095225\n",
      "actions= [[0. 1.]]\n",
      "1047694  Evaluations Remaining\n",
      "rewards= 0.19343746628456193\n",
      "Timestep 1\tScore: 102.87\tmin: 102.87\tmax: 102.87actions= [[0.20105179 0.        ]]\n",
      "1047693  Evaluations Remaining\n",
      "rewards= 0.17283659536931717\n",
      "Timestep 2\tScore: 103.04\tmin: 103.04\tmax: 103.04actions= [[0. 1.]]\n",
      "1047692  Evaluations Remaining\n",
      "rewards= 103.91888673556633\n",
      "Timestep 3\tScore: 206.96\tmin: 206.96\tmax: 206.96actions= [[0. 1.]]\n",
      "1047691  Evaluations Remaining\n",
      "rewards= -0.2677064744190343\n",
      "Episode 461\tScore: 206.69\tAverage Score: 123.969\n",
      "actions= [[0. 1.]]\n",
      "1047690  Evaluations Remaining\n",
      "rewards= 102.02766398123373\n",
      "actions= [[0. 1.]]\n",
      "1047689  Evaluations Remaining\n",
      "rewards= 0.024162368501548404\n",
      "Timestep 1\tScore: 102.05\tmin: 102.05\tmax: 102.05actions= [[0. 1.]]\n",
      "1047688  Evaluations Remaining\n",
      "rewards= 0.07375225487445158\n",
      "Timestep 2\tScore: 102.13\tmin: 102.13\tmax: 102.13actions= [[0. 1.]]\n",
      "1047687  Evaluations Remaining\n",
      "rewards= 0.24644139902129192\n",
      "Timestep 3\tScore: 102.37\tmin: 102.37\tmax: 102.37actions= [[0. 1.]]\n",
      "1047686  Evaluations Remaining\n",
      "rewards= -0.1566847540616081\n",
      "Episode 462\tScore: 102.22\tAverage Score: 122.682\n",
      "actions= [[0. 1.]]\n",
      "1047685  Evaluations Remaining\n",
      "rewards= 93.51141858045492\n",
      "actions= [[0. 1.]]\n",
      "1047684  Evaluations Remaining\n",
      "rewards= -0.06042116268671638\n",
      "Timestep 1\tScore: 93.45\tmin: 93.45\tmax: 93.45actions= [[0. 1.]]\n",
      "1047683  Evaluations Remaining\n",
      "rewards= -0.11325722234959379\n",
      "Timestep 2\tScore: 93.34\tmin: 93.34\tmax: 93.34actions= [[0. 1.]]\n",
      "1047682  Evaluations Remaining\n",
      "rewards= 0.04767408950786489\n",
      "Timestep 3\tScore: 93.39\tmin: 93.39\tmax: 93.39actions= [[0. 1.]]\n",
      "1047681  Evaluations Remaining\n",
      "rewards= -0.25742655728726493\n",
      "Episode 463\tScore: 93.13\tAverage Score: 122.83\n",
      "actions= [[0. 1.]]\n",
      "1047680  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= 106.65930230990391\n",
      "actions= [[0. 1.]]\n",
      "1047679  Evaluations Remaining\n",
      "rewards= -0.03421255078313479\n",
      "Timestep 1\tScore: 106.63\tmin: 106.63\tmax: 106.63actions= [[0. 1.]]\n",
      "1047678  Evaluations Remaining\n",
      "rewards= -0.20490885207111154\n",
      "Timestep 2\tScore: 106.42\tmin: 106.42\tmax: 106.42actions= [[0. 1.]]\n",
      "1047677  Evaluations Remaining\n",
      "rewards= 0.08254193324165948\n",
      "Timestep 3\tScore: 106.50\tmin: 106.50\tmax: 106.50actions= [[0. 1.]]\n",
      "1047676  Evaluations Remaining\n",
      "rewards= 0.020868450474203826\n",
      "Episode 464\tScore: 106.52\tAverage Score: 124.082\n",
      "actions= [[0. 1.]]\n",
      "1047675  Evaluations Remaining\n",
      "rewards= 96.51278782642518\n",
      "actions= [[0. 1.]]\n",
      "1047674  Evaluations Remaining\n",
      "rewards= 0.25726700844351225\n",
      "Timestep 1\tScore: 96.77\tmin: 96.77\tmax: 96.77actions= [[0. 1.]]\n",
      "1047673  Evaluations Remaining\n",
      "rewards= -0.03100606128793526\n",
      "Timestep 2\tScore: 96.74\tmin: 96.74\tmax: 96.74actions= [[0. 1.]]\n",
      "1047672  Evaluations Remaining\n",
      "rewards= -0.13381282733445365\n",
      "Timestep 3\tScore: 96.61\tmin: 96.61\tmax: 96.61actions= [[0. 1.]]\n",
      "1047671  Evaluations Remaining\n",
      "rewards= 0.1094332204811237\n",
      "Episode 465\tScore: 96.71\tAverage Score: 121.06\n",
      "actions= [[0. 1.]]\n",
      "1047670  Evaluations Remaining\n",
      "rewards= 91.83642701045865\n",
      "actions= [[0. 1.]]\n",
      "1047669  Evaluations Remaining\n",
      "rewards= 0.15230475311844494\n",
      "Timestep 1\tScore: 91.99\tmin: 91.99\tmax: 91.99actions= [[0. 1.]]\n",
      "1047668  Evaluations Remaining\n",
      "rewards= -0.03402970968946528\n",
      "Timestep 2\tScore: 91.95\tmin: 91.95\tmax: 91.95actions= [[0. 1.]]\n",
      "1047667  Evaluations Remaining\n",
      "rewards= 0.25356287876467576\n",
      "Timestep 3\tScore: 92.21\tmin: 92.21\tmax: 92.21actions= [[0. 1.]]\n",
      "1047666  Evaluations Remaining\n",
      "rewards= 0.24238027222345782\n",
      "Episode 466\tScore: 92.45\tAverage Score: 98.21\n",
      "actions= [[0. 1.]]\n",
      "1047665  Evaluations Remaining\n",
      "rewards= 92.65615565178625\n",
      "actions= [[0. 1.]]\n",
      "1047664  Evaluations Remaining\n",
      "rewards= -0.20933792890272196\n",
      "Timestep 1\tScore: 92.45\tmin: 92.45\tmax: 92.45actions= [[0. 1.]]\n",
      "1047663  Evaluations Remaining\n",
      "rewards= 0.13173809364208955\n",
      "Timestep 2\tScore: 92.58\tmin: 92.58\tmax: 92.58actions= [[0. 1.]]\n",
      "1047662  Evaluations Remaining\n",
      "rewards= -0.10226258751355255\n",
      "Timestep 3\tScore: 92.48\tmin: 92.48\tmax: 92.48actions= [[0. 1.]]\n",
      "1047661  Evaluations Remaining\n",
      "rewards= 0.10089037389687094\n",
      "Episode 467\tScore: 92.58\tAverage Score: 96.28\n",
      "actions= [[0. 1.]]\n",
      "1047660  Evaluations Remaining\n",
      "rewards= 98.53745973746047\n",
      "actions= [[0. 1.]]\n",
      "1047659  Evaluations Remaining\n",
      "rewards= 0.12252171016407232\n",
      "Timestep 1\tScore: 98.66\tmin: 98.66\tmax: 98.66actions= [[0. 1.]]\n",
      "1047658  Evaluations Remaining\n",
      "rewards= 0.1547347752640893\n",
      "Timestep 2\tScore: 98.81\tmin: 98.81\tmax: 98.81actions= [[0. 1.]]\n",
      "1047657  Evaluations Remaining\n",
      "rewards= -0.23309501079461148\n",
      "Timestep 3\tScore: 98.58\tmin: 98.58\tmax: 98.58actions= [[0. 1.]]\n",
      "1047656  Evaluations Remaining\n",
      "rewards= -0.05488599914936598\n",
      "Episode 468\tScore: 98.53\tAverage Score: 97.36\n",
      "actions= [[0. 1.]]\n",
      "1047655  Evaluations Remaining\n",
      "rewards= 101.14939903931634\n",
      "actions= [[0. 1.]]\n",
      "1047654  Evaluations Remaining\n",
      "rewards= -0.0754333514210006\n",
      "Timestep 1\tScore: 101.07\tmin: 101.07\tmax: 101.07actions= [[0. 1.]]\n",
      "1047653  Evaluations Remaining\n",
      "rewards= 0.0301165838297206\n",
      "Timestep 2\tScore: 101.10\tmin: 101.10\tmax: 101.10actions= [[0. 1.]]\n",
      "1047652  Evaluations Remaining\n",
      "rewards= 0.10347924694667388\n",
      "Timestep 3\tScore: 101.21\tmin: 101.21\tmax: 101.21actions= [[0. 1.]]\n",
      "1047651  Evaluations Remaining\n",
      "rewards= 0.043148768326727094\n",
      "Episode 469\tScore: 101.25\tAverage Score: 96.3025\n",
      "actions= [[0. 1.]]\n",
      "1047650  Evaluations Remaining\n",
      "rewards= 93.28202807997978\n",
      "actions= [[0. 1.]]\n",
      "1047649  Evaluations Remaining\n",
      "rewards= -0.11954866098734751\n",
      "Timestep 1\tScore: 93.16\tmin: 93.16\tmax: 93.16actions= [[0. 1.]]\n",
      "1047648  Evaluations Remaining\n",
      "rewards= 0.2556614865012925\n",
      "Timestep 2\tScore: 93.42\tmin: 93.42\tmax: 93.42actions= [[0. 1.]]\n",
      "1047647  Evaluations Remaining\n",
      "rewards= 0.10705869177952687\n",
      "Timestep 3\tScore: 93.53\tmin: 93.53\tmax: 93.53actions= [[0. 1.]]\n",
      "1047646  Evaluations Remaining\n",
      "rewards= -0.04092423026710934\n",
      "Episode 470\tScore: 93.48\tAverage Score: 95.66\n",
      "actions= [[0. 1.]]\n",
      "1047645  Evaluations Remaining\n",
      "rewards= 93.30480953043441\n",
      "actions= [[0. 1.]]\n",
      "1047644  Evaluations Remaining\n",
      "rewards= -0.1134518028967979\n",
      "Timestep 1\tScore: 93.19\tmin: 93.19\tmax: 93.19actions= [[0. 1.]]\n",
      "1047643  Evaluations Remaining\n",
      "rewards= -0.25566386068620117\n",
      "Timestep 2\tScore: 92.94\tmin: 92.94\tmax: 92.94actions= [[0. 1.]]\n",
      "1047642  Evaluations Remaining\n",
      "rewards= 0.2519620912602276\n",
      "Timestep 3\tScore: 93.19\tmin: 93.19\tmax: 93.19actions= [[0. 1.]]\n",
      "1047641  Evaluations Remaining\n",
      "rewards= -0.23507017992651447\n",
      "Episode 471\tScore: 92.95\tAverage Score: 95.76\n",
      "actions= [[0. 1.]]\n",
      "1047640  Evaluations Remaining\n",
      "rewards= 102.44210835376512\n",
      "actions= [[0. 1.]]\n",
      "1047639  Evaluations Remaining\n",
      "rewards= -0.14360229939860947\n",
      "Timestep 1\tScore: 102.30\tmin: 102.30\tmax: 102.30actions= [[0. 1.]]\n",
      "1047638  Evaluations Remaining\n",
      "rewards= -0.09545613076714465\n",
      "Timestep 2\tScore: 102.20\tmin: 102.20\tmax: 102.20actions= [[0. 1.]]\n",
      "1047637  Evaluations Remaining\n",
      "rewards= -0.22998468825049967\n",
      "Timestep 3\tScore: 101.97\tmin: 101.97\tmax: 101.97actions= [[0. 1.]]\n",
      "1047636  Evaluations Remaining\n",
      "rewards= -0.026625495057015947\n",
      "Episode 472\tScore: 101.95\tAverage Score: 97.6395\n",
      "actions= [[0. 1.]]\n",
      "1047635  Evaluations Remaining\n",
      "rewards= 94.74631498016866\n",
      "actions= [[0. 1.]]\n",
      "1047634  Evaluations Remaining\n",
      "rewards= 0.2327681376868469\n",
      "Timestep 1\tScore: 94.98\tmin: 94.98\tmax: 94.98actions= [[0. 1.]]\n",
      "1047633  Evaluations Remaining\n",
      "rewards= 0.02060695668954482\n",
      "Timestep 2\tScore: 95.00\tmin: 95.00\tmax: 95.00actions= [[0. 1.]]\n",
      "1047632  Evaluations Remaining\n",
      "rewards= 0.22910507687105097\n",
      "Timestep 3\tScore: 95.23\tmin: 95.23\tmax: 95.23actions= [[0. 1.]]\n",
      "1047631  Evaluations Remaining\n",
      "rewards= -0.21094556543124776\n",
      "Episode 473\tScore: 95.02\tAverage Score: 96.93\n",
      "actions= [[0. 1.]]\n",
      "1047630  Evaluations Remaining\n",
      "rewards= 108.9938451274929\n",
      "actions= [[0. 1.]]\n",
      "1047629  Evaluations Remaining\n",
      "rewards= 0.1515415209006501\n",
      "Timestep 1\tScore: 109.15\tmin: 109.15\tmax: 109.15actions= [[0. 1.]]\n",
      "1047628  Evaluations Remaining\n",
      "rewards= -0.09672521522624367\n",
      "Timestep 2\tScore: 109.05\tmin: 109.05\tmax: 109.05actions= [[0. 1.]]\n",
      "1047627  Evaluations Remaining\n",
      "rewards= -0.2537553004717856\n",
      "Timestep 3\tScore: 108.79\tmin: 108.79\tmax: 108.79actions= [[0. 1.]]\n",
      "1047626  Evaluations Remaining\n",
      "rewards= 0.010644424265902952\n",
      "Episode 474\tScore: 108.81\tAverage Score: 98.4481\n",
      "actions= [[0. 1.]]\n",
      "1047625  Evaluations Remaining\n",
      "rewards= 95.39156529687243\n",
      "actions= [[0. 1.]]\n",
      "1047624  Evaluations Remaining\n",
      "rewards= 0.22207329159271882\n",
      "Timestep 1\tScore: 95.61\tmin: 95.61\tmax: 95.61actions= [[0. 1.]]\n",
      "1047623  Evaluations Remaining\n",
      "rewards= 0.1683011268717194\n",
      "Timestep 2\tScore: 95.78\tmin: 95.78\tmax: 95.78actions= [[0. 1.]]\n",
      "1047622  Evaluations Remaining\n",
      "rewards= 0.2298530583766829\n",
      "Timestep 3\tScore: 96.01\tmin: 96.01\tmax: 96.01actions= [[0. 1.]]\n",
      "1047621  Evaluations Remaining\n",
      "rewards= 0.2375905379336003\n",
      "Episode 475\tScore: 96.25\tAverage Score: 98.99\n",
      "actions= [[0. 1.]]\n",
      "1047620  Evaluations Remaining\n",
      "rewards= 100.12884123544583\n",
      "actions= [[0. 1.]]\n",
      "1047619  Evaluations Remaining\n",
      "rewards= -0.04319640465935537\n",
      "Timestep 1\tScore: 100.09\tmin: 100.09\tmax: 100.09actions= [[0. 1.]]\n",
      "1047618  Evaluations Remaining\n",
      "rewards= 0.2535118848611657\n",
      "Timestep 2\tScore: 100.34\tmin: 100.34\tmax: 100.34actions= [[0. 1.]]\n",
      "1047617  Evaluations Remaining\n",
      "rewards= 0.22993232842296285\n",
      "Timestep 3\tScore: 100.57\tmin: 100.57\tmax: 100.57actions= [[0. 1.]]\n",
      "1047616  Evaluations Remaining\n",
      "rewards= 0.0026388594796116216\n",
      "Episode 476\tScore: 100.57\tAverage Score: 100.527\n",
      "actions= [[0. 1.]]\n",
      "1047615  Evaluations Remaining\n",
      "rewards= 99.43123017853833\n",
      "actions= [[0. 1.]]\n",
      "1047614  Evaluations Remaining\n",
      "rewards= 0.00947245979303446\n",
      "Timestep 1\tScore: 99.44\tmin: 99.44\tmax: 99.44actions= [[0. 1.]]\n",
      "1047613  Evaluations Remaining\n",
      "rewards= -0.15390260211912654\n",
      "Timestep 2\tScore: 99.29\tmin: 99.29\tmax: 99.29actions= [[0. 1.]]\n",
      "1047612  Evaluations Remaining\n",
      "rewards= 0.24236098056948396\n",
      "Timestep 3\tScore: 99.53\tmin: 99.53\tmax: 99.53actions= [[0. 1.]]\n",
      "1047611  Evaluations Remaining\n",
      "rewards= 0.16913843923913596\n",
      "Episode 477\tScore: 99.70\tAverage Score: 100.07\n",
      "actions= [[0. 1.]]\n",
      "1047610  Evaluations Remaining\n",
      "rewards= 107.50017307931039\n",
      "actions= [[0. 1.]]\n",
      "1047609  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= -0.07235845927479279\n",
      "Timestep 1\tScore: 107.43\tmin: 107.43\tmax: 107.43actions= [[0. 1.]]\n",
      "1047608  Evaluations Remaining\n",
      "rewards= -0.0721797425646642\n",
      "Timestep 2\tScore: 107.36\tmin: 107.36\tmax: 107.36actions= [[0. 1.]]\n",
      "1047607  Evaluations Remaining\n",
      "rewards= -0.04087252902647309\n",
      "Timestep 3\tScore: 107.31\tmin: 107.31\tmax: 107.31actions= [[0. 1.]]\n",
      "1047606  Evaluations Remaining\n",
      "rewards= 0.1415174230734122\n",
      "Episode 478\tScore: 107.46\tAverage Score: 102.566\n",
      "actions= [[0. 1.]]\n",
      "1047605  Evaluations Remaining\n",
      "rewards= 101.00431058992528\n",
      "actions= [[1. 0.]]\n",
      "1047604  Evaluations Remaining\n",
      "rewards= 104.44109595352441\n",
      "Timestep 1\tScore: 205.45\tmin: 205.45\tmax: 205.45actions= [[0. 1.]]\n",
      "1047603  Evaluations Remaining\n",
      "rewards= 100.98410669158358\n",
      "Timestep 2\tScore: 306.43\tmin: 306.43\tmax: 306.43actions= [[0. 1.]]\n",
      "1047602  Evaluations Remaining\n",
      "rewards= -0.10290957905847398\n",
      "Timestep 3\tScore: 306.33\tmin: 306.33\tmax: 306.33actions= [[0. 1.]]\n",
      "1047601  Evaluations Remaining\n",
      "rewards= 0.034023411521287183\n",
      "Episode 479\tScore: 306.36\tAverage Score: 142.076\n",
      "actions= [[0. 1.]]\n",
      "1047600  Evaluations Remaining\n",
      "rewards= 93.4158423261647\n",
      "actions= [[0. 1.]]\n",
      "1047599  Evaluations Remaining\n",
      "rewards= 0.21656059285103035\n",
      "Timestep 1\tScore: 93.63\tmin: 93.63\tmax: 93.63actions= [[0. 1.]]\n",
      "1047598  Evaluations Remaining\n",
      "rewards= 0.03259403355831125\n",
      "Timestep 2\tScore: 93.66\tmin: 93.66\tmax: 93.66actions= [[0. 1.]]\n",
      "1047597  Evaluations Remaining\n",
      "rewards= -0.13151563280975287\n",
      "Timestep 3\tScore: 93.53\tmin: 93.53\tmax: 93.53actions= [[0. 1.]]\n",
      "1047596  Evaluations Remaining\n",
      "rewards= -0.21461891961512602\n",
      "Episode 480\tScore: 93.32\tAverage Score: 141.48\n",
      "actions= [[0. 1.]]\n",
      "1047595  Evaluations Remaining\n",
      "rewards= 93.77718919806463\n",
      "actions= [[0. 1.]]\n",
      "1047594  Evaluations Remaining\n",
      "rewards= 0.12186707782595851\n",
      "Timestep 1\tScore: 93.90\tmin: 93.90\tmax: 93.90actions= [[0. 1.]]\n",
      "1047593  Evaluations Remaining\n",
      "rewards= -0.269149696673078\n",
      "Timestep 2\tScore: 93.63\tmin: 93.63\tmax: 93.63actions= [[0. 1.]]\n",
      "1047592  Evaluations Remaining\n",
      "rewards= -0.23611023413050525\n",
      "Timestep 3\tScore: 93.39\tmin: 93.39\tmax: 93.39actions= [[0. 1.]]\n",
      "1047591  Evaluations Remaining\n",
      "rewards= -0.0962546704010463\n",
      "Episode 481\tScore: 93.30\tAverage Score: 140.03\n",
      "actions= [[0. 1.]]\n",
      "1047590  Evaluations Remaining\n",
      "rewards= 92.87700543591919\n",
      "actions= [[0. 1.]]\n",
      "1047589  Evaluations Remaining\n",
      "rewards= 0.2657833394970175\n",
      "Timestep 1\tScore: 93.14\tmin: 93.14\tmax: 93.14actions= [[0. 1.]]\n",
      "1047588  Evaluations Remaining\n",
      "rewards= -0.19316511532289837\n",
      "Timestep 2\tScore: 92.95\tmin: 92.95\tmax: 92.95actions= [[0. 1.]]\n",
      "1047587  Evaluations Remaining\n",
      "rewards= -0.2626988741258858\n",
      "Timestep 3\tScore: 92.69\tmin: 92.69\tmax: 92.69actions= [[0. 1.]]\n",
      "1047586  Evaluations Remaining\n",
      "rewards= 0.010269744052972207\n",
      "Episode 482\tScore: 92.70\tAverage Score: 138.63\n",
      "actions= [[0. 1.]]\n",
      "1047585  Evaluations Remaining\n",
      "rewards= 92.99966971851704\n",
      "actions= [[0. 1.]]\n",
      "1047584  Evaluations Remaining\n",
      "rewards= 0.09258767766095488\n",
      "Timestep 1\tScore: 93.09\tmin: 93.09\tmax: 93.09actions= [[0. 1.]]\n",
      "1047583  Evaluations Remaining\n",
      "rewards= -0.0756328688027228\n",
      "Timestep 2\tScore: 93.02\tmin: 93.02\tmax: 93.02actions= [[0. 1.]]\n",
      "1047582  Evaluations Remaining\n",
      "rewards= -0.1577352215616563\n",
      "Timestep 3\tScore: 92.86\tmin: 92.86\tmax: 92.86actions= [[0. 1.]]\n",
      "1047581  Evaluations Remaining\n",
      "rewards= 0.17265981160619592\n",
      "Episode 483\tScore: 93.03\tAverage Score: 135.74\n",
      "actions= [[0. 1.]]\n",
      "1047580  Evaluations Remaining\n",
      "rewards= 107.91014672803425\n",
      "actions= [[0. 1.]]\n",
      "1047579  Evaluations Remaining\n",
      "rewards= -0.26524486275112835\n",
      "Timestep 1\tScore: 107.64\tmin: 107.64\tmax: 107.64actions= [[0. 1.]]\n",
      "1047578  Evaluations Remaining\n",
      "rewards= 0.18447410956793142\n",
      "Timestep 2\tScore: 107.83\tmin: 107.83\tmax: 107.83actions= [[0. 1.]]\n",
      "1047577  Evaluations Remaining\n",
      "rewards= -0.23026128106773758\n",
      "Timestep 3\tScore: 107.60\tmin: 107.60\tmax: 107.60actions= [[0. 1.]]\n",
      "1047576  Evaluations Remaining\n",
      "rewards= -0.020935826066170282\n",
      "Episode 484\tScore: 107.58\tAverage Score: 95.9858\n",
      "actions= [[0. 1.]]\n",
      "1047575  Evaluations Remaining\n",
      "rewards= 98.60490110994999\n",
      "actions= [[0. 1.]]\n",
      "1047574  Evaluations Remaining\n",
      "rewards= -0.1906378970084579\n",
      "Timestep 1\tScore: 98.41\tmin: 98.41\tmax: 98.41actions= [[0. 1.]]\n",
      "1047573  Evaluations Remaining\n",
      "rewards= 0.10091009228149872\n",
      "Timestep 2\tScore: 98.52\tmin: 98.52\tmax: 98.52actions= [[0. 1.]]\n",
      "1047572  Evaluations Remaining\n",
      "rewards= 0.2033973625808998\n",
      "Timestep 3\tScore: 98.72\tmin: 98.72\tmax: 98.72actions= [[0. 1.]]\n",
      "1047571  Evaluations Remaining\n",
      "rewards= -0.24773752394733073\n",
      "Episode 485\tScore: 98.47\tAverage Score: 97.02\n",
      "actions= [[0. 1.]]\n",
      "1047570  Evaluations Remaining\n",
      "rewards= 110.9386972363432\n",
      "actions= [[0. 1.]]\n",
      "1047569  Evaluations Remaining\n",
      "rewards= 0.007201168756444609\n",
      "Timestep 1\tScore: 110.95\tmin: 110.95\tmax: 110.95actions= [[0. 1.]]\n",
      "1047568  Evaluations Remaining\n",
      "rewards= 0.1623415750028694\n",
      "Timestep 2\tScore: 111.11\tmin: 111.11\tmax: 111.11actions= [[0. 1.]]\n",
      "1047567  Evaluations Remaining\n",
      "rewards= 0.021160680455275305\n",
      "Timestep 3\tScore: 111.13\tmin: 111.13\tmax: 111.13actions= [[0. 1.]]\n",
      "1047566  Evaluations Remaining\n",
      "rewards= -0.18180626132058464\n",
      "Episode 486\tScore: 110.95\tAverage Score: 100.555\n",
      "actions= [[0. 1.]]\n",
      "1047565  Evaluations Remaining\n",
      "rewards= 109.79318610222255\n",
      "actions= [[0. 1.]]\n",
      "1047564  Evaluations Remaining\n",
      "rewards= -0.021709044647983955\n",
      "Timestep 1\tScore: 109.77\tmin: 109.77\tmax: 109.77actions= [[0. 1.]]\n",
      "1047563  Evaluations Remaining\n",
      "rewards= -0.25897941757956655\n",
      "Timestep 2\tScore: 109.51\tmin: 109.51\tmax: 109.51actions= [[0. 1.]]\n",
      "1047562  Evaluations Remaining\n",
      "rewards= 0.2689460677860227\n",
      "Timestep 3\tScore: 109.78\tmin: 109.78\tmax: 109.78actions= [[0. 1.]]\n",
      "1047561  Evaluations Remaining\n",
      "rewards= 0.021622565369316504\n",
      "Episode 487\tScore: 109.80\tAverage Score: 103.970\n",
      "actions= [[0. 1.]]\n",
      "1047560  Evaluations Remaining\n",
      "rewards= 94.97436192740393\n",
      "actions= [[0. 1.]]\n",
      "1047559  Evaluations Remaining\n",
      "rewards= -0.013442984967874771\n",
      "Timestep 1\tScore: 94.96\tmin: 94.96\tmax: 94.96actions= [[0. 1.]]\n",
      "1047558  Evaluations Remaining\n",
      "rewards= -0.18845244621934576\n",
      "Timestep 2\tScore: 94.77\tmin: 94.77\tmax: 94.77actions= [[0. 1.]]\n",
      "1047557  Evaluations Remaining\n",
      "rewards= -0.12271369703434454\n",
      "Timestep 3\tScore: 94.65\tmin: 94.65\tmax: 94.65actions= [[0. 1.]]\n",
      "1047556  Evaluations Remaining\n",
      "rewards= 0.040044728598434\n",
      "Episode 488\tScore: 94.69\tAverage Score: 104.30\n",
      "actions= [[0. 1.]]\n",
      "1047555  Evaluations Remaining\n",
      "rewards= 110.97678590449244\n",
      "actions= [[0. 1.]]\n",
      "1047554  Evaluations Remaining\n",
      "rewards= -0.05273709910126634\n",
      "Timestep 1\tScore: 110.92\tmin: 110.92\tmax: 110.92actions= [[0. 1.]]\n",
      "1047553  Evaluations Remaining\n",
      "rewards= 0.0695217598971567\n",
      "Timestep 2\tScore: 110.99\tmin: 110.99\tmax: 110.99actions= [[0. 1.]]\n",
      "1047552  Evaluations Remaining\n",
      "rewards= 0.24383024425873234\n",
      "Timestep 3\tScore: 111.24\tmin: 111.24\tmax: 111.24actions= [[0. 1.]]\n",
      "1047551  Evaluations Remaining\n",
      "rewards= -0.11410235442224748\n",
      "Episode 489\tScore: 111.12\tAverage Score: 105.012\n",
      "actions= [[0. 1.]]\n",
      "1047550  Evaluations Remaining\n",
      "rewards= 104.38421530211772\n",
      "actions= [[0. 1.]]\n",
      "1047549  Evaluations Remaining\n",
      "rewards= 0.24704772267653397\n",
      "Timestep 1\tScore: 104.63\tmin: 104.63\tmax: 104.63actions= [[0. 1.]]\n",
      "1047548  Evaluations Remaining\n",
      "rewards= 0.07779172460268224\n",
      "Timestep 2\tScore: 104.71\tmin: 104.71\tmax: 104.71actions= [[0. 1.]]\n",
      "1047547  Evaluations Remaining\n",
      "rewards= 0.0546108950159816\n",
      "Timestep 3\tScore: 104.76\tmin: 104.76\tmax: 104.76actions= [[0. 1.]]\n",
      "1047546  Evaluations Remaining\n",
      "rewards= -0.09006166405938476\n",
      "Episode 490\tScore: 104.67\tAverage Score: 106.257\n",
      "actions= [[0. 1.]]\n",
      "1047545  Evaluations Remaining\n",
      "rewards= 110.39217888091419\n",
      "actions= [[0. 1.]]\n",
      "1047544  Evaluations Remaining\n",
      "rewards= -0.07199389154400837\n",
      "Timestep 1\tScore: 110.32\tmin: 110.32\tmax: 110.32actions= [[0. 1.]]\n",
      "1047543  Evaluations Remaining\n",
      "rewards= -0.22356581765521355\n",
      "Timestep 2\tScore: 110.10\tmin: 110.10\tmax: 110.10actions= [[0. 1.]]\n",
      "1047542  Evaluations Remaining\n",
      "rewards= -0.00868062077956333\n",
      "Timestep 3\tScore: 110.09\tmin: 110.09\tmax: 110.09actions= [[0. 1.]]\n",
      "1047541  Evaluations Remaining\n",
      "rewards= -0.23787538644694628\n",
      "Episode 491\tScore: 109.85\tAverage Score: 106.035\n",
      "actions= [[0. 1.]]\n",
      "1047540  Evaluations Remaining\n",
      "rewards= 102.67147333641763\n",
      "actions= [[0. 1.]]\n",
      "1047539  Evaluations Remaining\n",
      "rewards= 0.11865387750404821\n",
      "Timestep 1\tScore: 102.79\tmin: 102.79\tmax: 102.79actions= [[0. 1.]]\n",
      "1047538  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards= -0.2499982278026609\n",
      "Timestep 2\tScore: 102.54\tmin: 102.54\tmax: 102.54actions= [[0. 1.]]\n",
      "1047537  Evaluations Remaining\n",
      "rewards= 0.2578666015137503\n",
      "Timestep 3\tScore: 102.80\tmin: 102.80\tmax: 102.80actions= [[0. 1.]]\n",
      "1047536  Evaluations Remaining\n",
      "rewards= -0.12075257616799107\n",
      "Episode 492\tScore: 102.68\tAverage Score: 104.608\n",
      "actions= [[0. 1.]]\n",
      "1047535  Evaluations Remaining\n",
      "rewards= 103.82625817967609\n",
      "actions= [[0. 1.]]\n",
      "1047534  Evaluations Remaining\n",
      "rewards= -0.02252754818678282\n",
      "Timestep 1\tScore: 103.80\tmin: 103.80\tmax: 103.80actions= [[0. 1.]]\n",
      "1047533  Evaluations Remaining\n",
      "rewards= -0.1209944656974482\n",
      "Timestep 2\tScore: 103.68\tmin: 103.68\tmax: 103.68actions= [[0. 1.]]\n",
      "1047532  Evaluations Remaining\n",
      "rewards= 0.07578674308864608\n",
      "Timestep 3\tScore: 103.76\tmin: 103.76\tmax: 103.76actions= [[0. 1.]]\n",
      "1047531  Evaluations Remaining\n",
      "rewards= -0.14950306842677197\n",
      "Episode 493\tScore: 103.61\tAverage Score: 106.391\n",
      "actions= [[0. 1.]]\n",
      "1047530  Evaluations Remaining\n",
      "rewards= 98.48494029072317\n",
      "actions= [[0. 1.]]\n",
      "1047529  Evaluations Remaining\n",
      "rewards= -0.1956732517445361\n",
      "Timestep 1\tScore: 98.29\tmin: 98.29\tmax: 98.29actions= [[0. 1.]]\n",
      "1047528  Evaluations Remaining\n",
      "rewards= 0.14593974258583264\n",
      "Timestep 2\tScore: 98.44\tmin: 98.44\tmax: 98.44actions= [[0. 1.]]\n",
      "1047527  Evaluations Remaining\n",
      "rewards= 0.1853536036179002\n",
      "Timestep 3\tScore: 98.62\tmin: 98.62\tmax: 98.62actions= [[0. 1.]]\n",
      "1047526  Evaluations Remaining\n",
      "rewards= -0.12290424081947249\n",
      "Episode 494\tScore: 98.50\tAverage Score: 103.86\n",
      "actions= [[0. 1.]]\n",
      "1047525  Evaluations Remaining\n",
      "rewards= 107.35796665575602\n",
      "actions= [[0. 1.]]\n",
      "1047524  Evaluations Remaining\n",
      "rewards= 0.2505822748976425\n",
      "Timestep 1\tScore: 107.61\tmin: 107.61\tmax: 107.61actions= [[0. 1.]]\n",
      "1047523  Evaluations Remaining\n",
      "rewards= 0.21195179872612702\n",
      "Timestep 2\tScore: 107.82\tmin: 107.82\tmax: 107.82actions= [[0. 1.]]\n",
      "1047522  Evaluations Remaining\n",
      "rewards= -0.13767950588863842\n",
      "Timestep 3\tScore: 107.68\tmin: 107.68\tmax: 107.68actions= [[0. 1.]]\n",
      "1047521  Evaluations Remaining\n",
      "rewards= -0.14570636658032532\n",
      "Episode 495\tScore: 107.54\tAverage Score: 104.434\n",
      "actions= [[0. 1.]]\n",
      "1047520  Evaluations Remaining\n",
      "rewards= 104.39382411309244\n",
      "actions= [[0. 1.]]\n",
      "1047519  Evaluations Remaining\n",
      "rewards= -0.13964781112997526\n",
      "Timestep 1\tScore: 104.25\tmin: 104.25\tmax: 104.25actions= [[0. 1.]]\n",
      "1047518  Evaluations Remaining\n",
      "rewards= -0.1821585145152591\n",
      "Timestep 2\tScore: 104.07\tmin: 104.07\tmax: 104.07actions= [[0. 1.]]\n",
      "1047517  Evaluations Remaining\n",
      "rewards= -0.25154419762486757\n",
      "Timestep 3\tScore: 103.82\tmin: 103.82\tmax: 103.82actions= [[0. 1.]]\n",
      "1047516  Evaluations Remaining\n",
      "rewards= 0.14366584046826647\n",
      "Episode 496\tScore: 103.96\tAverage Score: 103.266\n",
      "actions= [[0. 1.]]\n",
      "1047515  Evaluations Remaining\n",
      "rewards= 93.84320477677299\n",
      "actions= [[0. 1.]]\n",
      "1047514  Evaluations Remaining\n",
      "rewards= -0.14578476065827095\n",
      "Timestep 1\tScore: 93.70\tmin: 93.70\tmax: 93.70actions= [[0. 1.]]\n",
      "1047513  Evaluations Remaining\n",
      "rewards= 0.13979349802279595\n",
      "Timestep 2\tScore: 93.84\tmin: 93.84\tmax: 93.84actions= [[0. 1.]]\n",
      "1047512  Evaluations Remaining\n",
      "rewards= -0.11778015149787402\n",
      "Timestep 3\tScore: 93.72\tmin: 93.72\tmax: 93.72actions= [[0. 1.]]\n",
      "1047511  Evaluations Remaining\n",
      "rewards= -0.08311058829743212\n",
      "Episode 497\tScore: 93.64\tAverage Score: 101.45\n",
      "actions= [[0. 1.]]\n",
      "1047510  Evaluations Remaining\n",
      "rewards= 95.34797614336188\n",
      "actions= [[0. 1.]]\n",
      "1047509  Evaluations Remaining\n",
      "rewards= 0.12396752240884457\n",
      "Timestep 1\tScore: 95.47\tmin: 95.47\tmax: 95.47actions= [[0. 1.]]\n",
      "1047508  Evaluations Remaining\n",
      "rewards= -0.09468690524365275\n",
      "Timestep 2\tScore: 95.38\tmin: 95.38\tmax: 95.38actions= [[0. 1.]]\n",
      "1047507  Evaluations Remaining\n",
      "rewards= 0.04862717706245734\n",
      "Timestep 3\tScore: 95.43\tmin: 95.43\tmax: 95.43actions= [[0. 1.]]\n",
      "1047506  Evaluations Remaining\n",
      "rewards= -0.03673634021918781\n",
      "Episode 498\tScore: 95.39\tAverage Score: 99.80\n",
      "actions= [[0. 1.]]\n",
      "1047505  Evaluations Remaining\n",
      "rewards= 92.4370077138947\n",
      "actions= [[0. 1.]]\n",
      "1047504  Evaluations Remaining\n",
      "rewards= -0.12234997008009918\n",
      "Timestep 1\tScore: 92.31\tmin: 92.31\tmax: 92.31actions= [[0. 1.]]\n",
      "1047503  Evaluations Remaining\n",
      "rewards= -0.004844152861411821\n",
      "Timestep 2\tScore: 92.31\tmin: 92.31\tmax: 92.31actions= [[0. 1.]]\n",
      "1047502  Evaluations Remaining\n",
      "rewards= -0.09189251679866084\n",
      "Timestep 3\tScore: 92.22\tmin: 92.22\tmax: 92.22actions= [[0. 1.]]\n",
      "1047501  Evaluations Remaining\n",
      "rewards= 0.20559726946966128\n",
      "Episode 499\tScore: 92.42\tAverage Score: 98.59\n",
      "actions= [[0. 1.]]\n",
      "1047500  Evaluations Remaining\n",
      "rewards= 96.59389224162426\n",
      "actions= [[0. 1.]]\n",
      "1047499  Evaluations Remaining\n",
      "rewards= 0.027712710632506354\n",
      "Timestep 1\tScore: 96.62\tmin: 96.62\tmax: 96.62actions= [[0. 1.]]\n",
      "1047498  Evaluations Remaining\n",
      "rewards= -0.03833660844487641\n",
      "Timestep 2\tScore: 96.58\tmin: 96.58\tmax: 96.58actions= [[0. 1.]]\n",
      "1047497  Evaluations Remaining\n",
      "rewards= -0.2457092059072905\n",
      "Timestep 3\tScore: 96.34\tmin: 96.34\tmax: 96.34actions= [[0. 1.]]\n",
      "1047496  Evaluations Remaining\n",
      "rewards= -0.018404035884128422\n",
      "Episode 500\tScore: 96.32\tAverage Score: 96.35\n",
      "Episode 500\tAverage Score: 96.35\n"
     ]
    }
   ],
   "source": [
    "def ddpg(n_episodes=500, max_t=1000,target_score=600):\n",
    "    \"\"\" Deep Deterministic Policy Gradients\n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "    \"\"\"\n",
    "    scores_window = deque(maxlen=5)\n",
    "    scores = np.zeros(num_agents)\n",
    "    scores_episode = []\n",
    "    agent = Agent(state_size, action_size, random_seed=0)\n",
    "    epsilon=0.6\n",
    "\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        \n",
    "        agent.reset()\n",
    "        env.reset() \n",
    "        scores = np.zeros(num_agents) \n",
    "        next_states = np.array([env.state]).reshape(1, 1) \n",
    "        for t in range(max_t):\n",
    "            states = next_states\n",
    "            actions = np.array(agent.act(states),dtype=\"float64\")\n",
    "            if epsilon > random.random() :\n",
    "                actions = np.random.randn(num_agents, action_size)    \n",
    "            actions = np.clip(actions, 0, 1)\n",
    "            print(\"actions=\",actions)\n",
    "#             print(\"actions1=\",actions1)\n",
    "            next_states, rewards, dones, _ = env.evaluateAction(actions[0])  # send the action to the environment  \n",
    "            print(\"rewards=\",rewards)\n",
    "            next_states = np.array([next_states]).reshape(1, 1) \n",
    "            agent.step(t,states, actions, rewards, next_states, dones) \n",
    "            scores += rewards\n",
    "            if t % 20:\n",
    "                print('\\rTimestep {}\\tScore: {:.2f}\\tmin: {:.2f}\\tmax: {:.2f}'\n",
    "                      .format(t, np.mean(scores), np.min(scores), np.max(scores)), end=\"\") \n",
    "            if dones:\n",
    "                break \n",
    "        score = np.mean(scores)\n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores_episode.append(score)\n",
    "        epsilon = epsilon*0.99\n",
    "        print('\\rEpisode {}\\tScore: {:.2f}\\tAverage Score: {:.2f}'.format(i_episode, score, np.mean(scores_window)), end=\"\\n\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=target_score:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "            torch.save(Agent.actor_local.state_dict(), 'models/arm_actor.pth')\n",
    "            torch.save(Agent.critic_local.state_dict(), 'models/arm_critic.pth')\n",
    "            break\n",
    "            \n",
    "    return scores_episode\n",
    "\n",
    "scores = ddpg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.plot the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.title(\"KDD-2019-DRL-Malaria\")\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
